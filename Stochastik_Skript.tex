\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\author{Maik Pickl und Fred Brockstedt}
\usepackage{mathrsfs}
\title{Stochastik}
\newcommand{\E}{\mathbb{E}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\supp}{\text{supp}}
\usepackage[left=4cm,right=3cm,top=4cm,bottom=4cm]{geometry}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Freds usepackages
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage{color}
\usepackage{verbatim}
\usepackage{varioref}
\usepackage{float}
\usepackage{amstext}
\usepackage[unicode=true,
bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
breaklinks=true,pdfborder={0 0 0},backref=page,colorlinks=true]
{hyperref}
\usepackage{bbold}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Freds Definitionen, Saetze und Theoreme
\numberwithin{equation}{section}
\numberwithin{figure}{section}

\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}[section]

\theoremstyle{definition}
\newtheorem{defn}[thm]{\protect\definitionname}
\newtheorem{example}[thm]{\protect\examplename}

\theoremstyle{remark}
\newtheorem{rem}[thm]{\protect\remarkname}

\theoremstyle{plain}
\newtheorem{lem}[thm]{\protect\lemmaname}
\newtheorem{prop}[thm]{\protect\propositionname}
\newtheorem{cor}[thm]{\protect\corollaryname}
\newtheorem*{fact*}{\protect\factname}
\newtheorem*{prop*}{\protect\propositionname}
\newtheorem*{lem*}{\protect\lemmaname}


\makeatother

\providecommand{\corollaryname}{Korollar}
\providecommand{\definitionname}{Definition}
\providecommand{\examplename}{Beispiel}
\providecommand{\factname}{Fakt}
\providecommand{\lemmaname}{Lemma}
\providecommand{\propositionname}{Satz}
\providecommand{\remarkname}{Bemerkung}
\providecommand{\theoremname}{Theorem}

\newcommand{\1}{ \mathbb{1} } %% Indikatorfunktion

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Index
\makeindex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Dokument
\begin {document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Inhaltsverzeichnis

% \chapter*{Übersicht}
% \textbf{\S 1 \qquad Grundbegriffe}
% \begin{itemize}
% \item Zufallsvariable
% \item Wahrscheinlichkeitsräume
% \item Konvergenzbegriffe
% \item \dots
% \end{itemize}
% \textbf{\S 2 \qquad Unabhängigkeit}
% \begin{itemize}
% \item Gesetze der großen Zahlen
% \item Zentraler Grenzwertsatz
% \end{itemize}
% \textbf{\S 3 \qquad Elementare bedingte Wahrscheinlichkeit}\\\\
% \textbf{\S 4 \qquad Bedingte Erwartungen}\\\\
% \textbf{\S 5 \qquad Elementare Begriffe der Statistik}\\\\

\tableofcontents{}
\chapter{Grundbegriffe}

\section{Wahrscheinlichkeitsräume}
\label{sec:wraeume}
% \Large{\textbf{1.1 Wahrscheinlichkeitsräume}}\normalsize
\begin{itemize}
\item Was kann passieren: $\Omega$ (Menge der möglichen Ereignisse)
\item Mit welchen Wahrscheinlichkeiten passiert etwas:
  \begin{center}
    $P: \mathcal{A} \subset \mathcal{P}(\Omega) \rightarrow [0,1]$
  \end{center}
  Wobei $\mathcal{A}$ weiter unten noch näher zu präzisieren ist.
\end{itemize}
% \textbf{1.1.1 Beispiel}\\\\
\begin{example}
  \begin{itemize}
  \item[i)] Ein Münzwurf: $\Omega=\{Kopf, Zahl\}:=\{0,1\}$
  \item[ii)] n-Münzwürfe: $\Omega=\{(x_1,\dots,x_n) \in \{0,1\}^n\}$
  \item[iii)] $\infty$-viele Münzwürfe: $\Omega=\{(x_i)_{i\in \mathbb{N}}|x_i \in \{0,1\}\}=\{0,1\}^\mathbb{N}(=[0,1])$
  \item[iv)] Stetige Funktionen auf $[0,1]$: $\Omega \in
    C^0([0,1],\mathbb{R})$ d.h. $\omega \in \Omega$ ist eine stetige Abbildung.
    \begin{center}
      $\omega: [0,1] \rightarrow \mathbb{R}$
    \end{center}
    z.B.: $\omega(t)=$ Aktienkurs zur Zeit $t \in [0,1]$\\\\\\
    Vereinbarung: Wir nennen $\omega \in \Omega$ ein \underline{\textit{Elementarereignis}}.\index{Elementarereignis}
  \end{itemize}
\end{example}
% \textbf{Definition 1.1.2}\\\\
\begin{defn} % flashcard-name: Ereignis
  Eine Teilmenge $A \in \Omega$ heißt ein \underline{\textit{Ereignis}}. \index{Ereignis}
  Wir sagen, ein Ereignis tritt ein, falls für das realisierte Elementarereignis $\omega \in \Omega$ gilt: $\omega \in A$.
  \begin{itemize}
  \item[i)] unmögliches Ereignis: $A=\emptyset$
  \item[ii)] sicheres Ereignis: $A=\Omega$
  \item[iii)] $A$ tritt nicht ein $\Leftrightarrow$ $A^c=\Omega\setminus A$ tritt ein 
  \end{itemize}
\end{defn}
\textit{Kombination von Ereignissen}
\begin{itemize}
\item[i)] $A_1 \cup A_2$; $\bigcup\limits_i A_i$\qquad \text{lies: mindestens ein} $A_i$ \text{tritt ein} \index{Ereignisse}
\item[ii)] $A_1 \cap A_2$; $\bigcap\limits_i A_i$\qquad \text{lies: alle} $A_i$ \text{treten ein} 
\item[iii)] $\limsup\limits_{n \to \infty} A_n=\bigcap\limits_{n}\bigcup\limits_{m\geq n}A_m$\qquad \text{lies:} $\infty$\text{-viele} $A_i$ \text{treten ein}  

  \textit{Begründung:} $\omega \in \limsup\limits_{n \to \infty} A_n \Leftrightarrow \forall k \in \mathbb{N} \exists n\geq k: \omega \in A_n \Leftrightarrow |\{A_n|\omega \in A_n\}|=\infty$
\item[iv)] $\liminf\limits_{n \to \infty} A_n=\bigcup\limits_{n}\bigcap\limits_{m\geq n}A_m$ \qquad lies: alle bis auf endlich viele $A_i$ treten ein
  \textit{Begründung:} $\omega \in \liminf\limits_{n \to \infty} A_n \Leftrightarrow \exists k \in \mathbb{N} \forall n\geq k: \omega \in A_n$
\end{itemize}
% \textbf{Beispiel 1.1.3}\\\\
\begin{example}
  Die Beispiele seien die gleichen wie unter 1.1.1, hier werden lediglich Anwendungen der eben gegebenen Definitionen auf die bereits angegebenen Beispiele angeführt.
  \begin{itemize}
  \item[i)] "1 tritt ein": $A=\{1\}$ 
  \item[ii)] "genau $k$-mal 1 aus $n$ Würfen": $A=\left\{(x_1,\dots,x_n) \in \{0,1\}^n| \sum\limits_{i=1}^nx_i=k\right\}$
  \item[iii)] Die relative Häufigkeit von "1'' ist $p \in [0,1]$: $A=\left\{(x_i)_{i \in \mathbb{N}}|\lim\limits_{n \to \infty}\frac{1}{n}\sum\limits_{i=1}^n x_i=p\right\}$
  \item[iv)] Ein Wert $c \in \mathbb{R}$ wird überschritten: $A=\left\{w \in \Omega| \max\limits_{0\leq t\leq 1}\omega(t)\geq c \right\}$  
  \end{itemize}
\end{example}
% \textbf{Definition 1.1.4}\\\\
\begin{defn}  % flashcard-name:  $\sigma$-Algebra
  $\mathcal{A}\subset \mathcal{P}(\Omega)=$Potenzmenge von  $\Omega$ heißt \index{$\sigma$-Algebra}$\sigma$-Algebra, falls gilt: 
  \begin{itemize}
  \item[i)] $\emptyset \in \mathcal{A}$
  \item[ii)] $A\in \mathcal{A} \Rightarrow A^c
    \in \mathcal{A}$
  \item[iii)] Sind $(A_i)_{i \in \mathbb{N}} \in \mathcal{A}$,
    so auch $\bigcup\limits_{i=1}^\infty A_i \in \mathcal{A}$
  \end{itemize}
\end{defn}
% \textbf{Bemerkung 1.1.5}\\\\
\begin{rem}
  Sei $\mathcal{A}$ eine $\sigma$-Algebra, dann gilt:
  \begin{itemize}
  \item[i)] $\Omega=\emptyset^c \in \mathcal{A}$
  \item[ii)] Sind $(A_i)_{i \in \mathbb{N}} \in \mathcal{A}$, so auch $\bigcap\limits_{i=1}^\infty A_i=\left(\bigcup\limits_{i=1}^\infty A_i^c\right)^c \in \mathcal{A}$\\
    \textit{Typische Konstruktion} Sei $\mathcal{A}_0$=Menge von
    Ereignissen die "dabei sein sollen". Setze:
    $\mathcal{A}=\bigcap\limits_{\substack{\mathcal{B} \text{ ist }
        \sigma-\text{Algebra}\\ \mathcal{A}_0\subset
        \mathcal{B}}}\mathcal{B}$
  \end{itemize}

\end{rem}
Frage: Wieso gilt $\mathcal{A}\neq \emptyset$? Antwort: Offenbar ist $\mathcal{B}=\mathcal{P}(\Omega)$ eine der $\sigma$-Algebren im Schnitt, außerdem gilt für alle $\mathcal{B}$: $\Omega \in \mathcal{B}$.
% \textbf{Bemerkung 1.1.6}\\\\
\begin{rem} 
  Sei $\Omega$ ein topologischer Raum, dann gilt:
  $\mathcal{A}_0=$"Menge der offenen Mengen"
  $\Rightarrow \sigma(\mathcal{A}_0)=$ die von $\mathcal{A}_0$ erzeugte $\sigma$-Algebra ist die Borel-$\sigma$-Algebra
\end{rem}

% \textit{Resümee}\\\\
\paragraph{Resümee:}
\label{sec:resumee}
Bisher haben wir die Eingangs gestellte Frage "Was kann passieren?" behandelt und als Antwort das Tupel $(\Omega,\mathcal{A})$ erhalten. Hierbei ist $\mathcal{A}$ ein Mengensystem in $\mathcal{P}(\Omega)$, dass in gewisser Weise die Ereignisse repräsentiert welche für uns von Interesse sind. Wir wenden uns nun der Frage ''Mit welchen Wahrscheinlichkeiten passiert etwas?'' zu.\\\\
% \textbf{Definition 1.1.7}\\\\
\begin{defn}  % flashcard-name: Wahrscheinlichkeits-Maß
  Sei $\Omega \neq \emptyset$ und $\mathcal{A}\subset
  \mathcal{P}(\Omega)$ eine $\sigma$-Algebra. Eine
  Funktion:\begin{center} $P: \mathcal{A} \rightarrow \mathbb{R}_+$
  \end{center}
  heißt ''Maß'' auf $\mathcal{A}$ falls folgendes gilt:
  \begin{itemize}
  \item[i)] $P(\emptyset)=0$
  \item[ii)] $P\left(\stackrel{\cdot}{\bigcup\limits_{i \in \mathbb{N}}}A_i\right)=\sum\limits_{i=1}^\infty P(A_i)$\\
    Gilt zusätzlich:
  \item[iii)] $P(\Omega)=1$
  \end{itemize}
  So heißt $P$ ein Wahrscheinlichkeitsmaß \index{Wahrscheinlichkeitsmaß}.
  Das Tripel $(\Omega,\mathcal{A},P)$ heißt Wahrscheinlichkeitsraum (Wahrscheinlichkeitsraum). \index{Wahrscheinlichkeitsraum}
\end{defn}
% \textbf{Beispiel 1.1.8}\\\\
\begin{example} \ % hier Leerzeichen, damit itemize in einer neuen Zeile beginnen kann
  \begin{itemize}
  \item[i)]
    $\mathcal{A}=\mathcal{P}(\Omega)=\{\emptyset,\{0\},\{1\},\{0,1\}\}$
    \qquad $P(\{0\})=P(\{1\})=\frac{1}{2}$ \qquad ''faire'' Münze
  \item[iii)] Modell für $\infty$-viele Münzwürfe
    Wie oben gilt: $\Omega=\{0,1\}^\mathbb{N}$. Wir konstruieren nun $\mathcal{A}$ indem wir einen Erzeuger angeben. Wir wählen als Erzeuger die Menge der \textit{\underline{Zylindermengen}}, die wie folgt definiert ist:
    \begin{center}
      $\mathcal{A}_0=\{B\subset \Omega|\exists n \in \mathbb{N}_0 \text{ und } B_0 \text{ mit } B=B_0\times\{0,1\}\times \{0,1\}\times\dots \} $
    \end{center}
    D.h. ein Ereignis in $\mathcal{A}_0$ tritt ein, wenn es von endlich vielen Realisierungen abhängig ist. Nach dem obigen Konstruktionsprinzip ist dann:
    \begin{center}
      $\mathcal{A}=\bigcap\limits_{\substack{\mathcal{B} \text{ ist }  \sigma-\text{Algebra}\\ \mathcal{A}_0\subset \mathcal{B}}}\mathcal{B}$
    \end{center}       
    Auf $\mathcal{A}_0$ wählen wir $P_0: \mathcal{A}_0 \to \mathbb{R}$ folgendermaßen:
    \begin{center}
      $P_0(\{\{x_1,x_2,\dots\}\in \{0,1\}^\mathbb{N}|x_1=\overline{x}_1,\dots,x_n=\overline{x}_n\})=\frac{1}{2^n}$
    \end{center}
    für $n \in \mathbb{N}$ und $\overline{x}_i \in \{0,1\}$.
  \end{itemize}
\end{example}
Wir werden später zeigen: $\exists !$ Fortsetzung von $P_0$ aus $\mathcal{A}$, genannt $P$ mit:
\begin{center}
  $P\left(\left\{\{x_i\}_{i \in \mathbb{N}} \in \{0,1\}^\mathbb{N}| \lim\limits_{n \to \infty} \frac{1}{n}\sum\limits_{i=1}^n x_i=\frac{1}{2}\right\}\right)=1$
\end{center}
lies: die Wahrscheinlichkeit, dass bei unendliche vielen Würfen gleich oft 0 und 1 geworfen werden ist 1. Dies bedeutet das endlich viele Realisierungen bereits asymptotisches Verhalten festlegen.
% \textbf{Bemerkung 1.1.9}\\\\
\begin{rem}
  Sei $P$ ein Wahrscheinlichkeitsmaß. Wir wissen: $P\left(\stackrel{\cdot}{\bigcup\limits_{i \in \mathbb{N}}}A_i\right)=\sum\limits_{i=1}^\infty P(A_i)$. Dann gilt für $A,B \in \mathcal{A}$:
  \[
  P(B)=P(A)+P(B\setminus A) \Leftrightarrow P(B\setminus A)=P(B)-P(A)
  \]
  Insbesondere gilt für $B=\Omega$: $P(A^c)=P(\Omega)-P(A)=1-P(A)$.
  Desweiteren gilt:
  \begin{eqnarray*}
    P(A\cup B)&=&P(A\cup(B\setminus (A\cap B))\\
    &=&P(A)+(P(B\setminus(A \cap B))\\
    &=& P(A)+P(B)-P(A\cap B)\\ 
    &\leq& P(A)+P(B)
  \end{eqnarray*}
  d.h. P ist subadditiv.
\end{rem}
% \textbf{Definition 1.1.10}\\\\
\begin{defn}  % flashcard-name: additiv, iso- und antiton stetig
  Sei $P:\mathcal{A} \to \mathbb{R}_+$ mit $P(\Omega)=1$.
  \begin{itemize}
  \item[i)] $P$ heißt \index{additiv}\underline{additiv} falls: $P(A\cup B)=P(A)+P(B) \qquad \forall~ A,B\in\mathcal{A} $ mit $A\cap B =\emptyset$ gilt. 
  \item[ii)] $P$ heißt \index{isoton stetig}\underline{isoton stetig}
    falls für alle (isotonen) Folgen:
    \begin{center}
      $A_1 \subseteq A_2 \subseteq A_3 \subseteq \dots$
    \end{center}
    mit $A_n \nearrow \bigcup\limits_{i=1}^\infty A_i$ gilt $P\left(\bigcup\limits_{i=1}^\infty A_i\right)=\lim\limits_{n \to \infty}P(A_n)$.
  \item[iii)] $P$ heißt \underline{antiton stetig} \index{antiton stetig}falls für alle
    (antitonen) Folgen:
    \begin{center}
      $\dots A_i \supseteq A_{i+1} \supseteq A_{i+2} \supseteq \dots$
    \end{center}
    mit $A_n \searrow \bigcap\limits_{i=1}^\infty A_i$ gilt $P\left(\bigcap\limits_{i=1}^\infty A_i\right)=\lim\limits_{n \to \infty}P(A_n)$.
  \end{itemize}
\end{defn}
% \textbf{Satz 1.1.11}\\\\
\begin{prop}  % flashcard-name: Wahrscheinlichkeitsmaß und Stetigkeit
  Sei $P_\mathcal{A}\to \mathbb{R}_+$ normiert ($P(\Omega)=1$). Dann sind folgende Aussagen äquivalent:
  \begin{itemize}
  \item[i)] $P$ ist Wahrscheinlichkeitsmaß \index{Wahrscheinlichkeitsmaß}
  \item[ii)] $P$ ist additiv und isoton stetig
  \item[iii)] $P$ ist additiv und antiton stetig
  \end{itemize}
\end{prop}
\begin{proof}
  (i $\Rightarrow$ ii) P ist $\sigma$-additiv, also auch additiv. Sei
  nun $(A_i)_{i \in \mathbb{N}}$ eine isotone Folge. Wir definieren
  eine Folge $(B_i)_{i \in \mathbb{N}}$, folgendermaßen:
  \begin{center}
    $B_1:=A_1 ~\wedge~ B_k=A_k\setminus A_{k-1} \qquad \forall k \geq
    2 $
  \end{center}
  Dann gilt offenbar $B_k\cap B_l=\emptyset$ für $k\neq l$. Ferner
  gilt:
  \begin{eqnarray*}
    P\left(\bigcup\limits_{i=1}^\infty A_i\right)&=&P\left(\bigcup\limits_{i=1}^\infty B_i\right)\\
    &\overset{\sigma \text{ Additivität}}{=}&\sum\limits_{i=1}^\infty P(B_i)\\
    &=& \lim\limits_{n \to \infty}\sum\limits_{i=1}^n P(B_i)\\ 
    &=& \lim\limits_{n \to \infty} P\left(\bigcup\limits_{i=1}^n B_i\right)\\
    &=& \lim\limits_{n \to \infty} P(A_n)
  \end{eqnarray*}
  (i $\Rightarrow$ iii) Wird Äquivalent zum letzten Punkt bewiesen
  durch Übergang zum Komplement. Sei also $(A_i)_{i \in \mathbb{N}}$
  eine antitone Folge. Dann gilt:
  \[A_n \searrow
  \bigcap\limits_{i=1}^\infty A_i \Leftrightarrow A_n^c \nearrow
  \bigcup\limits_{i=1}^\infty A_i^c\]

  $(A_i^c)_{i \in \mathbb{N}}$ ist also eine isotone Folge. Dann gilt
  mit dem bereits gezeigten:
  \begin{eqnarray*}
    1-P\left(\bigcap\limits_{n=1}^\infty A_n\right)&\overset{\text{Bemerkung 1.1.9}}{=}&P\left(\bigcup\limits_{n=1}^\infty A_n^c\right)\\
    &\overset{(\text{i } \Rightarrow \text{ ii})}{=}&\lim\limits_{n \to \infty}P(A_n^c)\\
    &\overset{\text{Bemerkung 1.1.9}}{=}&\lim\limits_{n \to \infty}(1-P(A_n))\\
    \Rightarrow P\left(\bigcap\limits_{n=1}^\infty A_n\right)=\lim\limits_{n \to \infty}(1-P(A_n)
  \end{eqnarray*} 
  (ii $\Rightarrow$ i) Sei $(A_i)_{i\in \mathbb{N}}$ eine Folge
  paarweiser disjunkter Mengen (Ereignisse). Wir definieren:
  $B_n=\bigcup\limits_{i=1}^n A_i$ und $B=\bigcup\limits_{i=1}^\infty
  A_i$, dann gilt $B_n \nearrow B$ und somit:
  \begin{eqnarray*}
    P\left(\bigcup\limits_{i=1}^\infty A_i\right)=P(B)&=&\lim\limits_{n \to \infty}P\left(\bigcup\limits_{i=1}^n A_i\right)\\
    &\overset{\text{Additivität}}{=}& \lim\limits_{n \to \infty}\sum\limits_{i=1}^n P(A_i)\\
    &=& \sum\limits_{i=1}^\infty P(A_i)
  \end{eqnarray*} 
  Offenbar gilt auch wegen $1=P(\Omega)=P(\emptyset^c)=1-P(\emptyset)$, dass $P(\emptyset)=0$.\\\\
  (iii $\Rightarrow$ i) Folgt wiederum analog durch Übergang zum
  Komplement.
\end{proof}

\section{Diskrete Modelle}
\label{sec:diskrete-modelle}
% \Large{\textbf{1.2 Diskrete Modelle}}\normalsize\\\\

In diesem Abschnitt ist $\Omega$ stets abzählbar. Wir setzen $\mathcal{A}=\mathcal{P}(\Omega)$.
% \textbf{Satz 1.2.1}\\\\
\begin{prop}  % flashcard-name: Wahrscheinlichkeitsmaß (1.2.1)
  Sei $\Omega$ abzählbar und $p: \Omega \to [0,1]$ mit
  $\sum\limits_{\omega \in \Omega}p(\omega)=1$. Dann definiert:
  \begin{center}
    $P(A)=\sum\limits_{\omega \in A} p(\omega)$ für $A\in
    \mathcal{P}(\Omega)$
  \end{center}
  ein Wahrscheinlichkeitsmaß auf $(\Omega,\mathcal{A})$. Tatsächlich ist jedes Maß auf
  $(\Omega,\mathcal{A})$ von dieser Form.
\end{prop}
\begin{proof}
  klar.
\end{proof}
Wir schreiben auch:
\begin{center}
  $P=\sum\limits_{i=1}^\infty \alpha_i\delta_{\omega_i}(*)$ wobei
  $\delta_{\omega_i}(\omega_j)
  \begin{cases}
    1 \text{ für } i=j\\
    0 \text{ sonst}
  \end{cases}$ und $(\omega_i)_{i \in \mathbb{N}}=\Omega$
\end{center}


% \textbf{Beispiel 1.2.2} 
\begin{example}[Laplace Modelle]
  % \textit{Laplace Modelle}\\\\
  Sei $|\Omega|<\infty$, im Laplace-Modell wählen wir:
  \begin{eqnarray*}
    p(\omega)&=&\dfrac{1}{|\Omega|} \qquad \text{Gleichverteilung}\\
    P(A)&=&\dfrac{|A|}{|\Omega|}=\dfrac{\text{Anzahl günstige Fälle}}{\text{Anzahl mögliche Fälle}}
  \end{eqnarray*}
\end{example}
% \textbf{Beispiel 1.2.3}\\\\
\begin{example} \ % itemize in neue Zeile
  \begin{itemize}
  \item[i)] Sei $M=\{1,2,\dots,n\}$. Sei weiter $\Omega=$Menge aller Permutationen auf $M$. Offenbar ist dann $|\Omega|=n!$. Wir wählen die Gleichverteilung auf $\Omega$ und definieren:
    Sei $\omega \in \Omega$ in der Darstellung $\omega=(\omega)_{i=1}^n$. Ein Fixpunkt ist ein $i_0 \in M$ mit $\omega_{i_0}=i_0$.
    Wir stellen uns nun folgende Fragen:
    
    \[P(\text{mindestens ein Fixpunkt})=P\left(\bigcup\limits_{i=1}^n \{\omega|\omega_i=i\}\right)=?\]
    Die Formel von Sylvester:
    \[P\left(\bigcup\limits_{i=1}^nA_i\right)=\sum\limits_{k=1}^n(-1)^{k-1}\sum\limits_{1\leq i_1 \leq \dots \leq i_k \leq n}P(A_{i_1}\cap\dots\cap A_{i_k})\]
    $\Rightarrow P(\text{mindestens ein Fixpunkt})
    =\sum\limits_{k=1}^n(-1)^{k-1}\sum\limits_{1\leq i_1 \leq \dots \leq i_k \leq n}P(\{\omega|\omega_{i_1}=i_1\}\cap\dots\cap \{\omega|\omega_{i_k}=i_k\})$
    Dann ist $|\{\omega|\omega_{i_1}=i_1\}\cap\dots\cap
    \{\omega|\omega_{i_k}=i_k\}|=(n-k)!$, da $k$ Elemente fix gehalten
    werden und die Anzahl der Möglichkeiten die restlichen $(n-k)$
    Elemente zu permutieren gleich $(n-k)!$ ist. Insgesamt folgt dann
    wegen der Gleichverteilung:
    \begin{eqnarray*}
      &=&\sum\limits_{k=1}^n(-1)^{k+1}\sum\limits_{1\leq i_1 \leq \dots \leq i_k \leq n}\dfrac{(n-k)!}{n!}\\
      &=&\sum\limits_{k=1}^n(-1)^{k+1}\binom{n}{k}\dfrac{(n-k)!}{n!}\\
      &=&\sum\limits_{k=1}^n(-1)^{k+1}\dfrac{1}{k!}
    \end{eqnarray*}
    Also ist die Gegenwahrscheinlichkeit
    \[P(\text{ kein Fixpunkt })=1-\sum\limits_{k=1}^n(-1)^{k+1}\dfrac{1}{k!}\text{ für } \overset{n \to \infty}{\rightarrow} e^{-1}\]
    Damit erhalten wir für alle $k \in M$:
    \begin{eqnarray*}
      P(\text{genau k
        Fixpunkte})&=&\underbrace{\dfrac{1}{n!}}_\frac{1}{|\Omega|}\cdot
      \underbrace{\binom{n}{k}}_{\text{k Stellen fest}}\cdot
      \underbrace{(n-k)!\sum\limits_{j=0}^{n-k}\dfrac{(-1)^j}{j!}}_{\text{n-k
          Stellen ohne Fixpunkt}} \\
      &=&\dfrac{1}{k!}\sum\limits_{j=0}^{n-k}\dfrac{(-1)^j}{j!}\text{
        und für }\overset{n \to \infty}{\rightarrow} \dfrac{1}{k!e}
    \end{eqnarray*}
    Dies führt auf die sogenannte Poisson-Verteilung auf $\mathbb{N}$ mit: $\pi_\lambda(\{k\}=\dfrac{\lambda^k}{e^\lambda k!}$
  \item[ii)] Binomialverteilung\\
    Sei $|S|<\infty$ ein Zustandsraum. (z.B. der Münzwurf mit $S=\{0,1\}$ oder der Würfel mit $S=\{1,2,3,4,5,6\}$)
    Sei $S_0 \subsetneq S$ die Menge der Erfolge. Wir setzen:
    $p=\dfrac{|S_0|}{|S|}$
    Gesucht ist die W'keit für $k$ Erfolge bei $n$ Wiederholungen. Sei  dazu:
    $\Omega=\{(x_1,\dots,x_n)|x_i \in S \forall i \in \{1,\dots,n\}\}$
    Dann ist offenbar: $|\Omega|=|S|^n$. Wir wählen auf $\Omega$ die Gleichverteilung. Sei nun $A_k$ das Ereignis 'genau k Erfolge'. Da wir uns im Rahmen des Laplace Modells befinden gilt:
    $P($k Erfolge$)=\dfrac{|A_k|}{|\Omega|}$
    Es gilt: $|A_k|=\binom{n}{k}|S_o|^k|S\setminus S_0|^{n-k}$ und
    damit
    \begin{eqnarray*}
      \dfrac{|A_k|}{|\Omega|}&=&\binom{n}{k}p^k\left(\dfrac{S\setminus S_0|}{|S|}\right)^{n-k}\\\\
      &=&\binom{n}{k}p^k(1-p)^{n-k}
    \end{eqnarray*}
    Für $p=\frac{\lambda}{n}$ erhalten wir:
    \[\binom{n}{k}\left(\dfrac{\lambda}{n}\right)^k\left(1-\dfrac{\lambda}{n}\right)^{n-k}=\dfrac{\lambda^k}{k!}\underbrace{\dfrac{n(n-1)\cdots(n-k+1)}{n^k}}_{\overset{n \to \infty}{\rightarrow} 1}\underbrace{\left(1-\dfrac{\lambda}{n}\right)^{n-k}}_{\overset{n \to \infty}{\rightarrow} e^{-\lambda}}\]
    Wir sehen, dass die Binomialverteilung für $p=\frac{\lambda}{n}$ gegen die Poissonverteilung konvergiert wenn wir mit $n$ gegen $\infty$ gehen. Daher eignet sich die Poissonverteilung für sehr kleine $p$ um die Binomialverteilung zu approximieren.
  \end{itemize}
\end{example}

\paragraph{Konstruktion von Maßen durch Abbildungen:}
Für $\Omega$ abzählbar und $\mathcal{A}=\mathcal{P}(\Omega)$ gilt für jede Abbildung:
\[T:(\Omega,\mathcal{A}) \to \underbrace{(\overline{\Omega},\overline{\mathcal{A}})}_\text{Maßraum}\]
$T^{-1}(\overline{\mathcal{A}})\in \mathcal{A} \qquad \forall \overline{A} \in \overline{\mathcal{A}}$ (Bemerkung: $T$ bildet zwischen $\Omega$ und  $\overline{\Omega}$ ab). Sei nun $P$ ein W'maß auf $(\Omega,\mathcal{A})$, dann definieren wir für $\overline{A} \in \overline{\mathcal{A}}$:
\begin{center}
  $\overline{P}(\overline{A})=P(T^{-1}(\overline{A}))=:T(P)=:P\circ T^{-1}$
\end{center}
Es gilt:
\begin{itemize}
\item[a)] $\overline{P}(\overline{\Omega})=P(T^{-1}(\overline{\Omega}))=P(\Omega)=1$
\item[b)] $\overline{P}(\emptyset)=P(T^{-1}(\emptyset))=P(\emptyset)=0$
\item[c)] Seien $\overline{A}_i\cap \overline{A}_j=\emptyset$ für $i\neq j$ dann gilt:
  \[\overline{P}\left((\bigcup\limits_{i=1}^n \overline{A}_i \right)=P\left(T^{-1}\left(\bigcup\limits_{i=1}^n \overline{A}_i\right)\right)=P\left(\bigcup\limits_{i=1}^n T^{-1}(\overline{A}_i)\right)=\sum\limits_{i=1}^\infty P(T^{-1}(\overline{A}_i))=\sum\limits_{i=1}^\infty \overline{P}(\overline{A}_i)\]
  d.h. also: $\overline{P}$ ist ein Wahrscheinlichkeitsmaß. Das heißt
  $T$ induziert ein Maß auf
  $(\overline{\Omega},\overline{\mathcal{A}})$ mit
  $\overline{\mathcal{P}}=T(P)$:
  \[(\Omega, \mathcal{A}, P)
  \overset{T}{\to}(\overline{\Omega},\overline{\mathcal{A}},\overline{\mathcal{P}})\]

  Wir betrachten nun den allgemeinen Fall, wenn $\mathcal{A}$ nicht notwendig $\mathcal{P}(\Omega)$ ist.
\end{itemize}
\section{Transformation von Wahrscheinlichkeitsräumen}
\label{sec:trafo-wraeume}
% \Large{\textbf{1.3 Transformation von W'Räumen}}\normalsize\\\\

Seien $(\Omega, \mathcal{A})$ und $(\overline{\Omega},\overline{\mathcal{A}})$ messbare Räume und $T: (\Omega, \mathcal{A}) \to (\overline{\Omega},\overline{\mathcal{A}})$.\\\\
% \textbf{Definition 1.3.1}\\\\
\begin{defn}  % flashcard-name: messbar
  Die Abbildung $T$ heißt messbar \index{messbar} (oder
  $\mathcal{A}/\overline{\mathcal{A}}$-messbar) wenn gilt:
  \begin{center}
    $T^{-1}(\overline{A}) \in \mathcal{A} \qquad \forall \overline{A}
    \in \overline{\mathcal{A}}$
  \end{center}
\end{defn}
% \textbf{Bemerkung 1.3.2}\\\\
\begin{rem} \
  \begin{itemize}
  \item[i)] Sei
    $\overline{\mathcal{A}}=\sigma(\overline{\mathcal{A}}_0)$ für
    $\overline{\mathcal{A}}_0 \subset
    \mathcal{P}(\overline{\Omega})$. Dann gilt:
    \begin{center}
      $T$ messbar $\Leftrightarrow T^{-1}(\overline{A}) \in
      \mathcal{A} \qquad \forall \overline{A} \in
      \overline{\mathcal{A}}_0$
    \end{center}
    z.B. gilt für $\overline{\Omega}=\mathbb{R}$ und
    $\mathcal{A}=\mathcal{B}(\mathbb{R})$:
    \begin{center}
      $T$ messbar $\Leftrightarrow \{\omega|T(\omega)\leq c\} \in
      \mathcal{A} \qquad \forall c \in \mathbb{R}$
    \end{center}
  \item[ii)] Verknüpfungen messbarer Abbildungen sind messbar
  \end{itemize}
\end{rem}
% \textbf{Satz 1.3.3}\\\\
\begin{prop} % flashcard-name: induziertes Wahrscheinlichkeitsmaß
  Sei $T:(\Omega, \mathcal{A})\to(\overline{\Omega},\overline{\mathcal{A}})$ messbar und $P$ ein Wahrscheinlichkeitsmaß auf $(\Omega, \mathcal{A})$. Dann definiert $\overline{P}=T(P)$ ein Wahrscheinlichkeitsmaß auf $(\overline{\Omega},\overline{\mathcal{A}})$.\\
  1.3.4 - 1.3.5 siehe Online-Skript. \url{http://horst.qfl-berlin.de/files/StochastikI_2.pdf}
\end{prop}
% \textbf{Beispiel 1.3.6} 
\begin{example}[Fortsetzung von Bsp. 1.1.8]
  Wir konstruieren ein Wahrscheinlichkeitsmaß auf
  $\overline{\Omega}:=\{0,1\}^\mathbb{N}$. Dazu sei $\Omega=[0,1]$,
  $\mathcal{A}=\mathcal{B}(\mathbb{R})$ und $P$ das Lebesgue-Maß. Wir
  setzen:
  \begin{eqnarray*}
    X_i:\overline{\Omega} &\to & \{0,1\}\\
    (\overline{\omega}_j)_{j \in \mathbb{N}} &\mapsto & \overline{\omega}_i
  \end{eqnarray*}
  Sei weiter $\overline{\mathcal{A}}$ die von der Projektionsabbildung
  erzeugte $\sigma$-Algebra:
  $\overline{\mathcal{A}}=\sigma(\{\overline{\omega}|X_i(\overline{\omega})=1$
  für $i\in \mathbb{N})$. Das Ziel ist nun $\overline{P}$ auf
  $(\overline{\Omega},\overline{\mathcal{A}})$ mittels $P$ zu
  definieren, derart dass $\overline{P}$ die 'richtigen
  Randverteilungen' hat:
  \begin{center}
    $\overline{P}(\{\overline{\omega}|X_1(\overline{\omega})=x_1,\dots,X_n(\overline{\omega})=x_n\})=\dfrac{1}{2^n}$
  \end{center}
  Für feste $(x_1,\dots,x_n) \in \{0,1\}^n$. Sei dazu:
  \begin{eqnarray*}
    T: \Omega &\to& \overline{\Omega}\\
    \omega &\mapsto & (T_1\omega, T_2\omega,\dots)\\\\
    \text{wobei}\\\\
    T_1(\omega)&=&
    \begin{cases}
      0 \text{ falls } \omega \in \left[0,\frac{1}{2}\right)\\
      1 \text{ falls } \omega \in \left(\frac{1}{2},1\right]
    \end{cases}\\\\
    T_2(\omega)&=&
    \begin{cases}
      0 \text{ falls } \omega \in \left[0,\frac{1}{4}\right)\cup \left(\frac{1}{2},\frac{3}{4}\right]\\
      1 \text{ falls } \omega \in
      \left(\frac{1}{4},\frac{1}{2}\right]\cup\left(\frac{3}{4},1\right]
    \end{cases}\\\\
    \vdots
  \end{eqnarray*}
  Dann ist $T_i=X_i\circ T$. Wegen $T^{-1}(\underbrace{\{X_i=1\}}_{\in
    \text{ Erzeuger}})=\{T_i=1\}$ und $\{T_i=1\}=$ Vereinigung endlich
  vieler Intervalle $\in \mathcal{B}([0,1])$ ist $T$ messbar. D.h. wir
  können definieren:
  \begin{center}
    $\overline{P}(\cdot)=P\circ T^{-1}(\cdot)$
  \end{center}
  Wir testen die Randverteilungen: für $(x_1,\dots,x_n) \in \{0,1\}^n$ gilt
  \[\overline{P}(X_1=x_1,\dots,X_n=x_n)=\overline{P}\left(\bigcap\limits_{i=1}^n\{X_i=x_i\}\right)=P\left(T^{-1}\left(\bigcap\limits_{i=1}^n\{X_i=x_i\}\right)\right)\]
  z.B. für $n=2$ und $x_1=0$, $x_2=1$: $T^{-1}(\{X_1=0\}\cap\{X_2=1\})=(\frac{1}{4},\frac{1}{2}]$\\
  Allgemeiner: $T^{-1}\left(\bigcap\limits_{i=1}^n\{X_i=x_i\}\right)=$ Intervall der Länge $2^{-n}$ d.h.:
  \[P\left(T^{-1}\left(\bigcap\limits_{i=1}^n\{X_i=x_i\}\right)\right)=2^{-n}\]
\end{example}

\section{Zufallsvariablen}
\label{sec:zufallsvariablen}
% \Large{\textbf{1.4 Zufallsvariablen}}\normalsize\\\\

Sei $(\Omega,\mathcal{A},P)$ ein Wahrscheinlichkeitsraum.
% \textbf{Definition 1.4.1}\\\\
\begin{defn} % flashcard-name: messbare Abbildung
  Eine messbare Abbildung\index{messbare Abbildung}
  \begin{eqnarray*}
    X:(\Omega,\mathcal{A}) \to (\mathbb{R},\mathcal{B}(\mathbb{R}))\\
    \text{oder}\\
    X:(\Omega,\mathcal{A}) \to (\overline{\mathbb{R}},\mathcal{B}(\overline{\mathbb{R}}))\\
  \end{eqnarray*}
  wobei $\overline{\mathbb{R}}=\mathbb{R}\cup\{\pm \infty \}$, heißt Zufallsvariable. Das Maß $P^X(\cdot)=P\circ X^{-1}$ heißt Verteilung von $X$ unter $P$.
\end{defn}
% \textbf{Bemerkung 1.4.2}\\\\
\begin{rem}
  \begin{itemize}
  \item[i)] $X: \Omega \to \overline{\mathbb{R}}$ ist eine ZV (=Zufallsvariable) falls $\{X\leq c\} \in \mathcal{A}$ für alle $c \in \mathbb{Q}$
  \item[ii)] Ist $X$ eine Zufallsvariable und $h:\overline{\mathbb{R}} \to \overline{\mathbb{R}}$ messbar, so auch $h\circ X$. Bsp.:$h(x)=|x|, h(x)=x^2, h(x)=e^x$
  \item[iii)] Sind $X_1,X_2,\dots$ Zufallsvariablen, so auch:
    \begin{itemize}
    \item $\sum\limits_{i=1}^\infty \alpha_i X_i$, insofern dies Sinn
      macht, da $\infty-\infty$ unbestimmt ist.
    \item $\sup\limits_{i\in \mathbb{N}}$, $\{\sup\limits_{i \in
        \mathbb{N}} X_i \leq c\}=\bigcap\limits_{i \in
        \mathbb{N}}\{X_i \leq c\}$
    \item $\inf\limits_{i \in \mathbb{N}} X_i$
    \item $\liminf\limits_{i \to \infty} X_i, \limsup\limits_{i \to
        \infty} X_i$
    \end{itemize}
  \end{itemize}
  $ $
\end{rem}
\paragraph{Typischer Spezialfall}
\begin{itemize}
\item[i)] Indikatorfunktionen\index{Indikatorfunktion}: für $A \in \mathcal{A}$ sei
  \begin{center}
    $\1_A(\omega)=
    \begin{cases}
      1 \text{ für } \omega \in A\\
      0 \text{ für } \omega \notin A
    \end{cases}$
  \end{center}
\item[ii)] Elementare Zufallsvariablen\index{elementare Zufallsvariable}
  \begin{center}
    $X=\sum\limits_{i=1}^n \alpha_i \1_{A_i}$ für $A_i \in \mathcal{A},
    \alpha_i \in \mathbb{R}$
  \end{center}
\end{itemize}
% \textbf{Satz 1.4.3}\\\\
\begin{prop} % flashcard-name: Zufallsvariable und isotone Folgen 
  Sei $X$ eine Zufallsvariable \index{Zufallsvariable}
  \begin{itemize}
  \item[i)] $X$ ist von der Form $X=X^+-X^-$ wobei $X^+=\max\{X,0\}$ und $X^-=\max\{-X,0\}$
  \item[ii)] Für jede Zufallsvariable $X\geq0$ existiert eine isotone $X_n \nearrow X$ von elementaren Zufallsvariable.
  \end{itemize}
\end{prop}
% \textit{Beweis}\\\\
\begin{proof} \
  \begin{itemize}
  \item[i)] klar
  \item[ii)] Definiere:
    $X_n=\sum\limits_{k=0}^{n2^n-1}k2^{-n}\1_{\{k2^{-n}\leq X <
      (k+1)2^{-n}\}}+n\1_{\{X\geq n\}}$. Dann ist $X_n$ elementar und
    $X_n \nearrow X$.
  \end{itemize}
\end{proof}
Ziel ist nun den Erwartungswert von $X$ zu definieren:
\begin{eqnarray*}
  \mathbb{E}[X]=\mathbb{E}X:&=&\int\limits_\Omega X(\omega)dP(\omega)\\
  &=&\int\limits_{X(\Omega)}x dP^X(dx)
\end{eqnarray*} 
Klar für $X=\1_A$ gilt $\mathbb{E}[\1_A]=P(A)$.

% \textbf{Definition 1.4.4}\\\\
\begin{defn} \index{Normaldarstellung} % flashcard-name: Normaldarstellung
  Sei $X$ eine reelwertige Zufallsvariable mit
  \begin{center}
    $X=\sum\limits_{i=1}^n\alpha_i\1_{A_i}$ (*) mit $\bigcup_i^\cdot
    A_i=\Omega$
  \end{center}
  so heißt (*) eine Normaldarstellung. Normaldarstellungen sind nicht eindeutig, es gilt jedoch:
\end{defn}
% \textbf{Lemma 1.4.5}\\\\
\begin{lem}  % flashcard-name: Summen und Grenzwerte von Normaldarstellungen
  Seien $\sum\limits_{i=1}^n \alpha_i \1_{A_i}$ und
  $\sum\limits_{j=1}^m\beta_j\1_{B_j}$ Normaldarstellungen von
  $X$. Dann gilt:
  \begin{center}
    $\sum\limits_{i=1}^n \alpha_i
    \1_{A_i}=\sum\limits_{j=1}^m\beta_j\1_{B_j}$
  \end{center}
\end{lem}
% \textit{Beweis}
\begin{proof}
  Es gilt: 
  \begin{align*}
    A_i&=\bigcup_j^\cdot (A_i\cap B_j)\\
    B_j&=\bigcup_i^\cdot (A_i\cap B_j)\\
    \intertext{D.h. es gilt: } 
    P(A_i)&=\sum\limits_{j=1}^mP(A_i\cap B_j)\\
    P(B_j)&=\sum\limits_{i=1}^nP(A_i\cap B_j)\\
    \sum\limits_{i=1}^n\alpha_iP(A_i)&=\sum\limits_{i,j}\alpha_iP(A_i\cap B_j)\\
    \sum\limits_{j=1}^n\beta_iP(B_i)&=\sum\limits_{i,j}\beta_jP(A_i\cap B_j)
  \end{align*}
  Auf $P(A_i\cap B_j)>0$ ist $A_i\cap B_j \neq \emptyset$ daher gilt
  dort $\alpha_i=\beta_j$. Auf $P(A_i\cap B_j)=0$ passiert
  nichts. Also gilt:
  \begin{eqnarray*}
    \sum\limits_{i,j}\beta_jP(A_i\cap B_j)&=&\sum\limits_{i,j}\alpha_iP(A_i\cap B_j)\\
    &=&\sum\limits_{i=1}^n\alpha_i\sum\limits_{j=1}^mP(A_i\cap B_j)\\
    &=&\sum\limits \alpha_i P(A_i)
  \end{eqnarray*}
\end{proof}
% \textbf{Definition 1.4.6}\\\\
\begin{defn} \index{Noramldarstellung} \index{Erwartungswert}  % flashcard-name: Erwartungswert
  Ist $X$ eine Zufallsvariable mit Normaldarstellung
  \begin{center}
    $X=\sum\limits_{i=1}^n\alpha_i\1_{A_i}$
  \end{center}
  so heißt: $\mathbb{E}[X]:=\sum\limits_{i=1}^n\alpha_iP(A_i)$ der \underline{Erwartungswert}.
\end{defn}
% \textbf{Satz 1.4.7} 
\begin{prop}[Eigenschaften des Erwartungswertes] \index{Erwartungswert}
  $\mathbb{E}[\cdot]$ ist ein lineares monotones Funktional:
  \begin{itemize}
  \item $\mathbb{E}[\alpha X]=\alpha \mathbb{E}[X]$
  \item Sei $X=\sum\limits_{i=1}^n\alpha_i \1_{A_i}$ und
    $Y=\sum\limits_{j=1}^m\beta_j\1_{B_j}$. Dann gilt ebenso:
    $X=\sum\limits_{i,j}\alpha_i\1_{A_i\cap B_j}$ und
    $Y=\sum\limits_{i,j}\beta_i\1_{A_i\cap B_j} \Rightarrow
    X+Y=\sum\limits_{i,j}(\alpha_i+\beta_j)\1_{A_i\cap
      B_j}$. D.h. $\mathbb{E}[X+Y]$ ist definiert und es gilt:
    \begin{eqnarray*}
      \mathbb{E}[X+Y]&=& \sum\limits_{i,j}(\alpha_i+\beta_j)P(A_i\cap B_j)\\
      &=&\sum\limits_{i=1}^n\alpha_i P(A_i)+\sum\limits_{j=1}^m\beta_jP(B_j)\\
      &=&\mathbb{E}[X]+\mathbb{E}[Y]
    \end{eqnarray*} 
  \item Sei $X\leq Y$. Sei weiter: $Z=Y-X\geq 0$. Dann gilt:
    \[\mathbb{E}[X+Z]=\mathbb{E}[Y]=\mathbb{E}[X]+\underbrace{\mathbb{E}[Z]}_{\geq
      0} \Rightarrow \mathbb{E}[Y]\geq \mathbb{E}[X]\]
  \end{itemize}
\end{prop}
Ziel: Definiere $\mathbb{E}X$ für $X\geq 0$ via Approximation durch elementare Zufallsvariablen $X_n\nearrow X$ und $\mathbb{E}X:=\sup\limits_{n\in \mathbb{N}}\mathbb{E}X_n=\lim\limits_{n\to \infty} \mathbb{E}X_n$
% \textbf{Lemma 1.4.8}\\\\
\begin{lem}\label{lem:erwartungswertabschaetzung} \index{Erwartungswertabschätzung}  % flashcard-name: Was muss gelten für $\mathbb{E}X\leq \mathbb{E}X_n$
  Seien $(X_n)_{n\in \mathbb{N}}$ und $X$ nichtnegative elementare Zufallsvariablen
  $X_n\nearrow$ und $X\leq \sup\limits_{n\in \mathbb{N}} X_n$. Dann
  gilt:
  \begin{center}
    $\mathbb{E}X\leq \mathbb{E}X_n$
  \end{center}
\end{lem}
% \textbf{Korollar 1.4.9}\\\\
\begin{cor}  % flashcard-name: Was muss gelten, damit  $\sup\limits_{n\in \mathbb{N}}\mathbb{E} X_n=\sup\limits_{n\in \mathbb{N}}\mathbb{E} Y_n$ gilt?
  Seien $(X_n)(Y_n)$ isotone Folgen elementarer Zufallsvariablen mit
  \begin{center}
    $\sup\limits_{n\in \mathbb{N}} X_n=\sup\limits_{n\in \mathbb{N}}
    Y_n$
  \end{center}
  Dann gilt:
  \begin{center}
    $\sup\limits_{n\in \mathbb{N}}\mathbb{E} X_n=\sup\limits_{n\in
      \mathbb{N}}\mathbb{E} Y_n$
  \end{center}
\end{cor}
% \textit{Beweis}\\\\
\begin{proof}
  Für alle $m\in \mathbb{N}$ gilt:
  \begin{eqnarray*}
    X_m&\leq\sup\limits_{n\in \mathbb{N}} X_n=\sup\limits_{n\in \mathbb{N}} Y_n\\
    Y_m&\leq\sup\limits_{n\in \mathbb{N}} Y_n=\sup\limits_{n\in \mathbb{N}} X_n
  \end{eqnarray*}
  Nach Lemma \ref{lem:erwartungswertabschaetzung} gilt dann:
  \begin{eqnarray*}
    \mathbb{E}X_m\leq \sup\limits_{n\in \mathbb{N}}\mathbb{E} Y_n
  \end{eqnarray*}
  \text{und}
  \begin{eqnarray*}
    \mathbb{E}Y_m\leq \sup\limits_{n\in \mathbb{N}}\mathbb{E} X_n
  \end{eqnarray*}
  Nehmen wir nun sup über $m \in \mathbb{N}$:
  \begin{eqnarray*}
    \sup\limits_{n\in \mathbb{N}}\mathbb{E}X_m &\leq &\sup\limits_{n\in \mathbb{N}}\mathbb{E}Y_n\\
    \sup\limits_{n\in \mathbb{N}}\mathbb{E}Y_m &\leq &\sup\limits_{n\in \mathbb{N}}\mathbb{E}X_n
  \end{eqnarray*}
  Damit folgt die Behauptung. 
\end{proof}
% \textit{Beweis von Lemma 1.4.8}
\begin{proof}[Beweis von Lemma \ref{lem:erwartungswertabschaetzung}]
  Sei $X=\sum\limits_{i=1}^n\alpha_i\1_{A_i}$ mit $\alpha_i \geq 0$,
  $A_i \in \mathcal{A}$. Sei weiter $\alpha \in (0,1)$, dann gilt:
  \begin{center}
    $B_n=\{\omega \in \Omega|X_n(\omega)\geq \alpha
    X(\omega)\}=:\{X_n\geq \alpha X(\omega)\}\nearrow \Omega$
  \end{center}
  wegen $X \leq \sup\limits_{n\in \mathbb{N}} X_n$ und $B_n \in
  \mathcal{A}$ (da alles diskret ist). Dann gilt offenbar auch:
  \begin{center}
    $X_n \geq \alpha X\1_{B_n} \qquad \forall n \in \mathbb{N}$ (**)
  \end{center}
  nach Definition von $B_n$ und $X_n\geq 0$. Also:
  \begin{center}
    $\mathbb{E}X=\sum\limits_{i=1}^n\alpha_i P(A_i)=\lim\limits_{n \to
      \infty} \sum\limits_{i=1}^n\alpha_i P(A_i\cap B_n)$
  \end{center}
  da $A_i\cap B_n \nearrow A_i$ und somit
  \begin{center}
    $\mathbb{E}X=\lim\limits_{n \to \infty}[\1_{B_n}X]$
  \end{center}
  Ferner gilt
  \begin{center}
    $\alpha
    \mathbb{E}[\1_{B_n}X]\overset{\text{Linearität}}{=}\mathbb{E}[\alpha
    \1_{B_n}X]\overset{\text{Monotonie}+(**)}{\leq}\mathbb{E}X_n\leq\sup\limits_{n\in
      \mathbb{N}}\mathbb{E}X_n$
  \end{center}
  und $\alpha \mathbb{E}X\leq \sup\limits_{n\in \mathbb{N}}\mathbb{E}X_n$ da $\1_{B_n}X\nearrow X$. Wegen $\alpha \in (0,1)$ beliebig folgt die Behauptung.
\end{proof}
Nach Korollar 1.4.9 ergibt folgende Definition Sinn:
% \textbf{Definition 1.4.10}\\\\
\begin{defn} \index{Erwartungswert} % flashcard-name: Erwartungswert von $X$
  Sei $X\geq 0$ Zufallsvariable auf $(\Omega,\mathcal{A},P)$ und $X_n$ eine Folge
  elementarer Zufallsvariablen mit $X_n\nearrow X$. Dann heißt:
  \begin{center}
    $\mathbb{E}X=\sup\limits_{n\in
      \mathbb{N}}\mathbb{E}X_n=\lim\limits_{n \to
      \infty}\mathbb{E}X_n$
  \end{center}
  Erwartungwert von $X$.
\end{defn}
\paragraph{Eigenschaften 1.4.11}
Der Erwartungswert ist ein lineares monotones Funktional. Ist $\Omega<\infty$ so gilt
\begin{center}
  $\mathbb{E}X=\sum\limits_{\alpha \in \Omega}\alpha P(\{\omega \in \Omega|X(\omega)=\alpha\})$
\end{center}
% \textbf{Beispiel}\\\\
\begin{example} \ 
  \begin{itemize}
  \item[(i)] Fairer MW, $\Omega=\{0,1\}^{\mathbb{N}}$\\
    Sei $T=\min\{k\in \mathbb{N}|\omega_k=1\}$ die Wartezeit auf die erste "1".
    Es gilt $P(T=k)=P(X_1(\omega)=0,\dots,X_{k-1}(\omega)=0,X_k(\omega)=1)$ wobei $X_i:\Omega \to \{0,1\}$ wieder die Projektionsabbildung auf die $i$-te Koordinate bezeichnet. Dann ist offenbar:
    \[P(T=k)=P(T\geq k+1)=2^{-k}\] 
    d.h. $P(T=0)=0$. Also gilt:
    \[\mathbb{E}(T)=\sum\limits_{k=1}^\infty kP(T=k)=\sum\limits_{k=1}^\infty k2^{-k}=2\]
    denn: \[\dfrac{q}{1-q}=\sum\limits_{k=1}^\infty q^k \Rightarrow \dfrac{d}{dq}\dfrac{q}{1-q}=\dfrac{d}{dq}\sum\limits_{k=1}^\infty q^k=\sum\limits_{k=1}^\infty \dfrac{d}{dq} q^k=\sum\limits_{k=1}^\infty kq^{k-1} \hfill (*)\]
    und \[\dfrac{d}{dq}\dfrac{q}{1-q}=\dfrac{1}{(1-q)^2} (=4 \text{ für } q=\dfrac{1}{2})\]
    Durch Multiplikation mit $q$ erhält man in (*) die gesuchte Reihe.
  \item[(ii)] Erwartungswert für die Anzahl der Erfolge bei $n \in \mathbb{N}$ Wiederholungen. Sei $S_n=\sum\limits_{i=1}^nX_i$.
    \begin{itemize}
    \item[a)]
      $\mathbb{E}S_n=\sum\limits_{k=1}^n\mathbb{E}X_i=\frac{n}{2}$
    \item[b)]\begin{eqnarray*}
        \mathbb{E}S_n&=&\sum\limits_{k=1}^nkP(S_n=k)\\
        &=& \sum\limits_{k=1}^nk\binom{n}{k}2^{-n}\\
        &=& n 2^{-n} \sum\limits{k=1}^n\dfrac{(n-1)!}{(k-1)!(n-1-(k-1))!}\\
        &=& n 2^{-n} \sum\limits{k=1}^n \binom{n-1}{k} (*)
      \end{eqnarray*}
      (*) ist dabei die binomische Formel $(x+y)^n=\sum\limits_{k=0}^n\binom{n}{k}x^{n-k}y^k$ für $x=y=1$, also $2^n=\sum\limits_{k=0}^n\binom{n}{k}$. Einsetzen in (*) ergibt: $(*)=n2^{-n}2^{n-1}=\frac{n}{2}$.
    \end{itemize}
  \end{itemize}

\end{example}
% \textbf{Satz 1.4.12} \textit{Satz von der monotonen Konvergenz}\\\\
\begin{prop}[Satz von der monotonen Konvergenz]
  Seien $X_n\geq 0$ Zufallsvariablen $(n \in \mathbb{N})$ mit $X_n \nearrow X$,
  dann gilt:
  \begin{center}
    $\mathbb{E}X_n \nearrow \mathbb{E}X$
  \end{center}
\end{prop}
% \textbf{Korollar 1.4.13}\\\\
\begin{cor} % flashcard-name: Vertauschbarkeit von Summen über Erwartungswerte
  Seien $X_n \geq 0$ Zufallsvariablen. Dann gilt:
  \begin{center}
    $\mathbb{E}[\sum\limits_{i=1}^\infty
    X_i]=\sum\limits_{i=1}^\infty\mathbb{E}[X_i]$
  \end{center}
\end{cor}
% \textit{Beweis}\\\\
\begin{proof}
  Folgt aus Satz 1.4.12 mit $Y_n=\sum\limits_{i=1}^nX_i \nearrow Y= \sum\limits_{i=1}^\infty X_i$ 
\end{proof}
% \textbf{Definition 1.4.14}\\\\
\begin{defn} \index{integrierbar} % flashcard-name: Erwartungswert
  Für eine Zufallsvariable $X:\Omega \to \mathbb{R}$ definieren wir den
  Erwartungswert durch:
  \begin{center}
    $\mathbb{E}X=\mathbb{E}X^+-\mathbb{E}X^-$
  \end{center}
  sofern $\min\{\mathbb{E}X^+,\mathbb{E}X^-\}<\infty$.
  Wir setzen
  \[p\mathcal{L}^1:=\{X:\Omega \to \mathbb{R}\] Zufallsvariable mit $\mathbb{E}[|X|]< \infty \}$
  und $\Vert X\Vert_1:=\mathbb{E}[|X|]$. Dann heißt $X$ integrierbar, falls $\Vert X \Vert_1 < \infty$.
  Man beachte, dass aus $\Vert X \Vert_1=0$ nicht $X=0$ folgt. Sei daher:
  $L^1=\mathcal{L}/\sim$ wobei $X\sim Y \Leftrightarrow P(X=Y)=1$
\end{defn} % flashcard-name: Was muss gelten damit ein Vektorraum und eine Halbnorm ein Banachraum ist?
% \textbf{Satz 1.4.15}\\\\
\begin{prop}
  $\mathcal{L}^1$ ist ein Vektorraum, $\Vert \cdot \Vert_1$ ist eine Halbnorm und $L^1$ ist ein Banachraum mit der Norm $\Vert \cdot \Vert_1$.
\end{prop}
% \textbf{Satz 1.4.16} \textit{Lemma von Fatou}\\\\
\begin{prop}[Lemma von Fatou]
  Seien $X_n\geq 0$ Zufallsvariablen (Es reicht auch $X_n \geq Y \in L^1$). Dann
  gilt:
  \begin{center}
    $\mathbb{E}[\liminf\limits_{n \to \infty} X_n]\leq
    \liminf\limits_{n \to \infty} \mathbb{E}[X_n]$
  \end{center}
\end{prop}
% \textbf{Bemerkung 1.4.17}
\begin{rem} 
  Es ist möglich, dass $\mathbb{E}[\liminf\limits_{n \to \infty} X_n] < \liminf\limits_{n \to \infty} \mathbb{E}[X_n]$ selbst wenn alle Grenzwerte existieren.\\
  Fairer MW: Verdoppeln des Einsatzes, bis die erste ,,1''
  fällt. Einsatz in Runde $n$:
  \begin{center}
    $X_n=2^{n-1}\1_{\{T>n-1\}}$
  \end{center}
  Wir hatten gesehen, dass gilt $P(T=\infty)=0$. Mit anderen Worten:
  \begin{center}
    $X_n(\omega) \to 0$ P-fast sicher
  \end{center}
  D.h. $\mathbb{E}[\liminf\limits_{n \to \infty} X_n]=\mathbb{E}[\lim\limits_{n \to \infty} X_n]=\mathbb{E}[0]=0$.\\
  Gleichzeitig ist aber: $\mathbb{E}[X_n]=2^{n-1}P(T>n-1)=1$\\
\end{rem}

\section{Ungleichungen}
\label{sec:ungleichungen}
% \Large{\textbf{1.5 Ungleichungen}}\normalsize\\\\\\
% \textbf{Satz 1.5.1}\\\\

\begin{prop} \index{Zufallsvariable} % flashcard-name: Wie kann man ein Wahrscheinlichkeitsmaß abschätzen?
  Sei $X$ eine Zufallsvariable, $h$ eine auf $X(\Omega)$ isotone, nicht negative
  Funktion. Dann gilt für alle $c \in X(\Omega)$:
  \begin{center}
    $h(c)P(X\geq c) \leq \mathbb{E}[h(X)]$
  \end{center}
\end{prop}
\begin{proof}
  Da $h$ isoton gilt,
  \begin{eqnarray*}
    h(c)P(X\geq c) &\leq & h(c)P(h(X)\geq h(c))\\
    &=& h(c) \mathbb{E}(\1_{\{h(X)\geq h(c)\}})\\
    &=& \mathbb{E}(h(c)(\1_{\{h(X)\geq h(c)\}})\\
    &\leq &\mathbb{E}(h(X)(\1_{\{h(X)\geq h(c)\}})\\
    &\leq &\mathbb{E}(h(X))
  \end{eqnarray*}
\end{proof}
\paragraph{1.5.2 Spezialfälle}
\begin{itemize}
\item[1)] Für $h(X)=X ~(X\geq)$ gilt
  \[P(|X|\geq c) \leq \frac{1}{c}\mathbb{E}(|X|) \qquad \forall c >0 (*)\]
  Insbesondere:
  \begin{center}
    $\mathbb{E}(|X|)=0 \Leftrightarrow P(|X|=0)=1 $
  \end{center}
  % \textit{Beweis}\\\\
  \begin{proof} \
    "'$\Leftarrow$"' klar\\
    "'$\Rightarrow$"' Betrachte (*) für $c=\frac{1}{n}$
    \begin{center}
      $P\underbrace{\left(|X|>\frac{1}{n}\right)}_{A_n\nearrow} \leq
      n\mathbb{E}|X|=0$
    \end{center}
    Also
    \begin{center}
      $P(|X|>0)=\lim\limits_{n \to \infty}P\left(X\geq
        \frac{1}{n}\right)=0$
    \end{center}
    Analog beweist man $\mathbb{E}(|X|)<\infty \Rightarrow
    P(|X|<\infty)=1$.
  \end{proof}
  Für ein Ereignis $\{X\in A\}$ mit $P(X \in A)=1$ schreiben wir P-fast sicher oder P-fs.
\item[2)] Cebysev-Ungleichung\\
  Für $h(x)=x^2$ und $X \in \mathcal{L}^1$ gilt
  \begin{center}
    $P(|X-\mathbb{E}X|)\geq c) \leq
    \frac{1}{c^2}\mathbb{E}((X-\mathbb{E}X)^2)$
  \end{center}
\end{itemize}
% \textbf{Satz 1.5.3} \textit{Jensen-Ungleichung}\\\\
\begin{prop}[Jensen-Ungleichung] \index{Jensen-Ungleichung}
  Sei $I\in \mathbb{R}$ ein offenes Intervall, $X \in \mathcal{L}^1$
  mit $X(\Omega)\subseteq I$. Sei weiter $h:I\to\mathbb{R}$ konvex,
  $h\circ X \in \mathcal{L}^1$ und $X$ nicht konstant. Dann gilt:
  \begin{center}
    $h(\mathbb{E}X)\leq \mathbb{E}(h(X))$
  \end{center}
\end{prop}
% \textit{Beweis}\\\\
\begin{proof} \ 
  \begin{itemize}
  \item[a)] Wir zeigen zunächst $\mathbb{E}X \in I$. Sei also
    \begin{center}
      $X(\omega)< \alpha \qquad \omega \in \Omega$
    \end{center}
    Dann auch
    \begin{center}
      $\mathbb{E}X\leq \alpha$
    \end{center}
    Es gilt sogar $\mathbb{E}X < \alpha$, da aus $\mathbb{E}X=\alpha$
    folgt
    \begin{center}
      $\mathbb{E}(\alpha-X)=\alpha-\mathbb{E}X=0$
    \end{center}
    Also $X(\omega)\equiv \alpha$ (d.h. $X$ ist konstant: Widerspruch!). Analog folgt $X(\omega)>\beta \qquad \forall \omega \in \Omega$ auch $\mathbb{E}X> \beta$. Also $\mathbb{E}X \in I$.
  \item[b)] Die Funktion $h$ ist konvex, also stetig und somit
    messbar. Damit ist aber auch $h\circ X$ messbar. Da $h$ konvex
    ist, existieren für alle $x \in I$ die links- und rechtsseitigen
    Ableitungen $h_\pm'(x)$ in $X$. Ferner gilt:
    \begin{center}
      $h(y)\geq h(x)+h_+'(x)(y-x)$
    \end{center}
    für gegebenes $y \in I$ und alle $x \in I$, mit Gleichheit für
    $x=y$. Also:
    \begin{center}
      $h(y)=\sup\limits_{x \in I}\{h(x)+h_+'(x)(y-x)\} \qquad (**)$
    \end{center}
    Für $y=X(\omega)$ gilt dann $h(X(\omega))\geq h(x)+h_+'(x)(X(\omega)-x)$ und damit für $h\circ X \in \mathcal{L}^1$ also:
    \begin{center}
      $\mathbb{E}(h\circ X) \geq h(x)+h_+'(x)(\mathbb{E}X-x) \qquad
      \forall x \in I$
    \end{center}
    Also auch
    \begin{center}
      $\mathbb{E}(h\circ X)\geq \sup\limits_{x \in
        I}\{h(x)+h_+'(x)(\mathbb{E}X-x)\}\overset{(**)}{=}h(\mathbb{E}X)$
    \end{center}
    da $\mathbb{E}X\in I$
  \end{itemize}
\end{proof}
\paragraph{Spezialfälle 1.5.4} \ 
\begin{itemize}
\item[i)] Für $h(x)=x^2$ gilt: $(\mathbb{E}X)^2\leq \mathbb{E}(X^2)$
\item[ii)] allgemeiner: für $p,q>0$ mit $\frac{q}{p}>1$ gilt
  \begin{center}
    $(\mathbb{E}|X|^p)^\frac{q}{p} \leq \mathbb{E}(|X|^q)$
  \end{center} 
  Ziehen wir auf beiden Seiten die $q$-te Wurzel, gilt
  \begin{center}
    $\underbrace{(\mathbb{E}|X|^p)^\frac{1}{p}}_{=:\Vert X\Vert_p}\leq\underbrace{(\mathbb{E}(|X|^q))^\frac{1}{q}}_{=:\Vert X\Vert_q}$ 
  \end{center}
\end{itemize}
% \textbf{Definition 1.5.5}\\\\
\begin{defn} \index{$L^p=\mathcal{L}^p/\sim$} % flashcard-name: $L^p=\mathcal{L}^p/\sim$
  Für $p>0$ sei $\mathcal{L}^p=\{X:\Omega \to \mathbb{R}$ mit $\Vert X\Vert_p<\infty\}$ und $L^p=\mathcal{L}^p/\sim$.
\end{defn}

\section{(Co-) Varianz}
\label{sec:varianz}
% \Large{\textbf{1.6 (Co-) Varianz}}\normalsize\\\\\\

Ausblick: Wiederholte Experimente
\begin{itemize}
\item Zufall mittelt sich raus (?)
  \begin{center}
    $\frac{1}{n}\sum\limits_{i=1}^nX_i\approx m$ für $ n\to \infty
    \qquad (\mathbb{E}X_i=m)$
  \end{center}
  in welchem Sinn?\\
  $\Rightarrow$ Konvergenz von Zufallsvariablen
\item Wie gut ist diese Approximation? (Zentraler Grenzwertsatz)
\end{itemize}

% \textbf{Definition 1.6.1}\\\\
Sei $X \in \mathcal{L}^1$, dann heißt 
\begin{center}
  $Var(x)=\mathbb{E}((X-\mathbb{E}X)^2)$ die Varianz von X\\
  $\sigma(X)=\sqrt{Var(X)}$ heißt Streuung (Standartabweichung)
\end{center} 
% \textbf{Bemerkung 1.6.2}\\\\
\begin{rem}
  Gilt $Var(x)=0$ so ist (Mit Satz 5.2)
  \begin{center}
    $X\equiv \mathbb{E}X$ P-fs
  \end{center}
  Für $Var(x)<\infty$ gilt $\mathbb{E}X^2< \infty$.
\end{rem}
% \textbf{Beispiel 1.6.3}\\\\
\begin{example}
  Münzwurf mit Parameter $p \in (0,1)$. Es sei $\Omega=\{0,1\}^n,
  \mathcal{A}=\mathcal{P}(\Omega), X_i(\omega)=\omega_i$ und
  $S_n(\omega)=\sum\limits_{i=1}^n X_i$. Wir definieren ein Maß $P_p$
  vermöge:
  \begin{center}
    $P_p(\cdot)=\sum\limits_{\omega \in \Omega}\alpha_\omega
    \delta_\omega(\cdot)$
  \end{center}
  mit $\alpha_\omega=p^{S_n(\omega)}(1-p)^{n-S_n(\omega)}$. 
  Eine Anwendung der Binomischen Formel liefert dann
  $\sum\limits_{\omega \in \Omega}\alpha_\omega=1$. Ferner gilt
  (z.B. mit Induktion über $n \in \mathbb{N}$) $P(X_i=1)=p$ für alle
  $i \in \{1,\dots,n\}$. Somit folgt
  \begin{center}
    $\mathbb{E}S_n=\sum\limits_{i=1}^n\mathbb{E}X_i=np$
  \end{center}
  Für die Varianz gilt:
  \begin{eqnarray*}
    \mathbb{E}S_n&=&\sum\limits_{k=0}^nk^2P_p(S_n=k)\\
    &=& \sum\limits_{k=0}^nk^2\binom{n}{k}p^k(^-p)^{n-k}\\
    &=&\sum\limits_{k=0}^nk(k-1)\binom{n}{k}p^k(1-p)^{n-k} (=p^2n(n-1))\\
    &+& \sum\limits_{k=0}^n k\binom{n}{k}p^k(1-p)^{n-k} (=np)\\\\
    Var(S_n)&=&n(n-1)p^2+np-n^2p^2\\
    &=&np(1-p)
  \end{eqnarray*}
  Also $\mathbb{E}\left(\frac{1}{n}S_n\right)=p$ und $Var\left(\frac{1}{n}S_n\right)=\frac{1}{n^2}Var(S_n)=\mathcal{O}\left(\frac{1}{n}\right) \overset{n \to \infty}{\to} 0$.\\
  Mit Cebysev gilt also: $P\left(\left|\frac{1}{n}S_n-p\right|\geq \varepsilon\right)\leq \frac{1}{\varepsilon^2}\frac{1}{n}p(1-p)$
\end{example}
% \textbf{Definition 1.6.4}
\begin{defn} \ \index{Ko-Varianz} \index{Varianz} % flashcard-name: Varianz und Kovarianz
  \begin{itemize}
  \item Für $X,Y \in \mathcal{L}^2$ ist
    $cov(X,Y)=\mathbb{E}([X-\mathbb{E}X][y-\mathbb{E}Y])$ die
    Ko-Varianz von $X$ und $Y$.
  \item Falls $\sigma(X), \sigma(Y)>0$ ist
    \begin{center}
      $\varrho(X,Y)=\dfrac{cov(X,Y)}{\sigma(X)\sigma(Y)}$
    \end{center}
    der Korrelationskoeffizient.
  \end{itemize}
  Gilt $cov(X,Y)=0$ so heißen $X$ und $Y$ unkorreliert.\\\\
\end{defn}
\paragraph{Rechenregeln:}
Für alle $a,b \in \mathbb{R}$ gilt:
\begin{itemize}
\item $Var(aX+b)=a^2Var(X)$
\item $Var(X+Y)=Var(X)+Var(Y)+2cov(X,y)$
\end{itemize}
Damit gilt für unkorrelierte Zufallsvariablen $X,Y$:
\begin{center}
  $Var(X+Y)=Var(X)+Var(Y)$
\end{center} 
\section{Das Schwache und Starke Gesetz der großen Zahlen}
\label{sec:gesetz-grosser-zahlen}
% \Large{\textbf{1.7 Das Schwache und Starke Gesetz der großen
% Zahlen}}\normalsize\\\\\\

% \textbf{Definition 1.7.0}\\\\
\begin{defn} \index{stochastische Konvergenz} \index{p-fast-sicher} \index{Konvergenz im $p$-ten Mittel} % flashcard-name: Konvergenz: stoachstische, p-fast-sicher p-ten Mittel
  Es seien $X_1,X_2,\ldots$ Zufallsvariablen auf $(\Sigma,\mathcal{A},P)$. Wir
  sagen:
  \begin{itemize}
  \item $(X_i)_{i \in \mathbb{N}}$ konvergiert stochastisch (in
    W'keit) gegen eine Zufallsvariable $X$ falls $\forall\varepsilon >0$ gilt:
    \begin{center}
      $\lim\limits_{n \to \infty}P(\{|X_n-X|\geq \varepsilon\})=0$
    \end{center}
    wir schreiben in diesem Fall $X_n \overset{P}{\to} X$.
  \item $(X_i)_{i \in \mathbb{N}}$ konvergiert fast-sicher (P-fs)
    gegen $X$, falls
    \begin{center}
      $P\left(\lim\limits_{n \to \infty}|X_n-X|=0\right)=1$
    \end{center}
    wir schreiben in diesem Fall $X_n \to X$ P-fs.
  \item $(X_i)_{i \in \mathbb{N}}$ konvergiert im $p$-ten Mittel
    $(p\geq 1)$ gegen $X \in \mathcal{L}^p$ falls
    \begin{center}
      $\mathbb{E}[(X_n-X)^p] \overset{n \to \infty}{\to}0$
    \end{center}
    wir schreiben in diesem Fall $\Vert X_n-X\Vert_p \to 0$.\\
  \end{itemize}
  Annahme für den Rest des Kapitels:\\
  Gegeben eine Folge paarweise unkorrelierter Zufallsvariablen $(X_i)_{i \in
    \mathbb{N}}$ d.h.
  \begin{center}
    $cov(X_i,X_j)=0 \qquad \forall i\neq j$
  \end{center}
  Wir setzen
  \begin{center}
    $S_n=\dfrac{1}{n}\sum\limits_{i=1}^nX_i$
  \end{center}
\end{defn}
% \textbf{Satz 1.7.1}\\\\
\begin{prop} \index{Erwartungswert} % flashcard-name: wenn $\lim\limits_{n \to \infty} \dfrac{1}{n}\sum\limits_{i=1}^nVar(X_i)<\infty$ gilt was gilt dann?
  Gilt $\lim\limits_{n \to \infty} \dfrac{1}{n}\sum\limits_{i=1}^nVar(X_i)<\infty$ so gilt $\mathbb{E}[(S_n-\mathbb{E}S_n)^2]\to 0$.
\end{prop}
% \textit{Beweis} 
\begin{proof}
  Übung. 
\end{proof}
% \textbf{Satz 1.7.2} \textit{Schwaches Gesetz der großen Zahlen}\\\\
\begin{prop}[Schwaches Gesetz der großen Zahlen] \index{Schwaches Gesetz der großen Zahlen}
  Es gelte
  \begin{center}
    $\mathbb{E}X_i=m\qquad \forall i \in \mathbb{N}$
  \end{center}
  sowie
  \begin{center}
    $\lim\limits_{n \to \infty}
    \dfrac{1}{n^2}\sum\limits_{i=1}^nVar(X_i) \to 0$
  \end{center}
  dann gilt
  \begin{center}
    $P\left[\left|\dfrac{1}{n}\sum\limits_{i=1}^n(X_i-m)\right|\geq
      \varepsilon\right] \overset{n \to \infty}{\to} 0 \qquad \forall
    \varepsilon >0$
  \end{center}
  $ $
  \underline{Von Stochastischer zu f.s. Konvergenz}
\end{prop}
Zur Erinnerung: (Borel-Cantelli) Seien $(A_i)_{i \in \mathbb{N}}$ Ereignisse mit
\begin{center}
  $\sum\limits_{i=1}^\infty P(A_i) < \infty $
\end{center} 
dann treten nur endlich viele $A_i$ ein.
% \textbf{Lemma 1.7.3} \textit{Schnelle stochastische Konvergenz impliziert fs-Konvergenz}\\\\
\begin{lem}[Schnelle stochastische Konvergenz impliziert fs-Konvergenz] \index{Schnelle stochastische Konvergenz impliziert fs-Konvergenz}
  Seien $Z_1, Z_2,\ldots$ Zufallsvariablen auf $(\Omega,\mathcal{A},P)$, so dass
  für alle $\varepsilon >0$ gilt $\sum\limits_{k=0}^\infty P(\{|Z_k|\geq
  \varepsilon\})< \infty $. Dann gilt
  \begin{center}
    $\lim\limits_{k \to \infty} Z_k=0$ P-fs
  \end{center}
\end{lem}
% \textit{Beweis}\\\\
\begin{proof}
  Nach Borel-Cantelli gilt
  \begin{center}
    $P\left(\limsup\limits_{n \to \infty}\{|Z_n|\geq
      \varepsilon\}\right)=0$
  \end{center}
  für alle $k \in \mathbb{N}$ gilt daher
  \begin{center}
    $\exists N_k \in \mathcal{A}$ mit $P(N_k)=0$
  \end{center}
  so, dass
  \begin{center}
    $\limsup\limits_{n \to \infty} (Z_n(\omega)\leq \dfrac{1}{k}\qquad
    \forall\omega \in \Omega\setminus N_k$
  \end{center}
  Sei $N=\bigcup\limits_{k \in \mathbb{N}}N_k$. Dann gilt
  \begin{center}
    $P(N)=P\left(\bigcup\limits_{k \in \mathbb{N}}N_k\right)\leq
    \sum\limits_{k=1}^\infty P(N_k)=0$
  \end{center}
  Für $\omega \in \Omega\setminus N$ gilt dann
  \begin{center}
    $\limsup\limits_{n \to \infty} |Z_n(\omega)|=0$
  \end{center}
  D.h. $P\left(\lim\limits_{n \to \infty}Z_n=0\right)=1$ 
\end{proof}
Wir folgern das starke Gesetz der großen Zahlen. \index{starke Gesetz der großen Zahlen}
% \textbf{Satz 1.7.4}\\\\
\begin{prop}[Starkes Gesetz der Großen Zahlen]
  Seien $X_1,X_2,\ldots \in \mathcal{L}^2$ paarweise unkorreliert und
  \begin{center}
    $c:=\sup\limits_{i \in \mathbb{N}} Var(X_i) < \infty$
  \end{center}
  Dann gilt
  \begin{center}
    $\left|\frac{1}{n}\sum\limits_{i=1}^nX_i-\dfrac{1}{n}\sum\limits_{i=1}^n\mathbb{E}X_i\right|
    \to 0$ P-fs
  \end{center}
\end{prop}
% \textit{Beweis}\\\\
\begin{proof}
  Sei o.B.d.A. $\E X_i=0 ~ \forall i \in \mathbb{N}$. Sei
  \begin{center}
    $S_n=\sum\limits_{i=1}^nX_i$
  \end{center}
  Dann gilt mit Cebysev
  \begin{center}
    $P\left[\dfrac{|S_n|}{n}\geq \varepsilon\right]\leq
    \dfrac{c}{\varepsilon^2n}$
  \end{center}
  Wir können Lemma 7.3 nicht direkt anwenden, da
  $\sum\limits_{i=1}^\infty \frac{1}{n}=\infty$.
  \begin{itemize}
  \item[a)] Wir können Lemma 7.3 aber entlang einer Teilfolge anwenden
    \begin{center}
      $p\left[\dfrac{S_n^2}{n^2}\geq
        \varepsilon\right]<\dfrac{c}{\varepsilon^2n^2}$
    \end{center}
    Nach Lemma 7.3 gilt
    \begin{center}
      $\lim\limits_{n \to \infty} \dfrac{S_n^2}{n^2}=0$ P-fs
    \end{center}
  \item[b)] Um Konvergenz entlang der ganzen Folge zu zeigen, nutzen
    wir ein Sandwichargument. Sei dazu $l \in \N$ und
    \begin{center}
      $D_k=\max\limits_{k^2<l\leq (k+1)^2} |S_l-S_k|$
    \end{center}
    Dann gilt
    \begin{eqnarray*}
      P\left[\left|\dfrac{D_k}{k^2}\right|\geq \varepsilon\right]&=&P\left[\bigcup\limits_{k^2<l\leq (k+1)^2}\{|S_l-S_n|\}\geq \varepsilon k^2\right]\\
      &\leq & \sum\limits_{k^2<l\leq (k+1)^2}P[|S_l-S_n|\geq \varepsilon k^2]\\
      &\leq & \dfrac{Var(|S_l-S_{k^2}|)}{\varepsilon^2 k^4}\leq \dfrac{c}{\varepsilon^2 k^3}\qquad (*)
    \end{eqnarray*}
    Insgesamt also
    \begin{center}
      $P\left[\left|\dfrac{D_k}{k^2}\right|\geq \varepsilon \right]\leq
      \dfrac{\tilde{c}}{k^2}$
    \end{center}
    für eine Konstante $\tilde{c}$. Nach Lemma 7.3 gilt somit
    \begin{center}
      $\dfrac{D_k(\omega)}{k^2} \to 0$ ~und~
      $\dfrac{S_{k^2}(\omega)}{k^2} \to 0$ P-fs
    \end{center}
    Sei $\varepsilon > 0$ ~und~ $k_0 \in \N$, so dass
    \begin{center}
      $\dfrac{D_k(\omega)}{k^2} < \dfrac{\varepsilon}{2}$ und
      $\dfrac{S_{k^2}(\omega)}{k^2} < \dfrac{\varepsilon}{2} \qquad
      \forall k\geq k_0$
    \end{center}
    Sei $n \geq k_0$ und $k\geq k_0$ mit $k^2<n\leq (k+1)^2$. Dann
    gilt
    \begin{eqnarray*}
      \left|\dfrac{S_n(\omega)}{n} \right| &\leq & \left|\dfrac{S_{k^2}(\omega)}{n} \right|+\left|\dfrac{S_n(\omega)}{n}-\dfrac{S_{k^2}(\omega)}{n} \right| \\
      &\leq &\left|\dfrac{S_{k^2}(\omega)}{k^2} \right|+\left|\dfrac{D_{k}(\omega)}{k^2} \right|\\
      &\leq &\dfrac{\varepsilon}{2}+\dfrac{\varepsilon}{2} =\varepsilon
    \end{eqnarray*}
  \end{itemize}
\end{proof}
% \textbf{Beispiel 1.7.5} \textit{Random Walk}\\\\
\begin{example}[Random Walk] \index{Random Walk}
  Betrachte ein MW-Modell mit Parameter $p=\frac{1}{2}$. Seien
  $X_1,X_2,\ldots$ die Projektionsabbildungen. Sei
  \begin{center}
    $Y_i=2X_i-1 \in \{1,-1\}$
  \end{center}
  Die Folge $S_n:=Y_1+\ldots+Y_n$ heißt Random-Walk. Nach Satz 7.4
  gilt
  \begin{center}
    $\dfrac{1}{n}S_n \to 0$ P-fs
  \end{center}
  Genauer gilt
  \begin{eqnarray*}
    \limsup\limits_{n \to\infty}\dfrac{S_n}{\sqrt{n\log\log n}}&=& 1 \qquad \text{P-fs}\\
    \liminf\limits_{n \to\infty}\dfrac{S_n}{\sqrt{n\log\log n}}&=& -1 \qquad \text{P-fs}
  \end{eqnarray*}
\end{example}

\section{Vergleich von Konvergenzbegriffen}
\label{sec:konvergenz}
% \Large{\textbf{1.8. Vergleich von Konvergenzbegriffen}}\normalsize\\\\
% \textbf{Definition 1.8.1}\\\\
\begin{defn} \index{konvergenz im $p$-ten Mittel} \index{stochastische Konvergenz} % flashcard-name: Wann konvergiert die Folge $(X_n)_{n \in \N}$ stochstisch, fast-sicher, im p-ten Mittel
  Seien $X_1,X_2,\ldots$ Zufallsvariablen auf $(\Omega,\mathcal{A},P)$. Die Folge
  $(X_n)_{n \in \N}$ konvergiert
  \begin{itemize}
  \item[i)] im $p$-ten Mittel gegen $X \in \mathcal{L}^p$ falls
    \begin{center}
      $\E[|X_n-X|^p] \to \infty$ für $n \to \infty$
    \end{center}
  \item[ii)] stochastisch (in Wahrscheinlichkeit) gegen eine Zufallsvariable $X$
    falls
    \begin{center}
      $P[|X_n-X|\geq \varepsilon ] \overset{n \to \infty}{\to} 0\qquad
      \forall \varepsilon >0$
    \end{center}
  \item[iii)] fast sicher gegen $X$ falls
    \begin{eqnarray*}
      && P\left[\lim\limits_{n \to \infty}X_n=X \right]=1\\
      &\Leftrightarrow &P[|X_n-X|\geq \varepsilon \text{ unendlich oft }] \overset{n \to \infty}{\to} 0
    \end{eqnarray*}
  \end{itemize}
\end{defn}
% \textbf{Satz 1.8.2}\\\\
\begin{prop} % flashcard-name: Welche Konvergenz folgt aus welcher
  Für i), ii), iii) wie in vorstehender Definition gilt
  \begin{itemize}
  \item i) $\Rightarrow$ ii)
  \item iii) $\Rightarrow$ ii)
  \item ii) $\Rightarrow$ iii) für eine Teilfolge
  \item iii) $\Rightarrow$ i) falls $\sup|X_n|^p \in L^1$
  \end{itemize}
\end{prop}
% \textit{Beweis}\\\\
\begin{proof}
  i) $\Rightarrow$ ii) Nach Satz 1.5.1 (Markov Ungleichung)
  \begin{center}
    $P[|X|\geq \varepsilon] \leq \dfrac{1}{\varepsilon^p}\E[|X|^p]$
  \end{center}
  gilt
  \begin{center}
    $P[|X_n-X|\geq \varepsilon] \leq \dfrac{1}{\varepsilon^p} \E[|X_n-X|^p]
    \overset{n \to \infty}{\to} 0$ nach Vorraussetzung für alle
    $\varepsilon>0$
  \end{center}
  iii) $\Rightarrow$ ii) Es gilt
  \begin{center}
    $\{\lim X_n=X\}=\bigcap\limits_{k \in
      \N}\underbrace{\overbrace{\bigcup\limits_{m=k}^\infty\bigcap\limits_{n\geq
          m} \{|X_n-X|\leq \frac{1}{k}\}}}^{=:A_k}_{\liminf
      \{|X_n-X|\leq \frac{1}{k}\}}$
  \end{center}
  Nach Annahme gilt $P(A_k)=1$. Also
  \begin{eqnarray*}
    1=P(A_k)&\overset{\text{Isotonie}}{=}& \lim\limits_{m \to \infty} P(\bigcap\limits_{n\geq m}\{|X_n-X|\leq \frac{1}{k}\})\\
    &\leq& \lim\limits_{m \to \infty} P(|X_n-X|\leq \frac{1}{k})
  \end{eqnarray*}
  Also für alle $k \in \N$
  \begin{center}
    $\lim\limits_{m \to \infty} P(|X_n-X|\leq\frac{1}{k})=1$
  \end{center}
  iii) $\Rightarrow$ i) Sei $Y:=\sup_{n \in \N}|X^n|^p+|X|^p \in
  L^1$. Dann gilt
  \begin{center}
    $|X_n-X|^p\leq 2^p|Y| \in L^1$
  \end{center}
  Nach Satz 1.4.18 (Satz von Lebesque) gilt dann (es existiert eine
  integrierbare Majorante!)
  \begin{center}
    $\E[|X_n-X|^p]\overset{n \to \infty}{\to} 0$
  \end{center}
  ii) $\Rightarrow$ iii) entlang einer Teilfolge\\
  Für $l \in \N$ existiert eine Teilfolge $(n_k(l))_{k \in \N}$ so
  dass gilt
  \begin{align*}
    P[|X_{n_k(l)}-X|\geq \frac{1}{l}] &\leq \frac{1}{2^k} \\
    \intertext{insbesondere}
    P[|X_{n_l(l)}-X|\geq \frac{1}{l}] &\leq \frac{1}{2^l}
    \intertext{Dann gilt:}
    \sum\limits_{k=1}^\infty \underbrace{P[|X_{n_k(k)}-X|\geq \frac{1}{l}]}_{\leq \frac{1}{2^k} \text{ für } k \geq l} &< \infty
  \end{align*}
  für alle $l \in \N$. Nach Lemma 1.7.3 gilt dann
  \begin{center}
    $\lim\limits_{k \to \infty} X_{n_k(k)}=X$ f.s. 
  \end{center}

  gilt $X_n\overset{L^1}{\to} X \in L^1$ so gilt auch
  \begin{center}
    $|\E[X_n]-\E[X] \leq \E|X_n-X| \to 0$
  \end{center}
\end{proof}
Ziel: $L^1$-Konvergenz $\Leftrightarrow$ stochastisch + ,,etwas''
% \textbf{Definition 1.8.3}\\\\
\begin{defn}  % flashcard-name: gleichmäßig integrierbar
  Sei $I$ eine Indexmenge. Eine Familie $(X_i)_{i \in I}$ von Zufallsvariablen
  heißt gleichmäßig integrierbar (GI) falls gilt
  \begin{center}
    $\lim\limits_{c \to \infty} \sup\limits_{i \in I}
    \underbrace{\int\limits_{\{|X_i|\geq
        c\}}|X_i|dP}_{\E[\1_{\{|X_i|\geq c\}}X_i]}=0 $
  \end{center}
\end{defn}
% \textbf{Satz 1.8.4} 
\begin{prop} \index{$L^1$ Konvergenz}  \index{Konvergenz im $p$-ten Mittel}  % flashcard-name: $X_n \overset{L^1}{\to} X (\in L^1)$ ist äquivalent zu was?
  \label{prop:LkonvergenzUndPkonvergenz}
  Seien $X_n \in L^1$, dann sind äquivalent
  \begin{itemize}
  \item[i)] $X_n \overset{L^1}{\to} X (\in L^1)$
  \item[ii)] $X_n \overset{P}{\to} X$ und $(X_n)$ ist gleichmäßig integrierbar
  \end{itemize}
\end{prop}
% \textbf{Korollar 1.8.5}\\\\
\begin{cor}  % flashcard-name: Aus $(X_n)$ gleichmäßig integrierbar folgt was?
  Seien $X_n \in L^1$ und $X_n \to X$ f.s., ist $(X_n)$ gleichmäßig integrierbar, so gilt
  \begin{center}
    $\E X_n \to \E X$ für $n \to \infty$
  \end{center}
\end{cor}
% \textbf{Bemerkung}\\\\
\begin{rem}
  Sind alle $X_i$ uniform durch eine Konstante beschränkt, so ist $(X_i)_{i \in I}$ gleichmäßig integrierbar.
\end{rem}
% \textbf{Satz 1.8.6} \textit{$\varepsilon - \delta$ Kriterium für GI}\\\\
\begin{prop} [$\varepsilon - \delta$ Kriterium für Gleichmäßige Integrierbarkeit]
  Seien $(X_i)_{i \in I}$ Zufallsvariablen auf $(\Omega, \mathcal{A},P)$. Dann sind
  äquivalent
  \begin{itemize}
  \item[i)] $(X_i)_{i \in I}$ ist gleichmäßig integrierbar
  \item[ii)] $\sup \E [|X_i|]< \infty$ und $\forall \varepsilon > 0
    \exists \delta >0$ so dass für alle $A \in \mathcal{A}$ mit $P(A)<
    \delta$ gilt $\int\limits_A |X_i|dP<\varepsilon$ für alle $i \in I$
  \end{itemize}
\end{prop}
% \textit{Beweis}\\\\
\begin{proof} 
  i) $\Rightarrow$ ii) Wir zeigen zunächst $\sup\limits_{i \in I}
  \E|X_i| < \infty$. Wegen gleichmäßig integrierbar existiert ein $c>0$, so dass
  \begin{center}
    \[\sup\limits_{i \in I} \int\limits_{\{|X_i|\geq c\}}|X_i|dP\geq
    1\]
  \end{center}
  Also gilt
  \begin{eqnarray*}
    \sup\limits_{i \in I} \E|X_i| &\leq& \sup\limits_{i \in I}\int\limits_{\{|X_i|\geq c\}}|X_i|dP+ \sup\limits_{i \in I}\int\limits_{\{|X_i|< c\}}|X_i|dP\\
    &\leq & 1+c < \infty 
  \end{eqnarray*}
  Sei nun $\varepsilon >0$. Sei $c\geq 0$, so dass
  \begin{center}
    \[\sup\limits_{i \in I} \int\limits_{\{X_i \geq c\}}|X_i|dP
    <\dfrac{\varepsilon}{2}\]
  \end{center}
  sei $ \delta:=\frac{\varepsilon}{2c}$ und $P(A)<\delta$. Dann gilt
  \begin{eqnarray*}
    \int\limits_A|X_i|dP&=&\sup\limits_{i \in I}\int\limits_{\{|X_i|\geq c\}\cap A}|X_i|dP+ \sup\limits_{i \in I}\int\limits_{\{|X_i|< c\}\cap A}|X_i|dP\\
    &\leq & cP(A)+\dfrac{\varepsilon}{2}\\
    &<& c\dfrac{\varepsilon}{2c}+\dfrac{\varepsilon}{2}=\varepsilon
  \end{eqnarray*}
  ii) $\Rightarrow$ i) Seien $\varepsilon, \delta >0 $ wie in ii)
  vorgegeben. Sei $c>0$ so daß
  \begin{center}
    $\dfrac{1}{c}\sup\limits_{i \in I} \E[|X_i|]<\delta$
  \end{center}
  nach Satz 1.5.1 gilt dann
  \begin{center}
    $P[\underbrace{|X_i|\geq c}_{= \text{eine der Testmengen } A \in
      \mathcal{A}}]\leq \dfrac{1}{c}\E[|X_i|]<\delta$
  \end{center}
  Also gilt nach Vorraussetzung mit $A=\{|X_i|\geq c\}$.
  \begin{center}
    \[\int\limits_{\{|X_i|\geq c\}}|X_i|dP < \varepsilon\]
  \end{center}
  Also auch
  \begin{center}
    \[\sup\limits_{i \in I}\int\limits_{\{|X_i|\geq c\}}|X_i|dP \leq
    \varepsilon \] 
  \end{center}
\end{proof}
% \textbf{Bemerkung 1.8.7}\\\\
\begin{rem}
  Gilt $Y \in L^1$ und $|X_i| \leq Y$ für alle $i \in I$ so gilt
  \begin{center}
    \[\sup\limits_{i \in I} \int\limits_{\{|X_i|\geq c\}}|X_i|dP \leq
    \int\limits_{\{Y \geq c\}}Y dP \overset{n \to \infty}{\to} 0 \]
  \end{center}
\end{rem}
% \textit{Beweis von Satz 1.8.4}\\\\
\begin{proof}[von Satz \ref{prop:LkonvergenzUndPkonvergenz}]
  \begin{itemize}
  \item[i) $\Rightarrow$ ii)] Übung
  \item[ii) $\Rightarrow$ i)] Nach Satz 8.2
    existiert $(n_k)_{k \in \N}$ mit
  \end{itemize}
  \begin{center}
    $X_{n_k} \to X$ f.s.
  \end{center}
  damit gilt
  \begin{eqnarray*}
    \E[|X|]&=&\E[\lim\limits_{k \to \infty} |X_{n_k}|]\\
    &\leq & \liminf\limits_{k \to \infty} \E[|X_{n_k}|]\\
    &\leq & \sup\limits_{n \in \N} \E[|X_n|]\\
    &\overset{1.8.6}{<}&\infty
  \end{eqnarray*}
  Also $X \in L^1$.\\
  Wir zeigen nun $L^1$-Konvergenz. Sei dazu o.B.d.A. $\E X_n=0$ (vgl. Übungsblatt 5). Sei $\varepsilon >0$, nach Satz 8.6 existiert ein $\delta >0 $ mit $\int\limits_A|X_n|dP<\varepsilon$ für $P(A)<\delta$. Da $X_n \overset{P}{\to} 0$ existiert ein $n_0= \N$ mit
  \begin{center}
    $P[|X_n|\geq\frac{\varepsilon}{2}]< \delta \qquad \forall n \geq n_0$
  \end{center}
  Also gilt für $n \geq n_0$
  \begin{center}
    \[\E[|X_n|]=\int\limits_{\{|X_n|\leq \frac{\varepsilon}{2}\}}|X_n|dP+\int\limits_{\{|X_n|> \frac{\varepsilon}{2}\}}|X_n|dP\leq \frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon \]
  \end{center}
  [Zu $X_n \to 0$ sei $Y_n=X_n-X$ gleichmäßig integrierbar]
\end{proof}
\section{Verteilung einer Zufallsvariable}
Sei $(\Omega,\mathcal{A},P)$ ein Wahrscheinlichkeitsraum, $X:\Omega \to \overline{\R}$ eine Zufallsvariable. $\mu$ sei die Verteilung von $X$ unter $P: \mu=P\circ X^{-1}$.

\paragraph{Annahme:} $P(X\in \R)=1$, also $X$ ist f.s. endlich. $\mu$ ist Wahrscheinlichkeitsmaß auf $(\R,B(\R))$.
% \textbf{Definition 9.1}\\\\
\begin{defn}  % flashcard-name: Verteilungsfunktion
  Die Funktion $F:\R \to [0,1]$ heißt \index{Verteilungsfunktion}Verteilungsfunktion zu $X$ bzw. $\mu$ und ist definiert durch : $F(b):=\mu((-\infty,b])=P(X\leq b)$ für $b \in \R$.
\end{defn}
% \textbf{Satz 9.2}\\\\
\begin{prop} \ \index{isoton} \index{rechtsstetig} \index{normiert} \index{messbar}  % flashcard-name: Was gilt für rechtsstetig und normiert
  \begin{itemize}
  \item[(i)] $F$ ist isoton: Für $a,b \in \R$ mit $a \leq b$ gilt $F(a)\leq F(b)$\\
    $F$ ist rechtsstetig: $F(a)=\lim\limits_{b\searrow a}F(b)$ (also insbesondere messbar)\\
    $F$ ist normiert: $\lim\limits_{a\searrow -\infty}F(a)=0$ und
    $\lim\limits_{a\nearrow \infty}F(a)=1$
  \item[(ii)] Zu jeder Funktion $F$ mit den Eigenschaften aus (i) gibt
    es genau ein Wahrscheinlichkeitsmaß $\mu$ auf $(\R,B(\R))$, so dass $F$ durch $\mu$
    induziert wird.
  \end{itemize}
\end{prop}
% \textit{Beweis}\\\\
\begin{proof}
  Zu (i)
  \begin{itemize}
  \item $F$ ist isoton ist klar
  \item Aus $b \searrow b$ folgt: $(-\infty,b] \searrow (-\infty,a]$
    und wegen der antitonen Stetigkeit von Wahrscheinlichkeitsmaßen (Satz 1.9)
    \begin{eqnarray*}
      F(a)&=&\mu((-\infty,a])\\
      &=& \lim\limits_{b\searrow a} \mu((-\infty,b]) \\
      &=& \lim\limits_{b\searrow a} F(b)
    \end{eqnarray*}
  \item Analog folgt\\
    $\lim\limits_{a\searrow -\infty} (-\infty,a]=\emptyset$ und\\
    $\lim\limits_{a\nearrow \infty} (-\infty,a]=\R$ der Rest folgt
    dann aus den Eigenschaften von $P$
  \end{itemize}
  Zu (ii)\\
  Existenz: Sei $\lambda$ das Lebesgue-Maß auf $(0,1)$. Definiere
  "'Umkehrfunktion"' $G$ von $F$ über $G:(0,1) \to \R$ mit
  \begin{center}
    $G(y):=\inf\{x \in \R:F(x)\geq y\}$ mit $y \in (0,1)$
  \end{center}
  Mit den Eigenschaften von $G$ und $F$ gilt dann: aus $y<F(x)$ folgt
  $G(y)\leq x$ und aus $G(y)\leq x$ folgt $F(x)\geq F(G(y))\geq
  y$. Damit gilt
  \begin{center}
    $(0,F(x)) \subset \{G\leq x\}\subset (0,F(x)]$
  \end{center}
  Damit ist $G$ messbar. Setze: $\mu:=G(\lambda)=\lambda\circ
  G^{-1}$. $\mu$ ist Wahrscheinlichkeitsmaß auf $(\R,B(\R))$ und für alle $x \in \R$
  gilt:
  \begin{center}
    $\mu((-\infty,x])=\lambda(\{G\leq x\})=\lambda((0,F(x)])=F(x)$
  \end{center}
  Eindeutigkeit: später
\end{proof}
% \textbf{Bemerkungen}\\\\
\begin{rem}
  \begin{itemize}
  \item[(i)] Sei $Y$ eine Zufallsvariable mit Gleichverteilung auf $(0,1)$,
    z.B. $(\Omega,\mathcal{A},P)=((0,1),B((0,1)),\lambda_{|(0,1)})$
    dann hat $G(Y)$ die Verteilung $\mu$.
  \item[(ii)] Manche Autoren definieren die Verteilungsfunktion $F$
    über $F(x):=\mu((-\infty,x))$ für $x \in \R$. In diesem Fall ist
    $F$ nicht rechts- sondern linksstetig.
  \end{itemize}
  Notationen: Sei $(x_n)_{n \in \N}$ eine Folge mit $x_n\searrow
  x$. Dann sei
  \begin{center}
    $F(x_+):=\lim\limits_{x_n\searrow x} F(x_n)$
  \end{center}
  Analog für eine Folge mit $x_n\nearrow x$
  \begin{center}
    $F(x_-):=\lim\limits_{x_n\nearrow x} F(x_n)$
  \end{center}
\end{rem}
% \textbf{Bemerkung 9.3}\\\\
\begin{rem} \index{Verteilugnsfunktion}
  Sei $F$ Verteilungsfunktion. Für $x \in \R$ definieren wir die
  Sprunghöhe
  \begin{center}
    $F(x)-F(x_-)=\lim\limits_{n \to \infty}
    \mu((x-\frac{1}{n},x])=\mu(\{x\})$
  \end{center}
  Insbesondere gilt: $F$ ist stetig gdw. für alle $x \in \R ~ \mu(\{x\})=0$.
  Man sagt in diesem Fall $\mu$ ist stetig.
  Ist $\mu~ \sigma$-additiv, dann gibt es abzählbares $S \subset \R$ mit $\mu(\{x\})=0$ für alle $x \in S^c$, da es höchstens $n$ Punkte gibt mit $\mu(\{x_i\})>n^{-1}$. 
\end{rem}
% \textbf{Definition 9.4}\\\\
\begin{defn} \index{diskret} \index{Sprungfunktion} \index{Treppenfunktion}  % flashcard-name: Diskret und Treppenfunktionen
  $F$ bzw $\mu$ heißen \underline{diskret}, wenn es eine abzählbare
  Menge $S \subset \R$ mit $\mu(S)=1$ gibt. In diesem Fall gilt: $\mu$
  ist eindeutig bestimmt über $\mu(\{x\})$ für $x \in S$ und $F$ ist
  \underline{Sprungfunktion} oder \underline{Treppenfunktion} mit der
  Darstellung.
  \begin{center}
    $F(x)=\sum\limits_{y \in S} \mu(\{y\})$
  \end{center}
\end{defn}
% Beispiel:
\begin{example}
  $S=\mathbb{Q}$, $dx \in (0,1)$ mit $\sum\limits_{x \in \mathbb{Q}} dx=1$. 
  Dann ist $\mu=\sum\limits_{x \in \mathbb{Q} }dx\delta_x$ und $F(b)=\sum\limits_{\substack{x \in \mathbb{Q}\\ x \leq b}} dx$
\end{example}
% \textbf{Definition 9.5}\\\\
\begin{defn} \index{Dichtefunktion}  % flashcard-name: absolut stetig
  $F$ bzw. $\mu$ heißen \underline{absolut stetig} wenn es eine
  messbare Funktion $f\geq 0$ (genannt \underline{Dichtefunktion})
  gibt, so dass gilt:
  \begin{center}
    \[F(x)=\int\limits_{-\infty}^xf(t)dt\] für alle $x \in \R$
  \end{center}
  bzw. für alle $A \in B(\R)$
  \begin{center}
    \[\mu(A)=\int\limits_A f(t) dt=\int\limits_{-\infty}^\infty
    \1_A(t)f(t)dt\]
  \end{center}
  Insbesondere gilt für jede Dichtefunktion
  \begin{center}
    \[\int\limits_{-\infty}^\infty f(t)dt=1\]
  \end{center}
\end{defn}
% \textbf{Bemerkung 9.6}\\\\
\begin{rem}
  Jede messbare Funktion $f \geq 0$ mit $\int\limits_{-\infty}^\infty
  f(t)dt=1$ legt über
  \begin{center}
    \[\mu(A):=\int\limits_Af(t)dt\]
  \end{center}
  ein Wahrscheinlichkeitsmaß auf $(\R,B(\R))$ fest.
\end{rem}
% \textbf{Beispiele 9.7}
\begin{example} \ 
  \begin{itemize}
  \item[(i)] Gleichverteilung auf $[a,b]$. Setze
    $f=\frac{1}{b-a}\1_[a,b]$ dann ist die entsprechende
    Verteilungsfunktion
    \begin{center}
      $F(x)=\begin{cases}
        0 \text{ für } x < a\\
        \dfrac{x-a}{b-a} \text{ für } x \in [a,b]\\
        1 \text{ sonst }
      \end{cases}$
    \end{center}
  \item[(ii)] \index{Exponentialverteilung} Exponentialverteilung zum Parameter $\alpha >0$
    \begin{center}
      $f(x)=\begin{cases}
        \alpha e^{-\alpha x} \text{ für } x \geq 0\\
        0 \text{ sonst }
      \end{cases}$
    \end{center}
    \begin{center}
      $F(x)=\begin{cases}
        1-e^{-\alpha x} \text{ für } x \geq 0\\
        0 \text{ sonst }
      \end{cases}$
    \end{center}
    Die Exponentialfunktion ist das stetige Analogon zur geometrischen
    Verteilung, da gilt für $k \in \N$

    \[ \int\limits_{k-1}^k
    f(x)dx=F(k)-F(k-1)=e^{-\alpha(k-1)}(1-e^{-\alpha}) \qquad (*)\]

    setze $p=1-e^{-\alpha} \Rightarrow (*)=(1-p)^{k-1}p=P[X=k]$ für
    geometrisch verteilte Zufallsvariable $X$ mit Parameter $p$
  \item[(iii)] Normalverteilung mit Parameter $m \in \R$ und
    $\sigma^2>0$. $N(m,\sigma^2)$:
    \begin{align*}
      f_{m,\sigma^2}(x)&=\dfrac{1}{\sqrt{2\pi \sigma^2}} e^{-\dfrac{(x-m)^2}{2\sigma^2}}\\
      F_{m,\sigma^2}(x)&=\dfrac{1}{\sqrt{2\pi \sigma^2}} \int\limits_{-\infty}^xe^{-\dfrac{(y-m)^2}{2\sigma^2}}dy\\
      \intertext{Substituiere: $z=\dfrac{y-m}{\sigma}$}
      &=\dfrac{1}{\sqrt{2\pi}} \int\limits_{-\infty}^{\dfrac{x-m}{\sigma}}e^{-\dfrac{z^2}{2}}dz\\
      &=F_{0,1}\left(\dfrac{x-m}{\sigma}\right)
    \end{align*}
    $N(0,1)$ heißt Standardnormalverteilung \index{Standardnormalverteilung}. Dazu definieren wir
    \begin{eqnarray*}
      \phi(x)&:=& f_{0,1}=\dfrac{1}{\sqrt{2\pi}}e^{-\dfrac{x^2}{2}}\\
      \Phi(x)&=& F_{0,1}(x)=\dfrac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^x e^{-\dfrac{y^2}{2}}dy
    \end{eqnarray*}
  \end{itemize}
\end{example}
Berechnung des Erwartungswertes von $h(x)$ für $h \geq 0$ messbar.
% \textbf{Satz 9.8}\\\\
\begin{prop}  % flashcard-name: Was ist $\E[h(x)]$
  Sei $h\geq 0$ eine messbare Funktion auf $\R$ und $X$ eine Zufallsvariable. Dann
  gilt
  \begin{eqnarray*}
    \E[h(x)] &=& \int\limits_{-\infty}^{\infty} h(x) \mu(dx)\\
    &=& \begin{cases}
      \int\limits_{-\infty}^\infty h(x)f(x) dx \text{ falls } \mu \text{ absolut stetig mit Dichte } f\\
      \sum\limits_{x \in S} h(x)\mu(\{x\}) \text{ falls } \mu \text{ diskret, } S \text{ abzählbar } \mu(S)=1
    \end{cases}
  \end{eqnarray*}
\end{prop}
% \textbf{Satz 8.8}\\\\
\begin{prop}
  Sei $g:\R_+ \to \R_+$ mit
  \begin{center}
    $\lim\limits_{x\to \infty} \dfrac{g(x)}{x}\nearrow +\infty$
  \end{center}
  gilt dann
  \begin{center}
    $\sup\limits_{i in I} \E[g(X_i)]<\infty$
  \end{center}
  so ist $(X_i)_{i \in I}$ gleichmäßig integrierbar.
\end{prop}
% \textbf{Korollar 8.9}\\\\
\begin{cor}
  Sei $p>1$ und $\sup\limits_{i \in I}\E[|X_i|^p]<\infty$ dann ist
  $X_i$ gleichmäßig integrierbar.
\end{cor}
% \textit{Beweis von Satz 8.8.}\\\\
\begin{proof}
  Sei $\varepsilon > 0$ und $c>0$, so dass
  \begin{center}
    $\dfrac{g(x)}{x}\geq \dfrac{1}{\varepsilon} \sup\limits_{i \in
      I}\E[g(X_i)] \qquad \forall x \geq c$
  \end{center}
  Dann gilt für alle $i \in I$
  \begin{eqnarray*}
    \int\limits_{\{|X_i|\geq c\}} |X_i|dP &=& \int\limits_{\{|X_i|\geq c\}} g(|X_i|)\dfrac{|X_i|}{g(|X_i|)} dP\\
    &\leq &\dfrac{\varepsilon}{\sup\limits_{i \in I}\E[g(X_i)]}\int\limits_{\{|X_i|\geq c\}} g(|X_i|)dP\\
    &\leq & \dfrac{\varepsilon}{\sup\limits_{i \in I}\E[g(X_i)]}\sup\limits_{i \in I}\E[g(X_i)]\\
    &\leq & \varepsilon 
  \end{eqnarray*}
\end{proof}

% \textbf{Proposition 8.10}\\\\
\begin{prop}  % flashcard-name: $X_n \in \mathcal{L}^1 \forall n\in \mathbb{N}$  und $X_n \overset{f.s.}{\to} X$ . Seien $X_n \geq 0$ dann gilt?
  Seien $X_n \in \mathcal{L}^1$ für alle $n \in \N$ und $X_n
  \overset{f.s.}{\to} X$. Seien $X_n\geq 0$, dann gilt
  \begin{center}
    $X_n \overset{\mathcal{L}^1}{\to} X \Leftrightarrow \E X_n \to \E
    X$
  \end{center}
\end{prop}
% \textit{Beweis}\\\
\begin{proof} 
  "'$\Rightarrow$"' ist klar\\
  "'$\Leftarrow$"'
  \begin{eqnarray*}
    X_n+X &=& \sup(X_n,X)+\inf(X_n,X) \text{ also }\\
    \E[X_n]+\E[X] &=& \E[\sup(X_n,X)]+\E[\underbrace{\inf(X_n,X)}_{0 \leq \cdot \leq X \in \mathcal{L}^1}]
  \end{eqnarray*}
  Nach dem Konvergenzsatz von Lebesgue also
  \begin{center}
    $\lim\limits_{n \to \infty} \E[\inf(X_n,X)]=\E X$
  \end{center}
  Nach Vorraussetzung gilt $\E X_n \to \E X$ also auch
  \begin{center}
    $\lim\limits_{n \to \infty} \E[\sup(X_n,X)]=\E X$
  \end{center}
  Insgesamt also
  \begin{eqnarray*}
    \E[|X_n-X|] &=&\underbrace{\E[\sup(X_n,X)]}_{\to \E[X]}-\underbrace{\E[\inf(X_n,X)]}_{\to \E[X]}\\
    & \to & 0 
  \end{eqnarray*}
\end{proof}
Reminder! Einfügen der Beispiele zu Dichtefunktionen!

\section{Schwache Konvergenz von Wahrscheinlichkeitsmaßen}
Sei $(\mu_n)_{n \in \N}$ eine Folge von Wahrscheinlichkeitsmaßen auf $(\Omega,\mathcal{A})$. Die Forderung
\begin{center}
  $\mu_n(A) \to \mu(A) \qquad \forall A \in \mathcal{A}$ (Wir schreiben $\mu_n \overset{w}{\to} \mu$)
\end{center}
ist häufig zu stark.
% \textbf{Definition 1.0.1}\\\\
\begin{defn}  % flashcard-name: Was muss gelten für $\mu_n(f) = \mu(f)$?
  Eine Folge $(\mu_n)_{n \in \N}$ von Wahrscheinlichkeitsmaßen konvergiert schwach
  gegen ein Maß $\mu$ auf $S(,B(S))$ wobei $(S,d)$ ein metrischer Raum
  ist, falls
  \begin{center}
    \[\mu_n(f)=\int\limits_S f(x)\mu_n(dx) \to
    \int\limits_Sf(x)\mu(dx):=\mu(f)\]
  \end{center}
  für alle $f \in C_b(S)$. (Wobei $C_b(S)$ der Raum der stetigen, beschränkten Funktionen auf $S$)
\end{defn}
% \textbf{Beispiele 1.0.2}\\\\
\begin{example}
  \begin{itemize}
  \item[i)] Sei $(x_n)$ eine Folge in $S$ mit $x_n \to x$. Dann
    konvergiert die Folge
    \begin{center}
      $(\delta_{x_n}(\cdot))_{n \in \N}$
    \end{center}
    schwach gegen $\delta_x(\cdot)$, da
    \begin{center}
      \[\int\limits_Sf(y)\delta_{x_n} dy=f(x_n) \overset{\text{f
          stetig}}{\to} f(x)=\int\limits_S f(x)\delta_x dy \]
    \end{center}
    Für $f(\cdot)=\1_A(\cdot)$ mit $A=\{x\}$ gilt
    \begin{eqnarray*}
      \int\limits_S f(y)\delta_{x_n} dy &=& 0 \qquad \text{ für alle } x_n \neq x\\
      \int\limits_S f(y) \delta_x  dy &=& 1
    \end{eqnarray*}
  \item[ii)] Sei $\mu_n=N(0,\frac{1}{n})$ dann gilt
    \begin{center}
      $\mu_n \overset{w} \delta(\cdot)$
    \end{center}
    da
    \begin{eqnarray*}
      \int\limits_\R f(x) d\mu_n(x) &=& \int\limits_\R f(x)\dfrac{1}{\sqrt{2\pi \frac{1}{n}}}e^{-\dfrac{x^2}{\frac{2}{n}}} dx\\
      \text{Substituiere } y=\dfrac{x}{\sqrt{\frac{1}{n}}}: &=& \int\limits_\R \underbrace{f\left(\frac{y}{\sqrt{n}}\right)}_{\to f(0)} \dfrac{1}{\sqrt{2\pi}}\underbrace{e^{-\dfrac{y^2}{2}}}_{\text{beschränkt}} dy\\
      &\underset{n \to \infty}{\overset{\text{Lebesgue}}{\to}} &f(0)
    \end{eqnarray*}
  \end{itemize}
\end{example}
\paragraph{Wiederholung}
Sei $(S,d)$ ein metrischer Raum. $(\mu_n)$ eine Folge von Wahrscheinlichkeitsmaßen auf $(S,B(S))$. Sei $\mu$ ein Maß $(S,B(S))$. Dann
\begin{center}
  $\mu_n \overset{w}{\to} \mu$
\end{center}
falls $\mu_n(f) \to \mu$ für alle $f \in C_b(S)$. Für $f \equiv 1$ folgt
\begin{center}
  $\mu_n(f)=\mu_n(S)=1$
\end{center}
Damit auch $\mu(S)=1$, d.h. $\mu$ ist ein W'maß.\\
\underline{Etwas Heuristik:} 
Sei $S=\R$, $b \in \R$. Sei weiter $b_n <b$ und $a_n>b$ für Folgen mit $b_n\nearrow b$ und $a_n \searrow a$. Dann gilt
\begin{center}
  $(-\infty,b_n] \nearrow (-\infty,b)$ und $(-\infty,a_n] \searrow (-\infty,b]$
\end{center}
also 
\begin{center}
  $\underbrace{\mu((-\infty,b_n])}_{F(b_n)} \nearrow \underbrace{\mu((-\infty,b))}_{F(b_-)}$ und $\underbrace{\mu((-\infty,a_n])}_{F(a_n)} \searrow \underbrace{\mu((-\infty,b])}_{F(b)}$
\end{center}
Falls gilt: $F(b)-F(b_-)=\mu(\{b\})=0$ ist $F$ an der Stelle $b$ stetig und $\mu(\{b\})=\mu(\underbrace{\partial}_{Rand}(-\infty,b])$.\\
Schlußfolgerung: Unstetigkeitsstellen von $F$ und das Maß von Rändern von Mengen sind wichtig!
% \textbf{Definition 10.2.1}\\\\
\begin{defn}  % flashcard-name: Was bedeutet $\mu$-randlos
  Eine Menge $A \in B(S)$ heißt $\mu$-randlos falls
  \begin{center}
    $\mu(\partial A)=0$ 
  \end{center}
  wobei $\partial A$ den Rand von $A$ bezeichnet
\end{defn}
% \textbf{Satz 10.3} \textit{Portemanteau-Theorem}\\\\
\begin{prop}[Portemanteau-Theorem] \index{Portemanteau-Theorem}
  Die folgenden Aussagen sind äquivalent
  \begin{itemize}
  \item[1)] $\mu_n \overset{w}{\to} \mu$
  \item[2)] $\mu_n(f) \to \mu(f) \qquad \forall f \in C_b(S)$
  \item[3)] für alle abgeschlossenen $F \subseteq S$ gilt
    \begin{center}
      $\limsup\limits_{n \to \infty} \mu_n(F) \subseteq \mu(F)$
    \end{center}
  \item[4)] Für alle offenen $G \subseteq S$ gilt
    \begin{center}
      $\liminf\limits_{n \to \infty}\mu_n(G) \supseteq \mu(G)$
    \end{center}
  \item[5)] Für alle $\mu$-randlosen $A \subseteq S$ gilt
    \begin{center}
      $\mu_n(A) \to \mu(A)$
    \end{center}
  \end{itemize}
\end{prop}
% \textit{Beweis}\\\\
\begin{proof} \ 
  \begin{itemize}
  \item[1) $\Rightarrow$ 2)] klar (Definition)
  \item[3) $\Leftrightarrow$ 4)] mit Komplementbildung
  \item[1) $\Rightarrow$ 3)] Sei $F$ abgeschlossen. Sei weiter
    \begin{center}
      $G_m=\{x \in S|\underbrace{d(x,F)}_{\inf\limits_{y \in
          F}d(x,y)}<\frac{1}{n}\}$
    \end{center}
    Wir betrachten eine geeignete Testfunktion $f \in C_b(S)$. Sei
    dazu
    \begin{center}
      $\varphi(x)=\begin{cases}
        1 \text{ für } x < 0\\
        0 \text{ für } x > 1\\
        1-x \text{ für } x \in [0,1]
      \end{cases}$
    \end{center}
    Sei dann $f(x)=\varphi(m\cdot d(x,F))$. Dann gilt
    \begin{itemize}
    \item $f(x)=1$ auf $F$
    \item $f(x)=0$ auf $G_m^c$
    \item $f \leq \1_{G_m}$
    \end{itemize}
    Also gilt:
    \begin{eqnarray*}
      \limsup\limits_{n \to \infty} \mu_n(F) &\leq & \limsup\limits_{n \to \infty} \mu_n(f)\\
      &\overset{2)}{\to }& \mu(f)\\
      &\leq & \mu(G_m)\\
      &\underbrace{\leq}_{G_m \searrow F}& \mu(F)+\varepsilon
    \end{eqnarray*}
    Für alle hinreichend großen $m \in \N$
  \item[3)+4) $\Rightarrow$ 5)] Sei $A ~ \mu$-randlos. Dann gilt
    \begin{eqnarray*}
      \mu(A)=\mu(\overset{\circ}{A}\cup \partial A)&=&\mu(\overset{\circ}{A})\\
      & \overset{(4)}{\leq}& \liminf\limits_{n \to \infty} \mu_n(\overset{\circ}{A})\\
      & \leq & \liminf\limits_{n \to \infty} \mu_n(A)\\
      & \leq & \limsup\limits_{n \to \infty} \mu_n(\bar{A})\\ 
      & \leq & \mu(\bar{A})=\mu(A)
    \end{eqnarray*} 
  \item[3) $\Rightarrow$ 1)] Es genügt zu zeigen
    \begin{center}
      $\limsup\limits_{n \to \infty} \mu_n(f)\leq \mu(f) \qquad
      \forall f \in C_b(S)$
    \end{center}
    da dann auch
    \begin{center}
      $-\liminf\limits_{n \to \infty}\mu_n(f)=\limsup\mu_n(-f)\leq
      \mu(-f)=-\mu(f)$
    \end{center}
    Sei dann o.B.d.A. $0 \leq f \leq 1$. Wir approximieren $f$ durch
    Elementarfunktionen. Sei dazu $k,j \in \N$. Wir fixieren $k$ und
    definieren
    \begin{center}
      $F_j:=\{f \geq \frac{j}{k}\}$
    \end{center}
    $F_j$ ist abgeschlossen, da $f$ stetig. Wir erhalten
    \begin{center}
      $F_j\setminus F_{j+1}=\{f \in [\frac{j}{k},\frac{j+1}{k})\}$
      sowie $F_0=S$ (da $f \geq 0$)
    \end{center}
    sowie $F_{k+1}=\emptyset$ da $f \leq 1$ und
    \begin{center}
      $S=\bigcup\limits_{j=0}^{\substack{k\\\cdot}}F_j\setminus
      F_{j+1}$
    \end{center}
    Dann gilt nach Konstruktion
    \begin{center}
      $\underbrace{\sum\limits_{j=0}^k\dfrac{j}{k}\1_{F_j\setminus
          F_{j+1}}}_{(*)} \leq f \leq
      \underbrace{\sum\limits_{j=0}^k\dfrac{j+1}{k}\1_{F_j\setminus
          F_{j+1}}}_{(**)}$
    \end{center}
    Wir erhalten
    \begin{eqnarray*}
      \sum\limits_{j=0}^k\dfrac{j+1}{k}\1_{{F_j}\setminus F_{j+1}}&=&\frac{1}{k}\sum\limits_{j=0}^k(j+1)\1_{{F_j}\setminus F_{j+1}}\\
      &=&\dfrac{1}{k}\left(\sum\limits_{j=0}^k(j+1)\1_{F_j}-\sum\limits_{j=0}^k(j+1)\1_{F_{j+1}} \right)\\
      &=& \dfrac{1}{k}\left(\sum\limits_{j=0}^k \1_{F_j}+\sum\limits_{j=0}^k j\1_{F_j}-\sum\limits_{j=1}^{k+1} j \1_{F_j}\right)\\
      &=& \dfrac{1}{k}\sum\limits_{j=0}^k \1_{F_j}\\
      &=& \dfrac{1}{k}\sum\limits_{j=1}^k \1_{F_j} + \dfrac{1}{k} \qquad\text{ (Da } F_0=S)
    \end{eqnarray*}
    Analoges Argument für (*) liefert
    \begin{center}
      $ \dfrac{1}{k}\sum\limits_{j=1}^k \1_{F_j} \overset{1)}{\leq} f
      \overset{2)}{\leq}\dfrac{1}{k}\sum\limits_{j=1}^k
      \1_{F_j}+\dfrac{1}{k}$
    \end{center}
    Also gilt
    \begin{eqnarray*}
      \limsup\limits_{n \to \infty} \mu_n(f)-\dfrac{1}{k}&\overset{2)}{\leq}& \limsup\limits_{n \to \infty} \dfrac{1}{k} \sum\limits_{j=1}^k \1_{F_j}\\
      &\leq & \dfrac{1}{k} \sum\limits_{j=1}^k \limsup\limits_{n \to \infty} \mu_n(F_j)\\
      &\overset{3)}{\leq}& \dfrac{1}{k} \sum\limits_{j=1}^k\mu(F_j)\\
      &\overset{1)}{\leq}& \mu(f)
    \end{eqnarray*}
    5) $\Rightarrow$ 3) Sei $F$ abgeschlossen. Sei $\delta > 0$ und
    \begin{center}
      $\partial\{x|d(x,F)\leq \delta\} \subseteq \{x|d(x,F)=\delta\}$
    \end{center}
    Für $\delta\neq \delta'$ gilt
    \begin{center}
      $\{x|d(x,F)=\delta\}\cap \{x|d(x,F)=\delta'\}=\emptyset \qquad
      (3)$
    \end{center}
    Behauptung:
    \begin{center}
      $D=\{\delta > 0|\mu(\{d(\cdot,F)=\delta'\})>0\}$
    \end{center}
    ist abzählbar. Denn
    \begin{center}
      $D_n=\{\delta > 0|\mu(\{d(\cdot,F)=\delta'\})>\frac{1}{n}\}$
    \end{center}
    enthält wegen $(3)$ maximal $n$ Elemente. Somit ist $D \subseteq \bigcup\limits_{n \in \N} D_n$ abzählbar. \\
    Wir finden also $\delta_k \searrow 0$ mit $\delta_k \in
    (0,\infty)\setminus D$ mit
    \begin{center}
      $F_k:=\{s(\cdot,F)\leq \delta_k\}$ ist $\mu$-randlos
    \end{center}
    Dann gilt aber
    \begin{eqnarray*}
      \limsup\limits_{n \to \infty} \mu_n(F)&\overset{F\subseteq F_k}{\leq}& \limsup\limits_{n \to \infty} \mu_n{F_k}\\
      &\overset{5)}{=}&\mu(F_k)\\
      &\overset{k \to \infty}{\to}& \mu(F) \qquad \text{ da } F_k \searrow F 
    \end{eqnarray*}
  \end{itemize}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Vorlesung vom 27.5.2013
%\textbf{Korollar 10.4}\\\\
\begin{cor}
  Sei $(\Sigma,\mathcal{A},P)$ ein W'Raum $X_n$ ($n \in \N$), $X$ ZVn
  mit Werten in $S$. Seien $\mu_n$ bzw. $\mu$ die entsprechenden
  Verteilungen. Dann gilt
  \begin{center}
    $X_n \overset{P}{\to} X \Rightarrow \mu_n \overset{w}{\to} \mu$
  \end{center}
\end{cor}
%\textit{Beweis}\\\\
\begin{proof} \ 
  Sei $f \in C_b(S)$ gleichmäßig stetig, d.h.
  \begin{center}
    $\forall \epsilon>0 \exists \delta>0$ so dass $\forall x,y \in S$
    mit $ d(x,y)<\delta \Rightarrow |f(x)-f(y)|<\epsilon$
  \end{center}
  Dann gilt
  \begin{eqnarray*}
    \left|\int fd\mu_n-\int fd\mu\right| &=& |\E[f\circ X_n]-\E[f\circ X]|\\
    &\leq & \int\limits_{\{d(X_n,X)<\delta\}} |f\circ X_n-f\circ X|dP+\int\limits_{\{d(X_n,X)\geq\delta\}} |f\circ X_n-f\circ X|dP\\
    &\leq & \epsilon + 2\Vert f\Vert_\infty \underbrace{P(d(X_n,X)\geq \delta)}_{\leq \frac{\epsilon}{2\Vert f\Vert_\infty}, n \geq n_0}\\
    &\leq & 2\epsilon
  \end{eqnarray*}
  Für allgemeine $f \in C_b(S)$ nutze das folgende Korollar. \qed\\\\\\
  Der Träger ("'support"') einer Funktion $f$ ist definiert durch
  \begin{center}
    $\supp(f):=\overline{\{x|f(x)\neq 0\}}$
  \end{center}
  Es sei
  \begin{center}
    $C_0(S)=\{f \in C_b(S)|\supp(f) $ kompakt $\}$
  \end{center}
  Jedes $f \in C_0(S)$ kann bzgl. $\Vert \cdot \Vert_\infty$ durch eine Lipschitz-stetige Funktion approximiert werden.\\\\\\
  Eine Folge $(\mu_n)_{n \in \N}$ von W'Maßen konvergiert vag gegen
  $\mu$, falls
  \begin{center}
    $\mu_n(f) \to \mu(f) \qquad \forall f \in C_0(S)$
  \end{center}
\end{proof}
%\textbf{Korollar 10.5}\\\\
\begin{cor}
  Seien $\mu_n,\mu$ W'Maße auf $(\Sigma,\mathcal{A})$ mit
  Verteilungsfunktion $F_n,F$. Dann sind äquivalent
  \begin{itemize}
  \item[1)] $\mu_n \to \mu$ vag
  \item[2)] $\mu_n \to \mu$ schwach
  \item[3)] $F_n(x) \to F(x)$ für alle Stetigkeitsstellen $x$ von $F$
  \item[4)] $\mu_n((-\infty,a])\to \mu((-\infty,a])$ für alle
    $\mu$-randlosen $(-\infty,a]$
  \end{itemize}
\end{cor}
%\textit{Beweis}\\\\
\begin{proof} \ 
  \begin{itemize}
  \item[1)$\Rightarrow$2)] Übung (Blatt 7)
  \item[2)$\Rightarrow$3)] Sei $x$ eine Stetigkeitsstelle von $F$
    \begin{center}
      $F(x_-)=F(x)$
    \end{center}
    d.h.
    \begin{center}
      $\mu((-\infty,x))=\mu((-\infty,x]) \Rightarrow \mu(\{x\})=0$
    \end{center}
    Also ist $(-\infty,x]~\mu$-randlos. Damit
    \begin{center}
      $\mu_n((-\infty,x])\to\mu((-\infty,x])$
    \end{center}
    nach dem Portemonteau-Theorem, also
    \begin{center}
      $F_n(x) \overset{n \to \infty}{\to} F(x)$
    \end{center}
    \item[3)$\Rightarrow$4)] Ist $(a,b]~\mu$-randlos, so gilt $\mu(\{a\})=\mu(\{b\})=0$ d.h. $a$ und $b$ sind Stetigkeitsstellen von $F$. Also wie in 2)$\Rightarrow$3)\\\\
    \item[4)$\Rightarrow$1)] Sei $D=\{x \in \R $ mit $\mu(\{x\})=0\}$. Wie im
    Portemonteau-Theorem zeigt man $\R\setminus D$ ist abzählbar. Also
    liegt $D$ dicht in $\R$. Sei nun $f \in C_0(\R))$ (glm. stetig!)
    und finde
    \begin{center}
      $c_1<\ldots<c_m \in D$
    \end{center}
    mit
    \begin{center}
      $\Vert f(\cdot)-\underbrace{\sum\limits_{k=1}^m
        f(c_{k-1})\1_{(c_{k-1},c_k]}(\cdot)}_{=:g}\Vert_\infty <
      \epsilon$
    \end{center}
    dann gilt
    \begin{eqnarray*}
      \left|\int fd\mu_n-\int fd\mu\right|&\leq &\underbrace{\left|\int(f-g)d\mu\right|}_{<\epsilon}+\left|\int gd\mu-\int g d\mu_n\right|+\underbrace{\left|\int(-f+g)d\mu_n \right|}_{<\epsilon}\\
      &\leq & 2\epsilon + \left|\int g d\mu_n-\int gd\mu\right|\\
      &\leq & 2\epsilon + \sum\limits_{k=1}^m f(c_{k-1})|\mu_n((c_{k-1},c_k])-\mu((c_{k-1},c_k])|
    \end{eqnarray*}
  \end{itemize}
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Freds LaTeX Code Vorlesung vom 29.5.2013
\chapter{Unabhängigkeit}


\section{Unabhängige Ereignisse}
\marginpar{Vorlesung 29.5.2013}
Es sei mit $\left(\Omega,\mathcal{A},\mathbb{P}\right)$ ein Wahrscheinlichkeitsraum
gegeben.
\begin{defn} \index{unabhängig}  % flashcard-name:  Was bedeutet Unabhängigkeit?
  Eine Familie $\left(A_{i}\right)_{i\in I}$ von Ereignissen heißt
  \emph{unabhängig}, falls gilt
  \begin{equation}
    P\left(\bigcap_{j\in J}A_{j}\right)=\prod_{i\in I}P\left(A_{i}\right)\ \forall\underset{\left|J\right|<\infty}{J\subseteq I}\label{eq:def1.1}
  \end{equation}
  Eine Familie $\left(B_{i}\right)_{i\in I}$ von Mengensystemen (z.B.
  $\sigma$-Algebren) heißt \emph{unabhängig}, falls \nameref{eq:def1.1}für
  alle $A_{j}\in B_{j}$ gilt.
\end{defn}
\begin{prop}  % flashcard-name: Was gilt für durchschnittsstabile Mengensysteme?
  Seien $\left(B_{i}\right)_{i\in I}$ durchschnitts-stabile unabhängige
  Mengensysteme. Dann gilt
  \begin{itemize}
  \item [{(i)}] Die $\sigma$-Algebren $\sigma\left(B_{i}\right)$ mit $i\in I$
    sind unabhängig.
  \item [{(ii)}] Sind $J_{k}$ $k\in\mathcal{K}$ disjunkte (nicht notwendig
    endliche) Teilmengen von $I$, so sind
    \[
    \sigma\left(\bigcup_{l\in J_{k}}B_{l}\right)\ \left(k\in\mathcal{K}\right)
    \]
    unabhängig. \label{s1.2(ii)}
  \end{itemize}
\end{prop}
\begin{proof}
  \textbf{\emph{(i)}} Seien $A_{j1}\in\sigma\left(B_{j1}\right),\ldots$
  $A_{jn}\in\sigma\left(B_{jn}\right)\ \left(n\in\mathbb{N}\right)$.
  Für $j_{2},\ldots,j_{n}$ sei $A_{jl}\in B_{jl}$. Definiere
  \begin{equation}
    \mathcal{D}_{j1}:=\left\{ A\in\sigma\left(B_{j1}\right):P\left(A\cap B_{j2}\cap\ldots\cap A_{jn}\right)\overset{(***)}{=}P\left(A\right)\prod_{l=2}^{n}P\left(A_{jl}\right)\right\} \label{eq:b1.2**-1}
  \end{equation}
  Nach Voraussetzung gilt
  \begin{equation}
    B_{j1}\subseteq\mathcal{D}_{j1}\label{eq:b1.2**}
  \end{equation}
  Ferner ist $\mathcal{D}_{j1}$ ein Dynkin-System. Da $B_{j1}$ durchschnittsstabil
  gilt
  \[
  \sigma\left(B_{j1}\right)=\mathcal{D}\left(B_{j1}\right)\subseteq D_{j}
  \]
  wegen \nameref{eq:b1.2**}. Also $(***)$ für alle $A\in\sigma\left(B_{j1}\right)$.
  Für $j_{2}$ wende das gleiche Argument an auf
  \[
  \sigma\left(B_{j1}\right),B_{j2},B_{j3},\ldots B_{jn}
  \]
  $\Rightarrow$ ersetze $B_{j2}$ durch $\sigma\left(B_{j2}\right)$
  usw.

  \textbf{\emph{(ii)}} langweilig
\end{proof}
\begin{example}
  Es seien $\left(A_{i}\right)_{i\in I}$ unabhängige Ereignisse. Dann
  sind auch 
  \[
  \sigma\left(A_{i}\right)=\left\{ \emptyset,\Omega,A_{i},A_{i}^{c}\right\} 
  \]
  $i\in I$ unabhängig. Insbesondere sind $\left(A_{i}^{c}\right)_{i\in I}$
  unabhängige Ereignisse. In der Regel sind $A_{i}$ und $A_{i}^{c}$
  nicht unabhängig
  \[
  P\left(A_{i}\cap A_{i}^{c}\right)=P\left(A_{i}\right)\left(1-P\left(A_{i}\right)\right)\overset{!}{=}0
  \]
  $\Rightarrow P\left(A_{i}\right)\in\left\{ 0,1\right\} $
\end{example}
\begin{rem}
  Paarweise unabhängig (d.h. für je $2$ Ereignisse) $\not\Rightarrow$
  unabhängig. Zum Beispiel
  \begin{eqnarray*}
    A & = & \left\{ \text{1. Wurf}=3\right\} \\
    B & = & \left\{ \text{2. Wurf}=5\right\} \\
    C & = & \left\{ \text{Summe}=7\right\} 
  \end{eqnarray*}
  $P\left(A\right)=\frac{1}{6}=P\left(B\right)=P\left(C\right)$ $P\left(A\cap B\right)=\frac{1}{36}=P\left(A\cap C\right)=P\left(B\cap C\right)$
  also sind $A,B,C$ paarweise unabhängig. Jedoch $P\left(A\cap B\cap C\right)=P\left(\emptyset\right)=0$.

  Seien $B_{n}\left(n\in\mathbb{N}\right)$ unabhängige $\sigma$-Algebren.
  ($B_{n}=$die zur Zeit $n$ observierbaren Ereignisse). Die \emph{terminale}
  \index{terminale sigma
    -Algebra@\emph{terminale $\sigma$-Algebra}} $\sigma$-Algebra (,,tail field``) ist gegeben durch
  \[
  \bigcap_{n\in\mathbb{N}}\sigma\left(\bigcup_{m\geq n}B_{m}\right)=:B_{\infty}
  \]
  = ,,Ereignisse, die nicht endlich vielen Realisierungen abhängen``.\\
  Im Münzwurfmodel
  \begin{itemize}
  \item $\left\{ \omega\in\left\{ 0,1\right\} ^{\mathbb{N}}|\lim_{n\to\infty}\frac{1}{n}\sum_{i=1}^{n}X_{i}\left(\omega\right)\text{ existiert}\right\} $
  \item $\limsup_{i\to\infty}\left\{ X_{i}=1\right\} $ ($+1$ kommt unendlich
    oft vor) 
  \end{itemize}
\end{rem}
\begin{prop}[0-1-Gesetz von Kolmogorov]
  \begin{comment}
    Eigentlich Satz 1.6
  \end{comment}


  Für alle $A\in B_{\infty}$ gilt
  \[
  P\left(A\right)\in\left\{ 0,1\right\} 
  \]
  (kein Zufall mehr auf $B_{\infty}$)
\end{prop}
\begin{proof}
  Nach Satz \ref{s1.2(ii)} (ii) sind $B_{1},\ldots,B_{n-1},\sigma\left(\bigcup_{m\geq n}B_{m}\right)$
  unabhängig. Per Definition gilt
  \[
  B_{\infty}\subseteq\sigma\left(\bigcup_{m\geq n}B_{m}\right)\ \forall n\in\mathbb{N}
  \]
  Also sind auch für alle $n$
  \[
  B_{1},\ldots,B_{n-1},B_{\infty}
  \]
  unabhängig (,,weniger Ereignisse zu teste``). Also sind
  \[
  B_{1},B_{2}\ldots B_{\infty}
  \]
  unabhängig. Nach Satz \ref{s1.2(ii)} (ii) sind damit auch
  \[
  \sigma\left(\bigcup_{n\geq1}B_{n}\right)\text{ und }B_{\infty}
  \]
  unabhängig $\left(J_{1}=\left\{ 1,2,3\ldots\right\} ,J_{2}=\left\{ \infty\right\} \right)$.
  Da $B_{\infty}\subseteq\sigma\left(\bigcup_{n\geq1}B_{n}\right)$
  ist $B_{\infty}$ und $B_{\infty}$ unabhängig. Rest mit folgendem
  Lemma.
\end{proof}
\begin{lem}  % flashcard-name:   Sei $B\subset\mathcal{A}$ eine $\sigma$-Algebra mit $B$ unabhängig von $B$. Dann gilt?
  Sei $B\subset\mathcal{A}$ eine $\sigma$-Algebra mit $B$ unabhängig
  von $B$. Dann gilt:
  \[
  P\left(A\right)\in\left\{ 0,1\right\} \ \forall A\in B
  \]
\end{lem}
\begin{proof}
  Sei $A\in B$. Dann gilt
  \begin{eqnarray*}
    P\left(A\right) & = & P\left(A\cap A\right)=P\left(A\right)^{2}\\
    & \Rightarrow & P\left(A\right)\in\left\{ 0,1\right\} 
  \end{eqnarray*}
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Fred LaTeX der Vorlesung vom 3.6.2013
\begin{lem}[Borel-Cantelli] \marginpar{Vorlesung vom 3.6.2013}
  Seien $\left(A_{i}\right)_{i\in\mathbb{N}}$ Ereignisse
  \begin{itemize}
  \item [{(i)}] $\sum_{i\in\mathbb{N}}P\left(A_{i}\right)<\infty\Rightarrow$$P($unendlich
    viele $A_{i}$ treten ein$)=0$
  \item [{(ii)}] $\sum_{i\in\mathbb{N}}P\left(A_{i}\right)=+\infty$ und
    die $A_{i}$ sind unabhängig $\Rightarrow P\left(\limsup A_{i}\right)=1$
  \end{itemize}
\end{lem}
\begin{proof}
  \textbf{\textit{(i)}}\textit{ hatten wir schon.}

  \textbf{(ii)} Da
  \[
  \limsup A_{i}=\bigcap_{n\in\mathbb{N}}\bigcup_{m\geq n}A_{m}
  \]
  genügt es zu zeigen
  \[
  P\left(\bigcup_{m\geq n}A_{m}\right)=1\ \forall n\in\mathbb{N}
  \]
  Das ist äquivalent zu 
  \[
  P\left(\bigcap_{m\geq n}A_{m}^{c}\right)=0\ \forall n\in\mathbb{N}
  \]
  Wegen Unabhuangigkeit gilt
  \begin{eqnarray*}
    P\left(\bigcap_{m=n}^{n+k}A_{m}^{c}\right) & = & \prod_{m=n}^{n+k}P\left(A_{m}^{c}\right)\\
    & = & \prod_{m=n}^{n+k}\left(\underset{1-\alpha_{n}}{\underbrace{1-P\left(A_{m}\right)}}\right)
  \end{eqnarray*}
  für $\alpha_{n}\leq1$. Es gilt
  \begin{figure}[H]
    \begin{centering}
      \includegraphics[width=\columnwidth]{figs/borelcantelli}
      \par
    \end{centering}

    \caption{Skizze zu Borel-Cantelli}


  \end{figure}
  Also gilt
  \begin{eqnarray*}
    P\left(\bigcap_{m\geq n}A_{m}^{c}\right) & = & \lim_{k\to\infty}P\left(\bigcap_{m=n}^{n+k}A_{m}^{c}\right)\\
    & \leq & \lim_{k\to\infty}\prod_{m=n}^{n+k}\exp\left(-P\left(A_{m}\right)\right)\\
    & = & \lim_{k\to\infty}\exp\left(-\sum_{m=n}^{n+k}P\left(A_{m}\right)\right)\\
    & = & 0
  \end{eqnarray*}
  da $\sum P\left(A_{m}\right)=+\infty$
\end{proof}

\section{Unabhängige Zufallsvariablen}


\paragraph*{Ziel:}

Wir hatten gezeigt:
\[
X_{i}\in\mathcal{L}^{2}
\]
unkorreliert mit 
\[
\sup_{i}\sigma^{2}\left(X_{i}\right)<\infty
\]
Dann gilt
\[
\lim_{n\to\infty}\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\mathbb{E}\left[X_{i}\right]\right)=0\ P-f.s.
\]
Wir zeigen nun: $X_{i}\in\mathcal{L}^{1}$ unabhängig und identisch
verteilt (iid). Dann gilt
\[
\underset{\text{empirisches Mittel}}{\frac{1}{n}\sum_{i=1}^{n}X_{i}}\to\mathbb{E}\left[X_{1}\right]=:m
\]
Empirisches Mittel $\to$erwartetes Resultat eines einzelnen Versuches.
\begin{defn}  % flashcard-name: Wie ist Unabhängigkeit definiert?
  Eine Familie $\left(X_{i}\right)_{i\in I}$ von Zufallvariabeln auf
  $\left(\Omega,\mathcal{A},\mathbb{P}\right)$ heißt unabhängig, falls
  die von den Zufallsvariablen erzeugten Familie von $\sigma$-Algebren
  \[
  \left(\sigma\left(X_{i}\right)\right)_{i\in I}\ \left(\sigma\left(X_{i}\right)=\left\{ \left\{ x\in A|A\in\mathcal{B}\left(\overline{\mathbb{R}}\right)\right\} \right\} \right)
  \]
  unabhängig ist.
\end{defn}
\begin{rem}
  Sei $\left(X_{i}\right)_{i\in I}$ unabhängig
  \[
  h_{i}:\bar{\mathbb{R}}\to\bar{\mathbb{R}}\text{ meßbar}
  \]
  Dann gilt
  \[
  y_{i}=h_{i}\left(X_{i}\right)\ i\in I
  \]
  definiert eine Familie unabhängiger Zufallsvariablen.
\end{rem}
\begin{proof}
  Es gilt
  \[
  y_{i}^{-1}\left(A\right)=\underset{\in\sigma\left(X_{i}\right)}{\underbrace{X_{i}^{-1}\circ\underset{\in\mathcal{B}\left(\bar{\mathbb{R}}\right)}{\underbrace{h_{i}^{-1}\left(A\right)}}}}\ \mathcal{A}\in\mathcal{B}\left(\bar{\mathbb{R}}\right)
  \]
  D.h.
  \[
  \sigma\left(y_{i}\subseteq\sigma\left(X_{I}\right)\right)
  \]
\end{proof}
\begin{prop}  % flashcard-name:   Seien $X_{1},X_{2},\ldots\geq0$ unabhängig. Dann?
  Seien $X_{1},X_{2},\ldots\geq0$ unabhängig. Dann 
  \[
  \mathbb{E}\left[X_{1}\ldots X_{n}\right]=\prod_{i=1}^{n}\mathbb{E}\left[X_{i}\right]
  \]
\end{prop}
\begin{proof}
  OBdA $n=2$ (Rest per Induktion). Angenommen $\left(X_{1}=X,X_{2}=Y\right)$
  \[
  X=\sum\alpha_{j}+\1_{A_{j}},\ Y=\sum\beta_{j}\1_{B_{j}}
  \]
  mit $A_{i}$ von $B_{i}$ unabhängig. Dann gilt
  \begin{eqnarray*}
    \mathbb{E}\left[X\ Y\right] & = & \sum_{i,j}\alpha_{j}\beta_{i}\underset{{=P\left(A_{j}\cap B_{i}\right)\atop =P\left(A_{j}\right)\cdot P\left(B_{i}\right)}}{\underbrace{\mathbb{E}\left[\1_{A_{j}}\cdot\1_{B_{i}}\right]}}\\
    & = & \sum_{i,j}\alpha_{j}\beta_{i}P\left(A_{j}\right)\cdot P\left(B_{i}\right)\\
    & = & \mathbb{E}\left[X\right]\cdot\mathbb{E}\left[Y\right]
  \end{eqnarray*}
  Für allgemeine Zufallsvariablen, wähle 
  \[
  X_{n}:=\sum_{k=0}^{n\cdot2^{n}-1}k\cdot2^{-n}\1_{\left\{ k\cdot2^{-n}\leq X<\left(k+1\right)2^{-n}\right\} }
  \]
  analog für $Y_{n}$. Dann gilt
  \[
  X_{n}\nearrow X,\ Y_{n}\nearrow Y
  \]
  und $X_{n}$ und $Y_{n}$ sind unabhängig. Mit monotoner Konvergenz
  folgt dann
  \begin{eqnarray*}
    \mathbb{E}\left[X\cdot Y\right] & = & \lim_{n\to\infty}\mathbb{E}\left[X_{n}\cdot Y_{n}\right]\\
    & = & \lim_{n\to\infty}\left(\mathbb{E}\left[X_{n}\right]\cdot\mathbb{E}\left[Y_{n}\right]\right)\\
    & \overset{\text{monotone}}{\underset{Konvergenz}{=}} & \mathbb{E}\left[X\right]\cdot\mathbb{E}\left[Y\right]
  \end{eqnarray*}
\end{proof}
\begin{rem} \ 
  \begin{itemize}
  \item[(i)] Da $X,Y\in\mathcal{L}^{2}$
    \[
    \mathbb{E}\left[X\cdot
      Y\right]=\mathbb{E}\left[X\right]\mathbb{E}\left[Y\right]+2cov\left(X,Y\right)
    \]
    gilt Unabhängigkeit$\Rightarrow$Unkorreliert.
  \item[(ii)] Die Umkehrung gilt i.d.R. nicht
    \[
    X\sim\mathcal{N}\left(0,1\right)\ y=x^{2}
    \]
    Dann gilt
    \begin{eqnarray*}
      \mathbb{E}\left[X\cdot Y\right] & = & \mathbb{E}\left[X^{3}\right]=0\\
      & = & \mathbb{E}\left[X\right]\mathbb{E}\left[X^{2}\right]
    \end{eqnarray*}
    Aber $X,Y$ nicht unabhängig!
  \end{itemize}
\end{rem}
\begin{cor} % flashcard-name:   Seien $X,Y\in\mathcal{L}^{1}$ unabhängig. Dann gilt?
  Seien $X,Y\in\mathcal{L}^{1}$ unabhängig. Dann gilt
  \[
  X\cdot Y\in\mathcal{L}^{1}
  \]
  und $\mathbb{E}\left[X\cdot Y\right]=\mathbb{E}\left[X\right]\cdot\mathbb{E}\left[Y\right]$.
\end{cor}

\section{Kolmogorov'sches Gesetz der großen Zahlen}
\begin{prop}[Kolmogorov] \index{Kolmogorov} % flashcard-name: Für $(X_i)_{i\in\mathbb{N}}\in\mathbb{L}^1$. Dann gilt?
  Seien $\left(X_{i}\right)_{i\in\mathbb{N}}$ i.i.d. Zufallsvariablen in $\mathcal{L}^{1}$
  mit $m:=\mathbb{E}\left[X_{i}\right]$ $i\in\mathbb{N}$. Dann gilt
  \begin{equation}
    \frac{1}{n}\sum_{i=1}^{n}X_{i}\to m\ P-f.s.\label{eq:kolmogorov}
  \end{equation}

\end{prop}

\begin{prop}[Etemadi] \index{Etemadi}

  Seien $\left(X_{i}\right)_{i\in\mathbb{N}}$ \emph{paarweise }unabhängig
  in $\mathcal{L}^{1}$, identisch verteilt. Dann gilt \ref{eq:kolmogorov}
  \[
  \frac{1}{n}\sum_{i=1}^{n}X_{i}\to m\ P-f.s.
  \]
\end{prop}
\begin{proof}[Etemadi] \index{Etemadi}

  Es seien oBdA $X_{i}\geq0$ (sonst auf $X_{i}^{+}$ und $X_{i}^{-}$
  getrennt anwenden).
  \begin{itemize}
  \item [{(A)}] Wir zeigen zunächst: wir können die $X_{i}$ abschneiden.
    Sei dazu 
    \begin{eqnarray*}
      \tilde{X}_{i} & = & \1_{\left\{ X_{i}<1\right\} }X_{i}\\
      & (= & h_{i}\left(X_{i}\right),h\left(x\right)=x\cdot\1_{\left\{ X<i\right\} }
    \end{eqnarray*}
    D.h. die $\tilde{X}_{i}$ sind paarweise unabhängig. Sei $\tilde{S}_{n}:=\sum_{i=1}^{n}\tilde{X}_{i}$.
    Wir wollen zeigen:
    \begin{equation}
      P\left[\lim_{n\to\infty}\frac{1}{n}\left(S_{n}-\tilde{S}_{n}\right)=0\right]=1\label{eq:etanadi}
    \end{equation}
    Wir wenden dazu Borell-Cantelli an. Es gilt
    \begin{eqnarray*}
      \sum_{n\geq1}\mathbb{P}\left[X_{n}\neq\tilde{X}_{n}\right] & = & \sum_{n\geq1}P\left[X_{n}\geq n\right]\\
      & \overset{\text{gleichmäßig}}{\underset{\text{Verteilt}}{=}} & \sum_{n\geq1}P\left[X_{1}\geq n\right]\\
      & = & \sum_{n\geq1}\sum_{k=n}^{\infty}P\left[X_{1}\in[k,k+1)\right]\\
      & = & \sum_{k=1}^{\infty}\underset{\mathbb{E}\left[k\cdot\1_{\left\{ X_{1}\in[k,k+1)\right\} }\right]\leq\mathbb{E}\left[X_{1}\cdot\1_{\left\{ X\in[k,k+1)\right\} }\right]}{\underbrace{k\cdot P\left[X_{1}\in[k,k+1)\right]}}\\
      & \leq & \mathbb{E}\left[X_{1}\right]<\infty
    \end{eqnarray*}
    Mit Borel-Cantelli gilt dann
    \[
    P\left[X_{n}\neq\tilde{X}_{n}\text{ undendlich oft}\right]=0
    \]
    und somit gilt \ref{eq:etanadi}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
    %% Vorlesung vom 5.6.2013
  \item [{(B)}] \marginpar{Vorlesung vom 5.6.2013}Wir wissen ,,Schnelle
    Stochastiische Konvergenz``$\Rightarrow$``f.s. Konvergenz``, also
    Konvergenz entlang einer Teilfolge. Sei $\alpha>1$ und 
    \[
    k_{n}:=L\alpha^{n}\lrcorner=\text{größte ganze Zahl}\leq\alpha^{n}
    \]
    d.h.
    \[
    \alpha^{n}-1<k_{n}\leq\alpha^{n}
    \]
    Angenommen, wir können zeigen:
    \begin{equation}
      \frac{\tilde{S}_{k_{n}}-\mathbb{E}\tilde{S}_{k_{n}}}{k_{n}}\to0\ P-f.s.\label{eq:etanadi(B)}
    \end{equation}
    wobei
    \[
    \tilde{S}_{k_{n}}=\sum_{i=1}^{k_{n}}\tilde{X}_{i}
    \]
    (zeigen wir in \textbf{(C)}). Dann folgt die Aussage des Satzes, denn:
    \[
    \frac{1}{k}\mathbb{E}\left[\tilde{S}_{k_{n}}\right]=\frac{1}{k_{n}}\sum_{i=1}^{k_{n}}\underset{\mathbb{E}\left[X_{i}\1_{\left\{ X_{i}<i\right\} }\right]\overset{identisch}{\underset{verteilt}{=}}\underset{i\to\infty\nearrow\mathbb{E}\left[X_{1}\right]=m\text{ mit monotoner Konvergenz}}{\underbrace{\mathbb{E}\left[X_{1}\cdot\1_{\left\{ X_{1}<i\right\} }\right]}}}{\underbrace{\mathbb{E}\left[\tilde{X}_{i}\right]}}
    \]
    Damit also
    \[
    \lim_{n\to\infty}\frac{1}{k_{n}}\mathbb{E}\left[\tilde{S}_{k_{n}}\right]=m
    \]
    Damit folgt dann mit \ref{eq:etanadi(B)}
    \[
    \lim_{n\to\infty}\frac{1}{k_{n}}\tilde{S}_{k_{n}}=m\ P-f.s.
    \]
    D.h. es existiert eine Nullmenge $N_{\alpha}$ mit 
    \[
    \frac{1}{k_{n}}\tilde{S}_{k_{n}}\left(\omega\right)\to m\ \forall\omega\notin N_{\alpha}
    \]
    Wir befreien uns nun von der Teifolge $\left(k_{n}\right)$. Sei $l\in\mathbb{N}$.
    Dann existiert ein eindeutiges $n\in\mathbb{N}$ mit
    \[
    l\in[k_{n},k_{n+1})
    \]
    Damit folgt 
    \[
    \underset{\to\frac{1}{\alpha}}{\underbrace{\frac{k_{n}}{k_{n+1}}}}\cdot\underset{\to m}{\underbrace{\frac{\tilde{S}_{k_{n}}}{k_{n}}}}\leq\frac{\tilde{S}_{l}}{l}\leq\underset{\to\alpha}{\underbrace{\frac{k_{n+1}}{k_{n}}}}\cdot\underset{\to m}{\underbrace{\frac{\tilde{S}_{k_{n+1}}}{k_{n+1}}}}
    \]
    (da $X_{i}\geq0$) D.h. für alle $\omega\notin N_{\alpha}$ gilt
    \[
    \frac{1}{\alpha}\cdot m\leq\liminf_{l\to\infty}\frac{\tilde{S}_{l}\left(\omega\right)}{l}\leq\limsup_{l\to\infty}\frac{\tilde{S}_{l}\left(\omega\right)}{l}\leq\alpha\cdot m
    \]
    Wähln nun $\alpha_{n}\searrow1$ mit entsprechender Nullmenge $N_{\alpha_{n}}$
    und setze
    \[
    N:=\bigcup_{n}N_{\alpha_{n}}\ P\left(N\right)=0
    \]
    Dann gilt für $\omega\notin N$:
    \[
    \underset{\to m}{\underbrace{\frac{1}{\alpha_{n}}m}}\leq\liminf_{l\to\infty}\frac{\tilde{S}_{l}\left(\omega\right)}{l}\leq\limsup_{l\to\infty}\frac{\tilde{S}_{l}\left(\omega\right)}{l}\leq\underset{\to m}{\underbrace{\alpha_{n}\cdot m}}
    \]
    D.h. für alle $\omega\notin N$ gilt
    \[
    \lim_{l\to\infty}\frac{\tilde{S}_{l}\left(\omega\right)}{l}=m
    \]

  \item [{(C)}] Wir zeigen nun schnelle stochastische Konvergenz entlang
    $\left(k_{n}\right)$. Dazu reicht es zu zeigen (Korrolar I 1.10)
    \[
    \sum_{n\geq1}P\left[\left|\frac{\tilde{S}_{k_{n}}-\mathbb{E}\left[\tilde{S}_{k_{n}}\right]}{k_{n}}\right|\geq\varepsilon\right]<\infty
    \]
    Dann folgt \ref{eq:etanadi(B)}. Aus ,,paarweise unabhängig`` folgt
    ,,paarweise unkorreliert``. Also mit Tschebyscheff: 
    \begin{eqnarray*}
      P\left[\left|\frac{\tilde{S}_{k_{n}}-\mathbb{E}\left[\tilde{S}_{k_{n}}\right]}{k_{n}}\right|\geq\varepsilon\right] & \leq & \frac{1}{\varepsilon^{2}k_{n}^{2}}\sum_{i=1}^{k_{n}}Var\left(\tilde{X}_{i}\right)\\
      & \leq & \frac{1}{\varepsilon^{2}}\frac{1}{k_{n}}\sum_{i=1}^{k_{n}}\underset{<\infty}{\underbrace{\mathbb{E}\left[\tilde{X}_{i}^{2}\right]}}
    \end{eqnarray*}
    Also müssen wir zeigen:
    \begin{eqnarray*}
      S & = & \sum_{n\geq1}\left(\frac{1}{k_{n}^{2}}\sum_{i=1}^{k_{n}}\mathbb{E}\left[\tilde{X}_{i}^{2}\right]\right)\\
      & = & \sum_{{\left(i,n\right)\in\mathbb{N}^{2}\atop i\leq k_{n}}}\frac{1}{k_{n}^{2}}\mathbb{E}\left[\tilde{X}_{i}^{2}\right]
    \end{eqnarray*}
    Dazu zeigen wir unten:
    \[
    \sum_{n:k_{n}\geq i}\frac{1}{k_{n}^{2}}\leq\frac{c}{i^{2}}
    \]
    für eine Konstante $c<\infty$. Angenommen, dies gilt. Dann folgt:
    \begin{eqnarray}
      S & = & \sum_{i=1}^{\infty}\left(\sum_{n:k_{n}\geq i}\frac{1}{k_{n}^{2}}\right)\mathbb{E}\left[\tilde{X}_{i}^{2}\right]\nonumber \\
      & \overset{(*)}{\leq} & \sum_{i=1}^{\infty}\frac{c}{i^{2}}\mathbb{E}\left[\tilde{X}_{i}^{2}\right]\label{eq:etanadi(C)}\\
      & \overset{identisch}{\underset{verteilt}{=}} & c\cdot\sum_{i=1}^{\infty}\frac{1}{i^{2}}\mathbb{E}\left[\1_{\left\{ X_{1}<i\right\} }\cdot X_{1}^{2}\right]\nonumber \\
      & \leq & c\cdot\sum_{i=1}^{\infty}\left\{ \frac{1}{i^{2}}\sum_{l=1}^{i}l^{2}P\left[X_{i}\in[l-1,l)\right]\right\} \nonumber \\
      & = & c\cdot\sum_{l=1}^{\infty}\left(l^{2}\left(\sum_{i=l}^{\infty}\frac{1}{i^{2}}\right)P\left[X_{i}\in[l-1,l)\right]\right)\nonumber 
    \end{eqnarray}
    Erinnerung:
    \begin{eqnarray*}
      \sum_{i=l}^{\infty}\frac{1}{i^{2}} & \leq & \frac{1}{l^{2}}+\sum_{i=l+1}^{\infty}\frac{1}{i\left(i-1\right)}\\
      & = & \frac{1}{l^{2}}+\sum_{i=l+1}^{\infty}\left(\frac{1}{i-1}-\frac{1}{i}\right)\\
      & = & \frac{1}{l^{2}}+\frac{1}{l}\leq\frac{2}{l}
    \end{eqnarray*}
    Also
    \begin{eqnarray*}
      S & \leq & 2\cdot c\sum_{l=1}^{\infty}l\cdot P\left[X_{1}\in[l-1,l)\right]\\
      & \leq & 2\cdot c\left(\mathbb{E}X_{1}+1\right)\\
      & < & \infty
    \end{eqnarray*}

  \item [{(D)}] Es bleibt \ref{eq:etanadi(C)} ({*}) zu zeigen
    \[
    \sum_{n:k_{n}\geq i}\frac{1}{k_{n}^{2}}\leq\frac{c}{i^{2}}
    \]
    Es gilt
    \[
    k_{n}=\llcorner\alpha^{n}\lrcorner\ k_{n}>\alpha^{n}-1\overset{\alpha>1}{>}\alpha^{n}-\alpha^{n-1}=\alpha^{n}\underset{=:c_{\alpha}}{\underbrace{\left(\frac{\alpha-1}{\alpha}\right)}}
    \]
    Sei $n_{i}$ die kleinste natürliche Zahl mit 
    \begin{equation}
      k_{n_{i}}=\llcorner\alpha^{n_{i}}\lrcorner\geq i\ \left(\alpha^{n_{i}}\geq i\right)\label{eq:etanadi(D)}
    \end{equation}
    Damit gilt
    \[
    \left\{ n|k_{n}\geq i\right\} =\left\{ n|n\geq n_{i}\right\} 
    \]
    und somit
    \begin{eqnarray*}
      \sum_{n:k_{n}\geq i}\frac{1}{k_{n}^{2}} & \leq & c_{\alpha}^{-2}\cdot\sum_{n\geq n_{i}}\frac{1}{\alpha^{2n}}\\
      & = & c_{\alpha}^{-2}\frac{1}{1-\alpha^{-2}}\alpha^{-2n_{i}}\\
      & \overset{\ref{eq:etanadi(D)}}{\leq} & \frac{c_{\alpha}^{-2}}{1-\alpha^{-2}}\frac{1}{i^{2}}\\
      & = & \frac{c}{i^{2}}
    \end{eqnarray*}

  \end{itemize}
\end{proof}
\begin{example}
  \begin{comment}
    3.4
  \end{comment}
  {} Seien $Y_{n}$ mit $n\in\mathbb{N}$ i.i.d. Zufallsvariablen $Y_{n}\geq0$ mit
  $\mathbb{E}Y_{n}=m$. Definiere
  \begin{eqnarray*}
    X_{n+1} & = & Y_{n}\cdot X_{n}\ (+B_{n})\\
    X_{1} & = & x
  \end{eqnarray*}
  Dann gilt $\left(x=1\right)$
  \[
  x_{n}=\prod_{i=1}^{n}y_{i},\ \mathbb{E}\left[X_{n}\right]=m^{n}
  \]
  Wie entwickelt sich 
  \[
  X_{n}\left(\omega\right)\text{ für }n\to\infty?
  \]
  Spiel: $X_{n}\left(\omega\right)$ EUR-Betrag zur Zeit $n\in\mathbb{N}$.
  Wir setzen jeweils $\frac{1}{2}X_{n}$ ein und 
  \begin{itemize}
  \item gewinnen das $c$-fache des Einsatzes mit Wahrscheinlichkeit $\frac{1}{2}$
  \item verlieren den Einsatz
  \end{itemize}
  \[
  X_{n+1}=\frac{1}{2}X_{n}+\begin{cases}
    c\frac{1}{2}X_{n}\\
    0
  \end{cases}=:Y_{n}\cdot X_{n}
  \]
  Angenommen $\ln Y_{1}\in\mathcal{L}^{1}$. Dann gilt
  \begin{eqnarray*}
    \frac{1}{n}\ln X_{n} & = & \frac{1}{n}\sum_{i=1}^{n}\ln Y_{i}\\
    & \overset{Kolmogorov}{\longrightarrow} & \mathbb{E}\left[\ln Y_{1}\right]=:\alpha
  \end{eqnarray*}
  Für $\alpha<0:$ dann existiert $\varepsilon>0$ mit $\alpha+\varepsilon<0$
  und
  \begin{eqnarray*}
    X_{n}\left(\omega\right) & \leq & e^{n\left(\alpha+\varepsilon\right)}\text{für }n\geq N\left(\omega\right)\\
    & \to & 0\text{ exponentiell schnell}
  \end{eqnarray*}
  Analog für $\alpha>0$
  \[
  X_{n}\left(\omega\right)\geq e^{n\left(\alpha-\varepsilon\right)}\nearrow\infty
  \]
\end{example}
\begin{fact*}
  $X_{n+1}=Y_{n}X_{n}+B_{n}$ mit $\left(Y_{n},B_{n}\right)$ i.i.d.
  gilt dann $\mathbb{E}\left[\ln Y_{1}\right]<0$ so verhält sich $\left(X_{n}\right)$
  asymptotisch vernünftig (,,stabil``).
\end{fact*}
zurück zum Spiel: sie $2<c<3$ Durch direkte Berechnung
\[
m=\mathbb{E}\left[Y_{1}\right]>1\text{ da }c>2
\]
Also
\[
\mathbb{E}\left[X_{n}\right]=m^{n}\nearrow\infty
\]
Gleichzeitig gilt 
\[
\mathbb{E}\left[\ln Y_{1}\right]<0\text{, da }c<3
\]
Damit 
\[
X_{n}\left(\omega\right)\to0\ P-f.s.
\]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Vorlesung vom 10.6.2013

\marginpar{Vorlesung vom 10.6.2013}

\paragraph*{Motivation: }

Seien $X_{1},X_{2},\ldots$ unabhängig und normalverteilt
\[
X_{i}\sim\mathcal{N}\left(m,\sigma^{2}\right)
\]
mit unbekannten $m\in\mathbb{R}$ und $\sigma^{2}>0$. Nach Komogorov:
\[
m_{n}:=\frac{1}{n}\sum_{i=1}^{n}X_{i}\left(\omega\right)\to m\ \mathbb{P}-f.s.
\]
Kolmogorov angewendet auf die $X_{i}^{2}$ liefert 
\[
\sigma_{n}^{2}:=\frac{1}{n}\sum\left(X_{i}^{2}-m_{n}\right)\overset{P-f.s.}{\longrightarrow}\sigma^{2}
\]
Damit gilt für $f\in C_{b}\left(\mathbb{R}\right)$ auch 
\[
\int f\left(x\right)\underset{{\text{Dichte der }\atop \mathcal{N}\left(m_{n}\sigma_{n}^{2}\right)\text{-Verteilung}}}{\underbrace{\varphi_{\left(m_{n},\sigma_{n}^{2}\right)}\left(x\right)}}dx=\int f\left(x\right)\varphi_{\left(m,\sigma^{2}\right)}\left(x\right)dx
\]
nach Lebesque, da 
\[
\varphi_{\left(m_{n},\sigma_{n}^{2}\right)}\left(x\right)\overset{f.s.}{\longrightarrow}\varphi_{\left(m,\sigma^{2}\right)}\left(x\right)\ \forall x\in\mathbb{R}
\]
und 
\[
\varphi_{\left(m_{n},\sigma_{n}^{2}\right)}\left(x\right)\in C_{b}\left(\mathbb{R}\right),\ f\in C_{b}\left(x\right)
\]
D.h. wir haben
\[
\mathcal{N}\left(m_{n}\left(\omega\right),\sigma_{n}^{2}\left(\omega\right)\right)\overset{f.s.}{\longrightarrow}\mathcal{N}\left(m,\sigma^{2}\right)
\]
schwach, d.h. die Folge 
\[
\left(\mathcal{N}\left(m_{n}\left(\omega\right),\sigma_{n}^{2}\left(\omega\right)\right)\right)_{n\in\mathbb{N}}
\]
konvergiert fast-sicher (bzgl. $\omega\in\Omega$) schwach gegen $\mathcal{N}\left(m,\sigma^{2}\right)$. 


\paragraph*{Frage:}

Wie kann man die Verteilung $\mu$ der $X_{i}$ schätzen? Wir wissen
$\mu=\nu$ falls
\[
\mu\left(f\right)=\nu\left(f\right)\ \forall f\in C_{b}\left(\mathbb{R}\right)
\]
Wir definieren die \index{empirische Verteilung@empirische\emph{ }Verteilung}\emph{empirische}
\emph{Verteilung}
\[
\rho_{n}\left(\omega,\bullet\right)=\frac{1}{n}\sum_{i=1}\delta_{X_{i}\left(\omega\right)}\left(\bullet\right)
\]
mit 
\[
\delta_{X}\left(A\right)=\begin{cases}
  1 & \text{falls }x\in A\\
  0 & \text{sonst}
\end{cases}
\]
Für $A\in\mathcal{B}\left(\mathbb{R}\right)$ also
\begin{eqnarray*}
  \rho_{n}\left(\omega,A\right) & = & \frac{1}{n}\sum_{i=1}^{n}\delta_{X_{i}\left(\omega\right)}\left(A\right)\\
  & = & \text{relative Häufigkeit eines Besuchs in der Menge }A
\end{eqnarray*}
$\rho_{n}\left(\omega_{i}\right)$ ist ein zufäliiges Wahrscheinlichkeitsmaß
auf $\left(\mathbb{R},\mathcal{B}\left(\mathbb{R}\right)\right)$. 


\paragraph*{Frage:}

Konvergiert die Folge 
\[
\left(\rho_{n}\left(\omega,\bullet\right)\right)_{n\in\mathbb{N}}
\]
gegen $\mu$ und wenn ja in welchem Sinn?
\begin{prop}  % flashcard-name: P-fast alle $\omega \in \Omega$ sind im Rahmen des Gesetzes von Klomogorov?
  Für P-fast alle $\omega\in\Omega$ gilt (im Rahmen des Gesetzes von
  Kolmogorov)
  \[
  \rho_{n}\left(\omega,\bullet\right)\overset{w}{\longrightarrow}\mu
  \]
\end{prop}
\begin{proof}
  Wir definieren zunächst die empirische Verteilungsfunktion
  \[
  F_{n}:\left(\omega,x\right)=\rho_{n}m(\omega,(-\infty,x])
  \]
  und 
  \[
  F\left(X\right):=\mu\left((-\infty,x]\right)
  \]
  Nach Kolmogorov (angewendet auf die Zufallsvariablen $\1_{(-\infty,x]}\circ X_{i}$)
  gilt 
  \begin{eqnarray*}
    F_{n}\left(\omega,x\right) & \overset{f.s.}{\longrightarrow} & \mathbb{E}\left[\1_{(-\infty,x]}\circ X_{i}\right]\\
    & = & P\left[X_{1}\leq X\right]=F\left(X\right)
  \end{eqnarray*}
  D.h. $\forall x\in\mathbb{R}\exists N_{x}\in\mathcal{A}$ mit $P\left(N_{x}\right)=0$,
  sodass 
  \[
  F_{n}\left(\omega,x\right)\to F\left(x\right)\forall\omega\notin N_{x}
  \]
  Wir definieren nun 
  \[
  N=\bigcup_{r\in\mathbb{Q}}N_{r},\ P\left(N\right)=0
  \]
  Seien nun $s,r\in\mathbb{Q}$ mit $s\leq x\leq r$ so gilt für $\omega\notin N$:
  \begin{eqnarray*}
    F\left(s\right) & = & \lim_{n\to\infty}F_{n}\left(\omega,s\right)\leq\liminf_{n\to\infty}F_{n}\left(\omega,x\right)\\
    & \leq & \limsup_{n\to\infty}F_{n}\left(\omega,x\right)\leq\limsup_{n\to\infty}F_{n}\left(\omega,r\right)\\
    & = & F\left(r\right)
  \end{eqnarray*}
  Sei nun $F$ in $x$ stetig, wähle 
  \[
  s_{n}\nearrow x,\ r_{n}\searrow x,\ s_{n},r_{n}\in\mathbb{Q}
  \]
  und finde 
  \[
  F_{n}\left(\omega,x\right)\to F\left(x\right)\ \forall\omega\notin N
  \]
  (Portemanteau). \index{Portemanteau-Theorem}
\end{proof}

\section{Gemeinsame Verteilung und Faltung von Zufallsvariablen}


\paragraph*{Bisher: }

Summen unabhängiger/unkorrelierter Zufallsvariablen


\paragraph*{Jetzt:}

Summen abhängiger Zufallsvariablen (Faltung): Wie berechnet man 
\[
S_{n}:=\sum_{i=1}^{n}X_{i}
\]
wenn die Verteilung der $X_{i}$ bekannt ist?
\begin{defn}   % flashcard-name: Wie ist Verteilung definiert?
  Seien $X_{1}\ldots X_{n}$ reelwertige Zufallsvariablen auf $\left(\Omega,\mathcal{A},P\right)$.
  Dann heißt die Verteilung 
  \[
  \bar{\mu}:=P\circ\bar{X}^{-1}
  \]
  von $\bar{X}\left(\omega\right)=\left(X_{1}\left(\omega\right),\ldots,X_{n}\left(\omega\right)\right)$
  die \emph{gemeinsame Verteilung}\index{gemeinsame Verteilung} der
  $X_{1}\ldots X_{n}$.
\end{defn}
\begin{rem}
  \ 
  \begin{enumerate}
  \item $\bar{\mu}$ ist als Bildmaß von $\bar{X}$ unter $P$ wohldefiniert.
  \item Nach Satz I.11.5 ist $\bar{\mu}$ eindeutig festgelegt durch
    \[
    \bar{\mu}\left(A_{1}\times\ldots\times A_{n}\right)=P\left(\bigcap_{i=1}^{n}\left\{ X_{i}\in A_{i}\right\} \right)
    \]
    für $A_{i}\in\mathcal{B}\left(\mathbb{R}\right)$ $\left(i=1\ldots n\right)$ 
  \end{enumerate}
\end{rem}

\section*{Wiederholung zu Produktmaßen}

Seien $\mu_{1}\ldots\mu_{n}$ Wahrscheinlichkeitsmaßen auf $\left(\mathbb{R},\mathcal{B}\left(\mathbb{R}\right)\right)$
sowie $A_{1}\ldots A_{n}\in\mathcal{B}\left(\mathbb{R}\right)$. Wir
definieren 
\[
\underset{\bigotimes_{i=1}^{n}\mu_{i}}{\underbrace{\left(\mu_{1}\otimes\ldots\otimes\mu_{n}\right)}}\left(A_{1}\times\ldots\times A_{n}\right)=\prod_{i=1}^{n}\mu_{i}\left(A_{i}\right)
\]
Es existiert eine eindeutige Fortsetzung auf $\left(\mathbb{R}^{n},\mathcal{B}\left(\mathbb{R}^{n}\right)\right)$,
sodass 
\[
\bigotimes_{i=1}^{n}\mu_{i}\left(A\right)=\underset{n-\text{fach }}{\underbrace{\int_{\mathbb{R}}\ldots\int_{\mathbb{R}}}}\1_{A}\left(x_{1}\ldots x_{n}\right)\bigotimes_{i=1}^{n}\mu_{i}\left(dx_{i}\right)
\]

\begin{prop*}[Fubini] \index{Fubini}
  Sei $f:\mathbb{R}^{n}\to\mathbb{R}$ nicht-negativ oder $\bar{\mu}:=\bigotimes_{i=1}^{n}\mu_{i}$
  integrierbar so gilt jede Permutation $i_{1},\ldots,i_{n}$ von $\left\{ 1\ldots n\right\} $
  \[
  \int_{\mathbb{R}^{n}}f\left(x_{1},\ldots,x_{n}\right)\bar{\mu}\left(dx_{1},\ldots,dx_{n}\right)=\int_{\mathbb{R}}\left(\ldots\left(\int_{\mathbb{R}}f\left(x_{1},\ldots,x_{n}\right)\mu_{i_{1}}\left(dx_{i_{1}}\right)\right)\ldots\right)\mu_{i_{n}}\left(dx_{i_{n}}\right)
  \]
\end{prop*}
\begin{prop} % flashcard-name: Was gilt für ZVen mit gemeinsamer Verteilung?
  Seien $X_{1}\ldots X_{n}$ Zufallsvariablen auf $\left(\Omega,\mathcal{A},P\right)$
  mit (Rand-)Verteilungen $\mu_{1}\ldots\mu_{n}$ und gemeinsamer Verteilung
  $\bar{\mu}$. Dann gilt $X_{1}\ldots X_{n}$unabhängig $\Leftrightarrow\bar{\mu}=\bigotimes_{i=1}^{n}\mu_{i}$.
  Insbesondere gilt dann
  \begin{itemize}
  \item [{i)}] $\bar{\mu}$ ist eindeutig festgelegt durch die $\mu$. 
  \item [{ii)}] Sind die $\mu_{i}$ absolut-stetig mit Dichten $f_{i}$,
    so ist auch $\bar{\mu}$ absolut-stetig mit Dichte
    \begin{eqnarray*}
      \bar{f}\left(\bar{x}\right) & = & \prod_{i=1}^{n}f_{i}\left(x_{i}\right)\\
      \bar{x} & = & \left(x_{1},\ldots,x_{n}\right)
    \end{eqnarray*}

  \end{itemize}
\end{prop}
Wir kommen zum Begriff der \index{Faltung}\emph{Faltung} von Wahrscheinlichkeitsmaßen
\begin{defn} % flashcard-name: Wie ist Translation definiert?
  Sei $x\in\mathbb{R}$. Dann heißt 
  \begin{eqnarray*}
    T_{x}:\mathbb{R} & \to & \mathbb{R}\\
    y & \mapsto & x+y
  \end{eqnarray*}
  die \index{Translation}\emph{Translation} (um $x$). Für Wahrscheinlichkeitsmaße $\mu_{1},\mu_{2}$
  aud $\left(\mathbb{R},\mathcal{B}\left(\mathbb{R}\right)\right)$
  heißt 
  \[
  \left(\mu_{1}*\mu_{2}\right)\left(A\right)=\int_{\mathbb{R}}\left(\mu_{2}\circ T_{x}^{-1}\right)\left(A\right)\mu_{1}\left(dx_{1}\right)
  \]
  die \emph{Faltung}\index{Faltung} von $\mu_{1}$ und $\mu_{2}$.
\end{defn}
Es gilt
\begin{eqnarray*}
  \left(\mu_{1}*\mu_{2}\right)\left(A\right) & = & \int\mu_{2}\left(A-x_{1}\right)\mu_{1}\left(dx_{1}\right)\\
  & = & \int\mu_{1}\left(dx_{1}\right)\underset{\int\1_{A-x_{1}}\left(x_{2}\right)\mu_{2}\left(dx_{2}\right)}{\underbrace{\mu_{2}\left(A-x_{1}\right)}}\\
  & = & \int\mu_{1}\left(dx_{1}\right)\int\1_{A-x_{1}}\left(x_{2}\right)\mu_{2}\left(dx_{2}\right)\\
  & = & \int\mu_{1}\left(dx_{1}\right)\int\1_{A}\left(x_{1}+x_{2}\right)\mu_{2}\left(dx_{2}\right)\\
  & = & \int\int\1_{A}\left(x_{1}+x_{2}\right)\mu_{1}\left(dx_{1}\right)\mu_{2}\left(dx_{2}\right)
\end{eqnarray*}
Mit anderen Worten: Sind $X_{1},X_{2}$ unabhängig, mit Verteilung
$\mu_{1},\mu_{2}$ so ist 
\[
\mu_{1}*\mu_{2}
\]
gerade die Verteilung von $X_{1}+X_{2}$\@.
\begin{prop} % Name: Verteilungen und Dichten
  Seien $X_{1},X_{2}$ unabhängige Zufallsvariablen mit Verteilung $\mu_{1},\mu_{2}$.
  Dann gilt
  \begin{itemize}
  \item [{i)}] Die Verteilung von $X_{1}+X_{2}$ ist gegeben durch $\mu_{1}*\mu_{2}$
  \item [{ii)}] Hat $\mu_{2}$ ein Dichte $f_{2}$, so ist $\mu_{1}*\mu_{2}$
    absolut stetig mit $f\left(x\right)=\int f_{2}\left(x-x_{1}\right)\mu_{1}\left(dx_{1}\right)$. 
  \end{itemize}
\end{prop}
\begin{proof}
  \textbf{\textit{i)}}\textit{ klar}

  \textbf{ii)} 
  \begin{eqnarray*}
    \left(\mu_{1}*\mu_{2}\right)\left(A\right) & = & \int\mu_{1}\left(dx_{1}\right)\mu_{2}\left(A-x_{1}\right)\\
    & \overset{Dichte}{=} & \int\mu_{1}\left(dx_{1}\right)\int_{A-x_{1}}f\left(x_{2}\right)dx_{2}\\
    & \overset{x_{2}=x-x_{1}}{=} & \int\mu_{1}\left(dx_{1}\right)\int_{A}f\left(x-x_{1}\right)dx\\
    & \overset{Fubini}{=} & \int_{A}\underset{f\left(x\right)}{\underbrace{\left(\int\mu_{1}\left(dx_{1}\right)f_{2}\left(x-x_{1}\right)\right)dx}}
  \end{eqnarray*}
\end{proof}
\begin{example}
  \ 
  \begin{itemize}
  \item [{i)}] Seien $X_{1},X_{2}$ Poisson verteilt mit Parameter $\lambda_{1},\lambda_{2}$.
    Dann gilt
    \[
    X_{1}+X_{2}\sim\prod\left(\lambda_{1}+\lambda_{2}\right)
    \]

  \item [{ii)}] $X_{i}\sim\mathcal{N}\left(m_{i},\sigma_{i}^{2}\right)$
    \[
    X_{1}+X_{2}\sim\mathcal{N}\left(m_{1}+m_{2},\sigma_{1}^{2}+\sigma_{2}^{2}\right)
    \]
    
  \end{itemize}
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Vorlesung vom 12.6.2013

\subsection*{Charakteristische Funktionen und Fourier Transformation}

\marginpar{Vorlesung vom 12.6.2013} Wir hatten gesehen $X_{1},X_{2}$
unabhängig mit Verteilungen $\mu_{1},\mu_{2}$. Dann hat $X_{1}+X_{2}$
die Verteilung
\[
\mu_{1}*\mu_{2}\left(A\right)=\int\mu_{1}\left(dx_{1}\right)\mu_{2}\left(A-x_{1}\right)
\]
Haben $\mu_{1},\mu_{2}$ Dichten $f_{1},f_{2}$ so gilt $\mu_{1}*\mu_{2}$hat
dichte $f$ mit 
\[
f=f_{1}*f_{2},\ f\left(x\right)=\int f_{1}\left(x_{1}\right)f_{2}\left(x-x_{1}\right)dx
\]
Unpraktisch für den Zentralen Grenzwertsatz\index{Zentralen Grenzwertsatz}:
\[
\sqrt{n}\sum_{i=1}^{n}\left(X_{i}-\mathbb{E}X_{i}\right)\overset{n\to\infty}{\longrightarrow}?
\]
Sei $\mu$ ein Wahrscheinlichkeitsmaß auf $\left(\mathbb{R},\mathcal{B}\left(\mathbb{R}\right)\right)$.
Dann ist die charakteristische Funktion gegeben durch 
\[
\varphi\left(t\right):=\int_{-\infty}^{\infty}e^{itu}\mu\left(du\right)\ \left(t\in\mathbb{R},i=\sqrt{-1}\right)
\]
Es gilt 
\[
e^{iu}=\cos\left(u\right)+i\sin\left(u\right)
\]
dies liegt auf dem Einheitskreis da
\[
\left|e^{i\cdot u}\right|=1
\]
Hat eine Zufallsvariable $X$ die Verteiltung $\mu$, so ist die charakteristische
Funktion\index{charakteristische Funktion}
\[
\varphi_{x}\left(t\right)=\varphi\left(t\right)=\mathbb{E}\left[e^{i\cdot t\cdot X}\right]=\int_{-\infty}^{\infty}e^{i\cdot t\cdot X}\mu\left(dx\right)
\]



\paragraph*{Wir werden zeigen:}
\begin{itemize}
\item die charakteristische Funktion legt die Verteilung fest.
\item $\mu_{1}*\mu_{2}$ hat charakteristische Funktion $\varphi_{X_{1}}\cdot\varphi_{X_{2}}$
\item punktweise Konvergenz von charakteristischen Funktionen impiziert
  schwache Konvergenz der Verteilungen.
\end{itemize}

\subsection*{Momente und Ableitungen}

Es gilt
\[
\varphi\left(0\right)=e^{0}=1,\ \left|\varphi\left(t\right)\right|\leq1
\]
sowie 
\begin{eqnarray*}
  \left|\varphi\left(t+\varepsilon\right)-\varphi\left(t\right)\right| & \leq & \int_{-\infty}^{\infty}\left|e^{i\left(t+\varepsilon\right)u}-e^{itu}\right|\mu\left(du\right)\\
  & \leq & \int_{-\infty}^{\infty}\underset{\leq1}{\underbrace{\left|e^{itu}\right|}}\underset{\nearrow0\text{ für }\varepsilon\to0}{\underbrace{\left|\left(e^{i\varepsilon u}-1\right)\right|}}\mu\left(du\right)\\
  & \to & 0
\end{eqnarray*}
für $\varepsilon\to0$ nach Lebesque. D.h. sie ist gleichmäßig stetig.
Ferner gilt 
\begin{equation}
  \int_{0}^{x}\underset{u'}{\underbrace{\left(x-s\right)^{n}}}\underset{v}{\underbrace{e^{is}}}ds=\underset{=\frac{1}{n+1}x^{n+1}+\int_{0}^{x}\frac{i}{n+1}\left(x-s\right)^{n+1}e^{is}ds}{\underbrace{-\frac{1}{n+1}\left(x-s\right)^{n+1}e^{is}|_{0}^{x}}}+\int_{0}^{x}\frac{i}{n+1}\left(x-s\right)^{n+1}e^{is}ds\label{eq:5.1*}
\end{equation}
Für $n=0$ gilt
\begin{eqnarray*}
  \frac{1}{i}e^{iX}-\frac{1}{i} & = & x+i\int_{0}^{X}\left(x-s\right)e^{is}ds\\
  e^{iX} & = & 1+ix+i^{2}\int\ldots ds
\end{eqnarray*}
Per Induktion über $n$ folgt
\[
e^{iX}=\underset{\mbox{Taylorentwicklung mit}}{\underbrace{\sum_{k=0}^{n}\frac{\left(ix\right)^{k}}{k!}}}+\underset{\mbox{Integraldarstellung für den Rest-Term}}{\underbrace{\frac{i^{n+1}}{n!}\int_{0}^{X}\left(x-s\right)^{n}e^{is}ds}}
\]
Mit $\left(n-1\right)$ für $n$ in \ref{eq:5.1*} und einsetzen liefert
\[
e^{iX}=\sum_{k=0}^{n}\frac{\left(ix\right)^{k}}{k!}+\frac{i^{n}}{\left(n-1\right)!}\int_{0}^{X}\left(x-s\right)^{n-1}\left(e^{is}-1\right)ds
\]
Das liefert folgende Abschätzung:
\[
\left|e^{iX}-\sum_{k=0}^{n}\frac{\left(ix\right)^{k}}{k!}\right|\leq\min\left\{ \underset{\mbox{kleine }x}{\underbrace{\frac{\left|X\right|^{n+1}}{\left(n+1\right)!}}},\ \underset{\mbox{große }x}{\underbrace{\frac{2\left|X\right|^{n}}{n!}}}\right\} 
\]
Falls $X$ eine Zufallsvariable ist mit 
\[
\mathbb{E}\left|X\right|,\mathbb{E}\left|X\right|^{2},\ldots,\mathbb{E}\left|X\right|^{n+1}<\infty
\]
d.h. die ersten $\left(n+1\right)$ Momente existieren, so folgt
\[
\left|\varphi\left(t\right)-\sum_{k=0}^{n}\frac{\left(it\right)^{k}}{k!}\mathbb{E}\left[X^{k}\right]\right|\leq\mathbb{E}\left[\min\left\{ \frac{\left|tX\right|^{n+1}}{\left(n+1\right)!},\ \frac{2\left|tX\right|^{n}}{n!}\right\} \right]
\]
Gilt nun 
\[
\lim_{n\to\infty}\frac{\left|t\right|^{n}\mathbb{E}\left[\left|X\right|^{n}\right]}{n!}=0
\]
so haben wir folgende Reihendarstellung. 
\begin{equation}
  \varphi\left(t\right)=\sum_{k=0}^{\infty}\frac{\left(it\right)^{k}}{k!}\mathbb{E}\left[X^{k}\right]\label{eq:5.1**}
\end{equation}
Hat die Zufallsvariable $t\cdot X$ ein \index{exponentielles Moment}\emph{exponentielles
  Moment}, d.h. 
\[
\mathbb{E}\left[e^{\left|t\cdot X\right|}\right]<\infty
\]
so gilt wegen 
\[
\mathbb{E}\left[e^{\left|t\cdot X\right|}\right]=\sum_{k=0}^{\infty}\frac{\left|t\right|^{k}}{k!}\mathbb{E}\left[\left|X\right|^{k}\right]<\infty
\]
d.h. es gilt Formel \ref{eq:5.1**}. 
\begin{example}[Charakteristische Funktion der Normalverteilung] \index{Normalverteilung}
  Sei $X\sim\mathcal{N}\left(0,1\right)$. Dann gilt in der Tat
  \[
  \mathbb{E}\left[e^{\left|t\cdot X\right|}\right]<\infty
  \]
  Dann gilt 
  \begin{eqnarray*}
    \mathbb{E}\left[\left|X\right|^{p}\right] & = & \int_{-\infty}^{\infty}\left|x\right|^{p}f_{0,1}\left(x\right)dx\\
    & = & 2\int_{0}^{\infty}x^{p}f_{0,1}\left(x\right)dx\\
    & = & 2\int_{0}^{\infty}x^{p}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}dx
  \end{eqnarray*}
  dabei ist $f_{0,1}$ die Dichte der $\mathcal{N}\left(0,1\right)$
  Verteiltung. Wir substituieren $y=\frac{x^{2}}{2}$
  \[
  =\frac{1}{\sqrt{2\pi}}2^{\frac{p}{2}}\underset{\Gamma\left(\frac{p+1}{2}\right)\mbox{; vgl Blatt 7}}{\underbrace{\int_{0}^{\infty}y^{\frac{p+1}{2}}e^{-y}dy}}
  \]
  Also 
  \[
  \mathbb{E}\left[\left|X\right|^{p}\right]=\frac{1}{\sqrt{\pi}}2^{\frac{p}{2}}\Gamma\left(\frac{p+1}{2}\right)
  \]
  zur Erinnerung
  \[
  \Gamma\left(x+1\right)=x\Gamma\left(x\right),\ \Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}
  \]
  Für $p=2k$ $\left(k=1,2,\ldots\right)$ gilt somit 
  \begin{eqnarray*}
    2^{k}\Gamma\left(\frac{2k+1}{2}\right) & = & 2^{k}\Gamma\left(\frac{2k-1}{2}+1\right)\\
    & = & 2^{k}\left(\frac{2k-1}{2}\right)\Gamma\left(\frac{2k-1}{2}\right)\\
    & = & 2^{k-1}\Gamma\left(\frac{2k-1}{2}\right)\\
    & = & \ldots\\
    & = & \left(2k-1\right)\left(2k-3\right)\ldots3\cdot1\cdot\Gamma\left(\frac{1}{2}\right)
  \end{eqnarray*}
  Also 
  \[
  \mathbb{E}\left[\left|X\right|^{2k}\right]=\left(2k-1\right)\left(2k-3\right)\cdots5\cdot3\cdot1
  \]
  D.h. für $\varphi\left(t\right)$
  \begin{eqnarray*}
    \varphi\left(t\right) & = & \sum_{k=0}^{\infty}\frac{\left(it\right)^{k}}{k!}\mathbb{E}\left[X^{k}\right]\\
    & = & \sum_{k=0}^{\infty}\frac{\left(it\right)^{2k}}{\left(2k\right)!}\mathbb{E}\left[X^{2k}\right]\\
    & = & \sum_{k=0}^{\infty}\left(\frac{-t^{2}}{2}\right)^{k}\underset{=\frac{1}{k!}}{\underbrace{\frac{2^{k}}{(2k)!}\left(2k-1\right)\left(2k-3\right)\cdots3\cdot1}}\\
    & = & \sum_{k=0}^{\infty}\frac{1}{k!}\left(-\frac{t^{2}}{2}\right)^{k}\\
    & = & \exp\left(-\frac{t^{2}}{2}\right)
  \end{eqnarray*}
  Mit der Reihendarstellung 
  \[
  \varphi\left(t\right)=\sum_{k=0}^{\infty}\frac{\left(it\right)^{k}}{k!}\mathbb{E}\left[X^{k}\right]
  \]
  gilt
  \[
  \varphi^{(k)}\left(0\right)=i^{k}\mathbb{E}\left[X^{k}\right]
  \]
\end{example}
\begin{lem} % flashcard-name: gilt $\mathbb{E}\left[\left|X\right|^{k}\right]<\infty$ folgt was?
  Es gelte $\mathbb{E}\left[\left|X\right|^{k}\right]<\infty$ so folgt
  \[
  \varphi^{\left(k\right)}\left(0\right)=i^{k}\mathbb{E}\left[X^{k}\right]
  \]

\end{lem}

\paragraph*{Ausblick:}

$\varphi_{x_{1}+\ldots+x_{n}}$ für unabhängige Zufallsvariablen und $\varphi$
gibt $\mu$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Vorlesung vom 17.6.2013
\marginpar{Vorlesung vom 17.6.2013}


\paragraph*{Wiederholung (Analysis): }

Die Exponentialfunktion im Komplexen ist 
\[
\exp\left(z\right)=\sum_{k=0}^{\infty}\frac{z^{k}}{k!}\ \left(z\in\mathbb{C},z=x+iy;x,y\in\mathbb{R}\right)
\]
Für $x\in\mathbb{R}$ sei
\[
\cos\left(x\right)=\Re\left(e^{ix}\right),\ \sin\left(x\right)=\Im\left(e^{ix}\right)
\]
Es gilt $\left|e^{ix}\right|^{2}=e^{ix}\cdot\overline{e^{ix}}=e^{ix}\cdot e^{-ix}=e^{0}=1$.
Es gilt also insbesondere 
\[
e^{ix}=\cos\left(x\right)+i\sin\left(x\right)
\]
Euler-Formel 
\[
\cos\left(x\right)=\frac{1}{2}\left(e^{ix}+e^{-ix}\right)
\]
$\varphi_{X}\left(t\right)=\mathbb{E}\left[e^{it\cdot X}\right]$
falls alle $X^{k}\in\mathcal{L}^{1}$ so gilt 
\[
\varphi_{X}\left(t\right)=\sum_{k=0}^{\infty}\frac{\left(it\right)^{k}}{k!}\mathbb{E}\left[X^{k}\right]
\]
Für $Z\sim\mathcal{N}\left(0,1\right)$ gilt
\[
\mathbb{E}\left[e^{\left|t\cdot Z\right|}\right]<\infty
\]
Denn 
\begin{eqnarray*}
  \frac{1}{\sqrt{2\pi}}\int_{\mathbb{R}}e^{\left|x\right|}\cdot e^{-\frac{x^{2}}{2}}dx & = & \frac{2}{\sqrt{2\pi}}\int_{0}^{\infty}e^{x}e^{-\frac{x^{2}}{2}}dx\\
  & = & \frac{2}{\sqrt{2\pi}}\int_{0}^{\infty}\exp\left(-\frac{1}{2}\left(x-1\right)^{2}\right)\exp\left(\frac{1}{2}\right)dx\\
  & = & \frac{2e^{1/2}}{\sqrt{2\pi}}\underset{\leq1}{\underbrace{\int_{0}^{\infty}\exp\left(-\frac{1}{2}\left(x-1\right)^{2}\right)dx}}\\
  & = & \infty
\end{eqnarray*}
Angenommen, wir wüssten:
\begin{itemize}
\item Für $X_{1}\ldots X_{n}$ unabhängig gilt: $\varphi_{X_{1}+\ldots+X_{n}}\left(t\right)=\prod_{i=1}^{n}\varphi_{X_{i}}\left(t\right)$
\item $\varphi$ legt $\mu$ eindeutig fest
\item $\varphi_{n}\left(t\right)\to\varphi\left(t\right)$ $\forall t\in\mathbb{R}$
  $\Rightarrow\left[\mu_{n}\overset{w}{\longrightarrow}\mu\right]$
\end{itemize}
Dann erhält man sofort, den \emph{Satz von DeMoivre-Laplace}:

Seien $X_{n}\left(n\in\mathbb{N}\right)$ i.i.d. Zufallsvariablen mit 
\[
\mathbb{P}\left[X_{n}=\pm1\right]=\frac{1}{2}
\]
Sei $s_{n}=\sum_{i=1}^{n}X_{i}$ dann 
\[
\frac{1}{\sqrt{n}}s_{n}\overset{\mathcal{D}}{\longrightarrow}Z\sim\mathcal{N}\left(0,1\right)
\]


\begin{comment}
  $\frac{s}{n}\approx\frac{1}{\sqrt{n}}\mathcal{N}\left(0,1\right)$
\end{comment}

\begin{proof}
  Die charakteristische Funktion von $X_{n}$ ist 
  \[
  \varphi\left(t\right)=\int e^{it}\mu\left(dt\right)=\frac{1}{2}\left(e^{it}+e^{-it}\right)=\cos\left(t\right)
  \]
  Also hat $\frac{s_{n}}{\sqrt{n}}$ charakteristische Funktion
  \[
  \varphi^{n}\left(\frac{t}{\sqrt{n}}\right)=\cos^{n}\left(\frac{t}{\sqrt{n}}\right)
  \]
  Wir wollen zeigen:
  \begin{eqnarray*}
    \cos^{n}\left(\frac{t}{\sqrt{n}}\right)\overset{n\to\infty}{\longrightarrow}e^{-\frac{1}{2}t^{2}} & \Leftrightarrow & n\log\left(\cos\left(\frac{t}{\sqrt{n}}\right)\right)\to-\frac{1}{2}t^{2}
  \end{eqnarray*}
  \emph{Erinnerung}: Regel von l'Hospital\\
  Es gilt 
  \[
  \lim_{x\to x_{0}}\frac{f\left(x\right)}{g\left(x\right)}=\lim_{x\to x_{0}}\frac{f'\left(x\right)}{g'\left(x\right)}
  \]
  wenn z.B.
  \[
  \lim_{x\to x_{0}}f\left(x\right)=\lim_{x\to x_{0}}g\left(x\right)=0
  \]
  Es gilt 
  \[
  n\log\left(\cos\left(\frac{t}{\sqrt{n}}\right)\right)\overset{x=\frac{t}{\sqrt{n}}}{=}\frac{t^{2}}{x^{2}}\log\left(\cos\left(x\right)\right)
  \]
  $\lim_{x\to0}\frac{t^{2}}{x^{2}}\log\left(\cos\left(x\right)\right)=\lim_{x\to0}-\frac{t^{2}}{2}\frac{\frac{1}{\cos\left(x\right)}\sin\left(x\right)}{x}=-\frac{t^{2}}{2}\underset{=1}{\underbrace{\lim_{x\to0}\frac{1}{\cos x}}}\underset{=1}{\underbrace{\lim_{x\to0}\frac{\cos x}{1}}}=-\frac{t^{2}}{2}$ 
\end{proof}

\paragraph*{Unabhängigkeit:}

Seien $X_{1},X_{2}$ unabhängig mit charakteristischen Funktionen
$\varphi_{1},\varphi_{2}$.
\[
\varphi_{j}\left(t\right)=\mathbb{E}\left[e^{itX_{j}}\right]=\mathbb{E}\left[\cos\left(t\cdot X_{j}\right)\right]+i\mathbb{E}\left[\sin\left(t\cdot X_{j}\right)\right]=\mathbb{E}\left[Y_{j}\right]+i\mathbb{E}\left[Z_{j}\right]
\]
Dann gilt wegen Unabhängigkeit: 
\begin{eqnarray*}
  \varphi_{1}\left(t\right)\cdot\varphi_{2}\left(t\right) & = & \left(\mathbb{E}\left[Y_{1}\right]+i\mathbb{E}\left[Z_{1}\right]\right)\left(\mathbb{E}\left[Y_{2}\right]+i\mathbb{E}\left[Z_{2}\right]\right)\\
  & = & \mathbb{E}\left[Y_{1}Y_{2}-Z_{1}Z_{2}+i\left(Y_{1}Z_{2}+Z_{1}Y_{2}\right)\right]\\
  & = & \mathbb{E}\left[e^{it\left(X_{1}+X_{2}\right)}\right]
\end{eqnarray*}

\begin{lem} % flashcard-name: Was gilt für unabhängige ZVen $(X_i)$ mit charakteristischen Funktionen $\phi_X_i$
  Seien $X_{i}$ $\left(i=1\ldots n\right)$ unabhängig mit charakteristischen
  Funktionen $\varphi_{X_{i}}$. Dann gilt
  \[
  \varphi_{X_{i}+\ldots+X_{n}}\left(t\right)=\prod_{i=1}^{n}\varphi_{X_{i}}\left(t\right)
  \]

\end{lem}
Wir zeigen nun: $\varphi$ liegt $\mu$ eindeutig fest. Genauer: wir
finden eine Darstellung
\[
\mu\left((a,b]\right)=\int f\left(a,b,t\right)\cdot\varphi\left(t\right)dt
\]
Wir betrachten zunächst folgendes Integral
\[
S\left(T\right)=\int_{0}^{T}\frac{\sin x}{x}dx
\]

\begin{lem*} % flashcard-name:  Was gilt für den Grenzwert \[\lim_{T\to\infty}\int_{0}^{T}\frac{\sin x}{x}dx\left(T\right)=\frac{\pi}{2}\]
  Es gilt
  \[
  \lim_{T\to\infty}S\left(T\right)=\frac{\pi}{2}
  \]
\end{lem*}
\begin{proof}
  Es gilt
  \[
  \frac{1}{x}=\int_{0}^{\infty}e^{-uX}du
  \]
  Einsetzen erigbt
  \begin{eqnarray*}
    \int_{0}^{T}\frac{\sin x}{x}dx & = & \int_{0}^{T}\sin x\cdot\left(\int_{0}^{\infty}e^{-uX}du\right)dx\\
    & \overset{\mbox{Fubini}}{=} & \int_{0}^{\infty}\underset{=\frac{1}{1+u^{2}}\left(1-e^{-uT}\left(u\cdot\sin T+\cos T\right)\right)}{\underbrace{\left[\int_{0}^{T}e^{-uX}\cdot\sin x\ dx\right]}}du\\
    & = & \int_{0}^{\infty}\frac{1}{1+u^{2}}du-\underset{\to0\mbox{ für }T\to\infty\mbox{ nach Lebesque}}{\underbrace{\int_{0}^{\infty}\frac{e^{-uT}\left(u\cdot\sin T+\cos T\right)}{1+u^{2}}du}}
  \end{eqnarray*}
  Also bleibt zu zeigen
  \[
  \int_{0}^{\infty}\frac{1}{1+u^{2}}du=\frac{\pi}{2}
  \]
  Wir wenden die Transformationsformel an:
  \[
  \left[a,b\right]\overset{T}{\longrightarrow}\left[u,v\right]\overset{f}{\longrightarrow}\mathbb{R}
  \]
  \[
  \int_{T_{a}}^{T_{b}}f\left(y\right)dy=\int_{a}^{b}f\left(T_{y}\right)T'y\ dy
  \]
  $f\left(y\right)=\frac{1}{1+y^{2}}$, $a=-\frac{\pi}{2}$, $b=\frac{\pi}{2}$,
  $T\left(x\right)=\tan\left(x\right)$. Mit einsetzen oben erhalten
  wir
  \begin{eqnarray*}
    \int_{T\left(a\right)}^{T\left(b\right)}f\left(y\right)dy & = & \int_{-\infty}^{\infty}\frac{1}{1+y^{2}}dy\\
    & = & \int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}\frac{1}{1+\tan^{2}\left(y\right)}\left(1+\tan^{2}\left(y\right)\right)dy\\
    & = & \pi
  \end{eqnarray*}
  Also gilt
  \[
  \int_{0}^{\infty}\frac{1}{1+y^{2}}dy=\frac{\pi}{2}
  \]

\end{proof}
\begin{comment}
  Kein Klausurbeweis
\end{comment}

\begin{prop}[Eindeutigkeitsatz] \index{Eindeutigkeitssatz}
  Sei $\mu$ ein Wahrscheinlichkeitsmaß mit charakteristischer Funktion
  $\varphi$ (Fourier-Transformierte). Sei $\mu\left(\left\{ a\right\} \right)=\mu\left(\left\{ b\right\} \right)=0$.
  Dann gilt
  \[
  \mu\left((a,b]\right)=\lim_{T\to\infty}\frac{1}{2\pi}\int_{-T}^{T}\frac{e^{-ita}-e^{-itb}}{it}\varphi\left(t\right)dt
  \]
  Insbesondere legt $\varphi$ das Maß $\mu$ eindeutig fest. 
\end{prop}
\begin{proof}
  Eindeitigkeit ist klar. Sei 
  \begin{eqnarray*}
    I_{T} & = & \frac{1}{2\pi}\int_{-T}^{T}\frac{e^{-ita}-e^{-itb}}{i\cdot t}\varphi(t)dt\\
    & \overset{\mbox{Fubini}}{=} & \frac{1}{2\pi}\int_{-\infty}^{\infty}\left[\int_{-T}^{T}\frac{e^{-it\left(a+x\right)}-e^{-it\left(b+x\right)}}{it}dt\right]\mu\left(dx\right)
  \end{eqnarray*}
  Da $e^{iy}=\cos\left(y\right)+i\sin\left(y\right)$ und $\cos\left(x\right)$
  eine gerade Funktion ist, folgt: 
  \[
  I_{T}=\int_{-\infty}^{\infty}\left[\frac{sgn\left(x-a\right)}{\pi}S\left(T\left|x-a\right|\right)-\frac{sgn\left(x-b\right)}{\pi}S\left(T\left|x-b\right|\right)\right]\mu\left(dx\right)
  \]
  Für $T\to\infty$ konvergiert der Integrand gegen: 
  \[
  \Psi_{a,b}\left(x\right)=\begin{cases}
    0 & x<a\\
    \frac{1}{2} & x=a\\
    1 & a<x<b\\
    \frac{1}{2} & x=b\\
    0 & x>b
  \end{cases}
  \]
  Also gilt 
  \[
  \lim_{T\to\infty}I_{T}=\int_{a}^{b}1d\mu=\mu\left((a,b]\right)
  \]
  da $\mu\left(\left\{ a\right\} \right)=\mu\left(\left\{ b\right\} \right)=0$. 
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Index
\printindex

\end{document}